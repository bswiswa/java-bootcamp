What is Java?
-general purpose, object oriented, platform independent, concurrent and very fast programming language.
-invented in the mid 90s. Similar to C & C++
-simplicity was the goal. Java has automatic memory management using garbage collection. No manual memory management like C or C++
-secure

Goals during creation
- low memory consumption
- should allow devices to commuicate
- should be independent of platforms - run on target device with no issues
- should be secure
- should support multithreading so that devices can perform other tasks
C++ was limited due to lack of platform independence
James Gosling created Oak then renamed Java. It was too advanced and rejected by cable companies.
HotJava browser created by Sun which made internet interactions more dynamic by embedding Java programs
First version released in 1996.

Compilation
- verify syntax & semantics of source code
- optimize code
- generates machine code

Platform dependency
-If processor differs, the software has to be recompiled in order to run

Interpreter
No compiling. Interpreter handles source code and produces results
Compiler path: source code -> compiler -> machine code -> CPU -> results
Interpreter path: source code -> interpreter -> results
Interpreter is a virtual machine that simulates a CPU.
Fetch & Execute cycle:
      CPU		<- Memory	<- Storage
      (executes)	-> data

Interpreter also fetches instructions from memory. It understands the statement then executes precompiled machine code in its library.
As long as a platform has an interpreter suitable for it, code will be made once and run anywhere
Pros of interpreter:
     platform independence
     no compilation step
     easier to update due to no compilation
Limitations of intepreter
	    Slow due to costly memory access. Registers make compiled
	    languages much faster
	    Source code is reinterpreted every time
	    Interpreter is loaded into memory

Java Intepretation
     source code -> Java Compiler -> Java byte code(platform independent intermediate) -> JVM (Java virtual machine, dependent on machine) -> results

eg Hello.java (source) -> javac Hello.java [compilation] -> Hello.class (Java byte code) -> Hello.class can now be executed on any platform with JVM via java Hello

Java Speed?
How is it fast if interpretation is slow?
- Bytecode interpretations are much faster because Java bytecode is
  compact, compiled and optimized already. Java Bytecode's compactness also
  allows quick transfer across networks. Remember that Java was designed to work with multiple types of devices on a network
- Just-in-time compilation (JIT) - monitors frequently executed bytecodes "hotspots". These hotspots are converted to machine code and cached. This cached machine code is executed faster later from the cache. This is called dynamic compilation. The caching gives Java its speed

Java Virtual Machine
- the cornerstone of Java
- is an abstract computing machine
- executes instruction set (Java bytecode)
- manipulates memory at runtime
- is secure across networks
Abstract JVM specification

Java Software Family
Java Standard Edition(Java SE)
     standalone applications for desktops & servers
Java Enterprise Edition (Java EE)
     enterprise applications for servers eg e-comerce websites
     includes Java SE
Java Micro Edition (Java ME)
     applications for resource-constrained devices

Java SE
Java Runtime Environment
     	  only run Java programs
Java Development Kit (JDK)
	  develop & run Java programs

Java program structure
     CLASS
     variable declarations
     constructors, statements
     methods
     nested classes, statements

if you have a class with the modifier public, then the name of the file has to be the same as that class name

main method is invoked first when the Java Virtual Machine (JVM) loads the class bytecodes.
It must be declared as
   public - for JVM to be able to invoke it. otherwise it will not run. public means that you can call the method from outside of the class you are currently in. This is necessary because this method is being called by the Java runtime system which is not located in your current class.
   static - access modifier which allows us to call this method directly using the class name without creating an object of it. So every function in a class that only performs tasks in it should be static eg static int add_num
   void - return values mean different things on different platforms. Java is avoiding that problem by having its main method return nothing. There are other ways to exit the program eg System.exit()

Classes & Objects
OOP roots back to 1960s. Conceived to implement large projects and implement
real world scenarios in a natural way

Classes are blueprints and objects are instances of classes
Class members - variables, methods, member classes, member interfaces

class Student{
//variable declarations

//method declarations
}

to initialize an object we use the new key word
the dot operator is used to access the object's state and methods

Java Basics
     comments //ignore rest of line /*ignore block*/
     case-sensitive Test != test
     classes, methods and variables must start with letter, underscore or $
     some reserved keywords like class, interface, enum...
     Printing to console
     	      System.out.println(string) - print and go to new line
	      System.out.print(string) - print and place cursor after the printed string.

Variables
	containers of data or references to objects.
	always have a type associated with it and they will hold data of that type
	variable type also determines the methods that can be performed on that type.
	Variable type is declared when the object is created. It cannot be changed thereafter. Thus Java is a statically-typed language. There is static type checking to prevent assigning a type that is not the original type.
	Dynamically typed languages allow variables to change their types at any point eg JavaScript
	Static type checking has the advantage that it allows earlier detection of programming mistakes.
	Variable declaration <type> <name> = [literal or expression]
	Variable is something whose value can be changed
Variable Kinds
	 instance variables or attributes - declared directly in the body of the class. If not initialized they always have a default value. They represent state specific to each object of a class. Cannot be reinitialized directly within a class. Reinitialization is done within object methods only
	 static variables - declared in class with keyword static. Is shared by all objects in that class. Only one copy is maintained per class regardless of the number of objects of class. Also get default value and cannot be reinitialized directly within the class.
	 local variables - declared in methods. Includes method parameters. Not accessible outside of the method. They only exist on the stack when the method is mounted and they are cleared off after its execution. No need for default value.

Variable types
	 Primitive
	 8 types - boolean, byte, short, int, long, float, double, char (char is internally represented as an unsigned int)
	   integers
		whole or fixed point numbers - byte, short, int, long
		represented by signed two's complement.
		Binary addition:
		Sign-magnitude representation of bits makes the left-most
		bit 1 for negative and 0 for positive. There are however
		two problems associated with this representation
		1. There are two representations of zero eg for 8 bits -
		1000 0000 and 0000 0000 [ -0 and +0 ]
		2. Binary addition of positive and negative numbers doesn't
		work - eg add 16 [ 0001 0000 ] to -24 [ 1001 1000 ] =
		1010 1000 or -40
		In order to make binary addition work, we need a way to find
		a number which when added to another binary number results
		in 0000 0000 (in 8 bits for example). In other words for
		every bit pattern of N bits there is a corresponding bit
		pattern of N bits which produces an N-bit zero when the two
		patterns are used as operands for the binary addition
		algorithm. Each pattern can be thought of representing the
		negative of the number that is represented by the other
		pattern.
		This representation is called two's complement. It is
		derived as follows:
		1. Start with an N-bit representation of an integer
		2. To calculate the N-bit representation of the negative
		integer, reflect each bit of the bit pattern
		(change 0 to 1 and 1 to 0)
		3. Add one.

		integers represent whole or fixed-point numbers
		types: byte(8 bit)[-128 to +127], short(16 bit)[-32768 to 32767 (~32 000)], int(32 bit) [-2147483648 to 2147483647 (~2 billion)], long(64bit)
		default of all ints is 0 for class-level variables, however within methods, they have no defaults and so they need to be initialized before use
		long = 10000000000L // L required if above the int range
		int also stores hexadecimal numbers or Java 7 binary or octals. Underscores can be used in between digits to improve readability eg int x = 1_243_300;
Floating-Point Numbers
real numbers with 32 bit float or 64-bit double
   double is more precise
   Data representation ~ 32 and 64 bit IEEE 754 flaating point convention
   float -3.4E38 to 3.4E38 where E is power 10
   double -1.7E308 to 1.7E308
   float f = 123.4f //TRAILING F is required (upper or lower case)
   double d = 123.4 //TRAILING D is optional

   General rule - avoid float and double if exact answers are required. Unsuitable for money calculations.
Recommended to use BigDecimal which comes in Java library. You can use int or long but you have to keep track of decimal point yourself.
Floating point arithmetic is not as fast as integer. In general stick with int and double.
double's greater precision is useful. Use float if memory saving is important.

Characters
represented by 16 bit unsigned integers internally
range is 0 to 2^16 -1 (since we are not dealing with negative numbers)
default value when defined directly in class is '\0' or '\u0000' (if defined in method, it has no default and is uninitialized). '\u0000' is a unicode hexadecimal escape sequence
Java uses 16 bit unicode scheme (UTF-16) which means that they are first encoded in UTF-16 format (a hexadecimal number) then stored as a 16 bit unsigned int.UTF is one of the implementations of the unicode standards.
eg 'A' is encoded to hexadecimal 0041 which is then stored as a 16 bit unsigned int 00000000 01000001
   char c = 'A'; // always in single quotes
   char c = 65; // can also be declared with an unsigned int. It will be assigned the UTF-16 character corresponding to 65. thus we can add to char variables just like we do with ints
   char c = '\u0041'; // assigned with a hexadecimal unicode number. Useful if keyboard doesn't allow us to assign certain characters.
   char c = 0x41; // hexadecimal converted to decimal number and character corresponding to that UTF number is assigned.

Boolean
Boolean bit storage is JVM specific/ machine specific. Has value of true or \
false. Default value is false;

Type Casting
Assign variable or literal of one data type to another type eg change a byte to an int or long to int. It is only available for numeric to numeric casting. Since an character is stored as an unsigned int, it can also be typecasted. Cannot cast to boolean or viceversa.
Implicit typecasting:
	 smaller to larger type conversion - widening conversion
	 eg int x = 65; long y = x; (implicit casting by compiler)
	 assigning an int to a float is implicit. As long as range of values of the final type is larger than the input type, casting is implicit eg long int to float is implicit. So assigning char to int is implicit.

Explicit typecasting
	 when assigning a variable of larger range to a smaller range type = narrowing conversion. note that even though char and short are both 16 bits, char has a larger positive range.
	 long y = 42;
	 int x = (int)y;
	 without the above cast we would get a compiler error due to the different type.

* although implicit casting is taken care of by the compiler, you can still explicitly cast.
Out of range assignments result in information loss
    eg byte narrowByte = (byte)123456; // narrowByte = 64 (only lowest rightmost 8 bits are saved)
Truncation
Floating-point to int/char will always truncate the number
	       eg int x = (int)3.14f; // x = 3;
	       	  int y = (int)0.9; // y = 0;
		  char c = (char) 65.5; y = 'A'

Information Loss Implicit Casting
Assigning int to float or long to float can result in loss of precision. Assigning long to double results in loss as well.
int and long to float can lose some of the least significant bits during assignment. The same can happen for long to double [both have 64 bits]. int to double is fine though.

You may have to explicitly cast when there is an issue with range of values.

Object references
       Student s = new Student();
       here s is a variable that is an object reference. It holds bits that reference the student object in memory. It is not the object itself.
       Student s means allocate memory for a Student reference variable
       new Student() means allocate memory for a student object
       Objects are created and stored on the Heap.
       Default reference of an object reference is null, until it is explicitly initialized. If you try to reference a member of a null pointer, you will get a NullPointerException.

Statements
They are what constitutes a program.
Every statement ends with a semi colon and is a command to be executed.
A statement changes program state.
3 kinds of statements
  declarations eg int count = 25;
  expression statements eg count = 25; count++;
  control flow statements eg if(count < 100){....}

  Only declaration statements can be defined at class level. Expression or control flow methods can be part of other sections like methods.

Arrays
An array is a data structure. A data structure is an organized collection of related data. An array is a container object that holds a fixed number of values of single type. Since an array is an object it is stored on the heap. The variable referencing it is an object reference.
Creating an array
	 int myArray[] = new int[7] // each element by default is zero (default int value)
	 int myArray[] = new int[]{9,11,2,3}; // no need to specify array size here
	 int myArray[] = {9,11,2,5};
	 int[] myArray = new int[7]; is also ok so it is up to you.
	 array length = array.length [note that it is not array.length()]
	 NOTE: an array is an object and so it is only created using the new keyword. Simply declaring int b[10]; or Student students[10]; IS NOT ALLOWED
Array of Object references
      Student students[] = new Student[2];
      Note that the above only creates an array of object references that are pointing to null. If you try to access members from them
      you will get a NullPointerException. In order to use the array, you have to do a for loop and instantiate objects by calling the
      constructor method [new Constructor()] for each of the references to point to.
      So all in all to create an array of object references with actual objects being pointed to:
      1. declare the array with its size: Student students[] = new Student[2];
      2. loop through and instantiate objects for the references: for(int i = 0; i < students.length; i++){ students[i] = new Student(); }
Random access
       Linear layout, contiguously -> fast random access. Accessing is O(1) - constant time
       Searching an array is O(n) however, linear time. This can be modified with data structures.
Remember that an array is an object that stores a fixed number of elements. All these elements should be of a single type.

2D Arrays
   Creation: int myArray[][] = new int[4][2]; no. of rows first, columns next [x][y]; THE LENGTH OF A 2D ARRAY IS THE NUMBER OF ROWS IT HAS
Internally JVM creates a one dimensional array and each element refers to each of the 4 rows. Each element is actually an object reference referring to another int array with 2 elements. So a 2D array is actually implemented as a 1D array with object references. These references point to arrays themselves
	   Look at array declaration
	   	type myArray[] -> array of type
		type myArray[][] -> array of int array
If you want to declare and populate the 2D array:
int myArray[][] = new int[][]{ {9,11}, {2,5}, {3,4} }; OR
int myArray[][] = { {9,11}, {2,5}, {3,4} };

Array with Irregular rows:
      int myArray[][] = new int[2][];
      myArray[0] = new int[5];
      myArray[1] = new int[2];
      so first row has 5 columns and second row has 2 columns
      This helps avoid storing duplicate or unwanted rows and save storage space. This is very useful for large matrices.
.length of a 2D array returns the number of rows it contains

3D Arrays
Rare in practice.
int myArray = new int[4][4][4];

Methods
Variables define object state. Methods define object behavior.
Methods have self-contained logic that can be used many times
All software's algorithms are coded into methods and nothing can be achieved without them.
They can receive input and generate output
Syntax of a method
       returnType methodName(type param1, type param2,...){

       		  return someValue;
		  }

Method signature includes only methodName(type param1, type param2...); so only method name and its parameters, not its return type

Return types
       void - nothing to return
       if return type is something other than void, then the method must return something.
       The return value must be compatible with return type of method eg an int method can return a byte however a byte method can only return a downcasted int or narrowed to byte  since int is larger than byte.

Methods help avoid duplicate code - reduce maintenance headaches
Divide complex logic into multiple smaller pieces in their own methods - this promotes software reusability, clean and readable code. Each method should do only one thing and no more.

Method types
       instance methods
       		Object-level methods
		Invocation: dot operator eg objectRef.methodName()
		Affect object state by
		       affecting instance variables
		       invoking other instance methods in that class
	static methods
	       have keyword static in declaration otherwise they are instance methods
	       are class-level methods - no access to state ie cannot access
	       instance variables/methods
	       can only access static variables and other static methods
	       invocation: className.methodName()

Passing Data
	When primitives are passed to a function, their updates within the function do not affect the state of the variable in the calling environment. However, if an object reference is passed to a method, the object is also updated in the calling environment.
	Pass by value
	primitives are stored in 3 components:
	<logical name, memory address, value>
	At run time, for a primitive variable only memory address and value are available. The memory address is provided by the logical name

	For object references, <object reference, memory address of actual object>

Pass by value = a copy of the value of the primitive argument is passed
     Object reference = value of an object reference is the memory address of the object, so a copy of the value of the memory address is passed to functions.
Java is always pass by value during method invocation; Remember that when object references are passed to methods, it is a reference to the actual object that is passed.

METHOD INVOCATION AND ARRAY NOTICE
When calling a method with an array literal, the following is valid
   function(new int[]{1,3,5}), if you try function({1,3,5}) THIS IS INVALID
   this kind of array {1,3,5} is only valid at array initialization say
   int arr[] = {1,3,5}; but it is invalid for re-initialization or method calls.

Method Overloading
multiple methods have the same name but different parameter list.
to overload a method YOU MUST change either the parameters or parameter types or both. Changing the RETURN TYPE DOESN'T MATTER
Applies to instance and static methods.
	eg boolean updateProfile(int newID){...}
	   boolean updateProfile(int newID, char gender){...}
If two functions have compatible data types, the function that gets called is the one that is closest to the data type submitted
   eg void overload(int i) {...} and void overload(short i){...} if someone calls byte b = 23; overload(b), then overload(short) is called since it has the next largest data type
   to the byte input.
You would have a compilation error if
    you try to overload a funtion by just changing the return type eg
    void updateProfile(int newId){...} and boolean updateProfile(int newId){...}
    you will also get an error if you just make the same signature with static.
In all these you will get a duplicate method error.
You get errors if you just change the return type or other modifiers that are not in the method signature because when calling a method, we do not specify its return type or
its access modifiers thus when you call updateProfile(4), the program does not know which one you want to run it with since you cannot call it whilst specifying return type
like void updateProfile(4);

varargs
from Java 5 onwards methods can have variable number of arguments.These special types of parameters are called varargs and even though it is a single parameter it can take 0, 1 or many arguments. It is always the last parameter specified (or the only one if the method has no other arguments)
    Syntax: three dots following parameter type (called ellipsis) type eg
    	    foo(boolean flag, int... items)
Invocation: array of any size eg (from above) foo(true, new int[]{1,2,3});
	    commma-separated arguments eg foo(true, 1,2,3); here 1,2,3 are the varargs. Here those last three numbers are automatically converted to an array. Within the method the vargarg is treated like a normal array.
	    The varargs can also be ignored completely eg foo(true). In this case, an empty array will be passed to the varargs parameter.
	    Varargs restrictions:
	    	    - must be last variable in the invocation
		    - cannot have two varargs in an invocation (violates the rule above)
Why varargs in the first place? Why not just an array?
    provides simpler and flexible invocation
    can choose to not use it and function will still run.
    printf is a method introduced in Java 5 which uses varargs
    printf(String format, Object....args);
    eg System.out.printf("DOB: %d/%d/%d", 1,1,1978);

    varargs & main Method
    public static void main(String args[]){...} OR
    public static void main(String...args){...}

    varargs & Overloaded methods
    a vararg is made into an array and so the following are duplicates and will not compile
    foo(boolean flag, int...items);
    foo(boolean flag, int[] items);

    varargs method will be matched last

Constructor
Runs on object creation. Initializes object state (that is its instance variables)
     eg Student s = new Student();
     Student() invokes the constructor
     Syntax of constructor
     	    ClassName(type param1, type param2,...){
	    ...
	    }

	    looks like a method but it does not have a return type
eg class Student{
   	 int id;
	 Student(int newId){
	 id = newId;
}

}

In the above class definition, the constructor is:
        Student(int newId){
	 id = newId;
} and it initializes each new Student object with an id value of newId

If a constructor is not provided, the compiler will create a default constructor called a no-args constructor (no parameters).
eg class Student{
   int id;
}
the above class has no class constructor so on compilation, the compiler will add a no-args constructor:
    class Student{
    int id:
    Student(){}
}

This now allows us to create a new object that we can reference by
     Student s = new Student();
Note that once an object has a constructor and that constructor requires a variable, you cannot create a new object using the no-args constructor.

Constructor overloading
Can be done just like methods. Parameter list must be different. Constructor names are always the same as the class name anyway.
Why constructor overloading?
    to create objects with different capabilities eg Java's file output handling
    FileOutputStream(String name, boolean append) // open a file and append
    FileOutputStream(String name) // overwrite the contents of existing file

Constructors can have a return statement but it doesn't return anything.

we use this keyword so that we can access instance variables that are hidden (or shadowed) by local variables.
   class Student{
   	 int id;
	 String name;
	 void updateProfile(int newID, String name){
	      id = newId;
	      this.name = name;
	      }
}

we use this.name in the updateProfile() method because one of the method parameters is called name which happens to be one of the instance variables of the Class. So anytime you are in the method and you use name, you are referring to the parameter name. You'd have to use this.name in order to get the instance variable.
Static methods are class methods so they can not use the this reference as this reference is used to access instance variables and instance methods only.

You can run a class from a different file as Java will automatically search and compile the file with the right class. You do not need to compile both files. Note that this is
subject to certain accessibility restrictions and package setups. [Classes in the same file folder, with no other explicit package definitions are assumed to be in the same package and will be compiled together]

Reassigning Object References
By default Java passes by value. See the ReassignObjectReferences.java file. Any object in memory left without reference will be freed up by Java's garbage collection

Operator
	A symbol which performs an operation on its operands and produces a result.
Unary operator - operates on one operand eg -x, x++;
Binary operator - operates on two operands. placed between operands (infix)
Ternary operator uses two symbols a ? and a : eg (x > 3)? x : 0

Arithmetic Operators
+ addition eg int i = 5 + 2; (+ can also be used to concatenate strings)
- subtraction
Note that both + and - can be used as unary operators eg -x or +x
* multiplication
/ division
% modulus - returns the remainder
++ increment - post-increment (x++) and pre-increment (--x);
-- decrement - post-decrement (x--) or pre-decrement (--x);

Arithmetic operators apply to all primitive types except boolean.
Compound arithmetic assignment x = x + 5 => x += 5; others include -=, *=, /=, %=

Arithmetic Operation Rules
	   Operator precedence rules
	   1. Multiplicative operators (*, /, %) have higher precedence over additive operators.
	   2. Operators in the same level will be evaluated left to right
	   3. Parentheses can be used to change the order of evaluation

Operand Promotion
	Operands smaller than int are promoted to int before addition is applied[byte, short or char]
	eg 127(byte) + 1 (byte) -> 127 (int) + 1 (int) -> 128 (int)
	'a' + 'b' = 195 why? char is treated as a 16 bit unsigned integer
	'a''s decimal value is 97 and 'b' is 98 in UTF-16
	4. Same type operations if both operands are int, long, float or double, then operations are carried in that type and evaluated to a value of that type thus 1 / 2 = 0 not 0.5
	Mixed Type Operations
	If both operands belong to different types, then the smaller type is promoted to larger type (note that long is converted to float even though long is 64 bit and float is 32 bit - float has a greater +).
	Comparison Operators/Relational Operators
	compare one operand with another and test some condition. Since we are testing a condition, the output will be a boolean value. Key for flow control statements
	< lt	<= le  > gt  >= ge	 == eq   != neq
Logical operators/conditional operators
comparison operators alone can only test a single condition eg if(x > 7){..}
How about testing multiple conditions? eg (x > 7) and (y < 2)?

&& AND	  || OR	  ! NOT

With these logical operators we can test one or more conditions. Logical operators just like relational operators will return boolean values.They can be used in control flow statements.

&& and || are short circuit operators because they can quickly evaluate without checking both sides of the expression eg  left operand && right operand -> this will evaluate to false if left operand is false and will not wait to check right operand. It only checks right operand if left is true.
left operand || right operand also evaluates fast without checking if left operand is true.
These two short circuit operators can improve run time performance.
&& prevents NullPointerException by preventing us from accessing an object which is null eg if(s != null && s.getGender() == "male"){...} here the && prevents us from just trying to access the getGender method on a null pointer.
Operator precedence
	 ! then && then ||
	 you can use parentheses to change evaluation order

Bitwise Operators
operate on bits. Operands can be integers or boolean
	Applications - mostly in embedded systems with resource constrained environments where things must be manipulated very efficiently.
	Hash tables eg Java HashMap's hash function
	Compression and encryption
Bitwise Operators
	& returns 1 if both bit inputs are 1
	| returns 1 if either of input bits is 1
	^ returns 1 if only one of the input bits is 1
	~ inverts bits of its operand
	bitwise & and | are non-short circuit operators so they always check both operands unlike in && and ||
	Compound bitwise assignment &=
Bit Shift Operators
    shift bits. Their operands must be integers.
    << left shift
    >>> unsigned right shift
    >> signed right shift [preserves the sign of the original number]
    Uses - faster than multiplication and division and compilers can use them. Used in games and embedded programming. Also systems without floating points.Can also be expressed with compound expressions >>=, >>>= <<=

Control-flow
If body of any of the control statements has more than one statement, use curly braces. Note that it is also good practice to include curly braces anyway
if, for, while, do while, switch

if(x > 7){...}
else if(x == 5){...}
else {...}

switch(x){
	case a:
	     do ...;
	     break;
	case b:
	     do ...;
	     break;
	default:
		do....;

}

a switch expression's numerical final value SHOULD EVALUATE TO AN INTEGER. Thus items submitted to the switch expression should be converted to integers and then compared.No duplicate values should be placed in the switch expression. Note that the range of the case values should be in the data type range.
Case label value must be a constant expression.Can be an integer or string literal. eg final int label = 4;
only constants can be used as cases
                                 in a switch statement, hence the use of fin\
al. This is because the switch statement is setup during compilation so it n\
eeds the final values. A null case cannot be used as well
switch statement cannot be used in the following conditions:
       - there is more than one condition to test
       - tests other than equality eg month >= 3;
       - switch cannot be used for variables that are not integers, strings or enum
       - if at least one of the case label restrictions does not apply.
switch is preferred if:
       - readability improves
       - intent - the switch is clear with what variable is being evaluated
       - switch is faster than if because case labels are known at compile time. Also, switch has less comparisons. In the worst case, an if statement will take O(n) time to evaluate whereas a switch statement is O(1)
Ternary Operator
Can be used as an alternative to an if else statement.
Shorthand for if-else with single statements
	  result = (boolean-expression)? value-if-true : value-if-false;
**Note that parentheses are optional but they improve readability.
When to use ternary operations - to improve code readability
Ternary operator cannot be an expression statement.
 (x > 2)? 3: 4; is invalid. Ternary operator can only be used if we are assigning something. eg int y = (x > 2)? 3:4;

for Statement
To iterate over array elements.
for(int i = 0; i < 10; i++){...}
 Initialization part of for loop can be done on the outside. eg
   	   int i = 0;
	   for(;i<10; i++){...}		UGLY
for-each Statement
Iterate arrays & other data structures
for(int i: array){
	System.out.println(i);
}
Increments are taken care of internally. Reduces chances of errors in nested loops.
Traditional for loop should be used when you need to transform one item in the index. Also useful when you want to traverse two arrays in parallel.
eg for(int i = 0, j = 0; i < I_array.length && j < J_array.length; i++,j++){
   System.out.println(I_array[i]+ " "+ J_array[j]);
}
Traditional for loops are also good for backward iteration. With for each you can only move forward.
For each has much cleaner cde.
While loop
Run if you do not know the number of times the loop should run
Do while
Runs at least once. Note that the do{...}while(...); expression ends with a semicolon;
Infinite loops
	 while(true){
		if(getTime() == 8){
			     sendEmails();
			     }
			     }
break statement
Exits immediately enclosing swith or loop (for/while). A break statement needs to be in a switch or for/while loop otherwise it will be invalid
Labeled break Statement
How about if you want to exit one of the outer switch/loop. First we label the block statement label: block statement eg outermost: THEN we use the statement break outermost;
A block statement contains 0 or more statements enclosed in curly braces eg any control statement with a brace. Once we have labeled a block , we can use the break label; command to break;
continue statement
	 continues with the next iteration of the innermost loop. skips the rest of the loop and goes to the next cycle.
There is also a labeled continue statement. First we label the loop we want then we use continue label. the continue label cannot be used with an if statement though. break can be used with it though.
Variable scope
Every variable has a scope
Entire class variables/globals

Packages and Information Hiding
Java API
Library of well-tested classes. Over 4 000 in Java 8
Packages contain classes
Why do we need packages?
    packages provide meaningful organizaiton of classes
    name scoping
    security

Important packages
	  - java.lang = fundamental classes eg String
	  - java.util = Data structures
	  - java.io = reading & writing
	  - java.net = networking
	  - java.sql = databases
Know and Use the Libraries
API benefits
    - focus on writing new logic
    - good APIs improve performance over time
    - gain new functionality too

Accessing Packages
if classes are on the same package, they usually have direct access
if in a different package,
	 - use import statement
	 - use the fully qualified class name - rare package_name.class_name. Even if we wrote the class we may have to use these

import Statement
eg import java.util.ArrayList;

class Fooclass{
      void(){
      ArrayList list = new ArrayList();
}

}

Have to put import statement above the class definition. Here we imported a single class called ArrayList from java.util. This is also called a single type import.
Often we import multiple classes. We can use * import (star import) - import on demand. This imports all classes in a package.
eg. import java.util.*;
Or you can use explicit imports for specific classes.

* import has the problem that it can break your code eg
  import java.util.*;
  import java.sql.*;

  if initially the java.util package has a Date class but next year, the java.sql adds a Date class as well. An explicit import would not have this problem. Explicit imports also add more clarity. Although there is no strict consensus, explicit imports are preferred.

Alternative to using import is to use the fully-qualified class name eg
	    java.util.ArrayList list = new java.util.ArrayList();
This is cumbersome and is only useful if say we want to use java.util.Date & java.sql.Date in the same class. You would need to use at least one fully qualified class-name or both as shown below.

Solution 1
USE ONLY ONE EXPLICIT IMPORT

    import java.util.Date;
    import java.sql.*;

    Date date; //from util
    java.sql.Date date2;

    here the explicit import always takes precedence over * import in such a scenario. If we had even more packages, we still can only explicitly import one of them.

Solution 2
USE FULLY QUALIFIED NAMES
    import java.util.*;
    import java.sql.*;

    java.util.Date date;
    java.sql.Date date2;

we still have to use only fully qualified names here

NOTE THAT THE FOLLOWING IS NOT ALLOWED:
     import java.util.Date;
     import java.sql.Date;

this is because it is a specific import of an identical class name
An import statement does not make your class bigger and it does not affect the run time performance. It simply saves you from typing the fully-qualified name - the compiler does this during compilation.

java.lang is imported by default- that is why we could use String

Creating our own packages
Packages are directories on the file system.
We need the package statement in the name. Typically package names have at least two or 3 components separated by dots. It must be the first statement above any imports

   eg package bswiswa.package.name;
      import java.util.ArrayList;
      class Basics{
}

To create package
   ensure that a matching directory structure exists
   use package statement
   once class is compiled, the package name is part of the class name

In professional projects, class files and source code are kept separately
This helps in deployment and code distribution.
setup the package statement in the same folder structure
companies use their reversed internet domain names to begin their package na\
mes eg com.precipio.share
Package name may not be valid because of hyphens or other special characters\
. Also if package name begins with a digit or a reserved keyword eg "int". I\
n this case the suggested convention is to add an underscore
eg java_bootcamp.StudentPackage above

***When creating a package make sure there is a matching directory structure that matches the name of the package
eg if your package is called methods.math and your class file part of that package is Trigonometry.java, then
Trigonometry.java needs to be in the folder directory methods/math/
Trigonometry.java will look like this:

package methods.math;
class Trigonometry{...}

We compile this file as normal using the Java compiler command: javac Trigonometry.java
The generated class file can be misleading. When you look at it it is called Trigonometry.class, however,
it actually does not contain a Trigonometry class. This is because any .java file that contains a package statement at the top
is compiled to produce a class file which includes the package name in it. Thus our Trigonometry.java file with the
package methods.math; statement up top is compiled into a class called "methods.math.Trigonometry".
In order to run this bytecode we use the java command but things are different from running a regular class file which is not associated with a
package. The interpreter looks to find our class in the class path first. Once it gets to the class path, it uses the name of the
package to navigate into the folders to find our bytecode. That is why it is important that a folder structure that matches your package name
actually exists. So the full path that the interpreter will look is equal to the CLASSPATH + package-path. In the above example,
the package path is methods/math/ so our CLASSPATH needs to be the file directories that connect down to the methods/ folder
eg /User/Documents/user1/ .We can set the CLASSPATH permanently by typing export CLASSPATH=/User/Documents/user1/ in the terminal
Then we can run the java methods.math.Trigonometry and we will evaluate the bytecode as normal. We can also temporarily explicitly specify
the classpath for a given run by using the -cp flag and specifying the folder structure where we want our classpath to go eg
java -cp ../upper_folder/ ../upper_folder/A_Class

Explanation 2 
Then we need to use a package statement at the top of the class.
Once a package statement is placed on top of a class, the package name becomes part of the class name so for example the command to interpret the bytcode java Basics will no longer work for a class Basics with a package statement but you will have to use java bswiswa.javacoding.Basics ie a fully qualified name.
**NOTE THAT you still compile the class using javac Basics.java and the output class is still called Basics.class and not bswiswa.javacoding.Basics.class
To make it work, you may have to change the CLASSPATH to the PARENT FOLDER of your package so you can run it anywhere eg if the path to your package files is /Documents/code/package/PackageFile.java, then you need on UNIX, you should type the command,
export CLASSPATH=/Document/code/ because since the package name will become part of the class name on compilation, when you run the java command to run the virtual machine, the interpreter will look into the path defined by adding the CLASSPATH + class name so it will be CLASSPATH+PackageName/ClassName. On UNIX you have to use the terminal command: export CLASSPATH=/Users/macbookpro/Documents/java-bootcamp/ for example
Normally once the class files are created and we wanted to share the class files externally in the form of a library, we would create a library and we would share the JAR file. The JAR file only has the class files.

Sub-packages
Packages help to meaningfully organize our classes. Sometimes in large projects, a single package can have numerous groups of classes that perform some specialized functions. These groups of classes can be more meaningfully be organized into subpackages eg java.util & java.util.concurrent
import java.util.* only imports classes in the java.util package and not any of the ones from its subpackages.
If you want to import a subpackage, the full subpackage name should be specified so in the example of java.util and java.util.concurrent, if you want to use subpackages in concurrent, you have to explicitly import them

import java.util.*;
import java.util.concurrent.*;

How should we name packages?
Use the organization's reverse internet domain name
    eg edu.stanford.math.geometry vs com.oracle.math.geometry
Component Naming Conventions
	  components in packages should consist of lowercase alphabets, rarely digits
	  should be short, less than 8 characters
	  should have meaningful abbreviations eg util for utilities
	  acronyms are fine eg awt for Abstract Window Toolkit
	  generally a component should be a single word
	  Never start with java or javax as these words are used with the standard java API.

Note on ClassPaths
If classpath is set, java interpreter would scan each of the paths in classpath to run the program specified on the command line. javac command, on the other hand, will not rely on the classpath to compile the program specified on the command line. It will always try to compile the program specified on the command line by looking for that program in the same directory where the javac command is being executed, i.e., if the command is javac HelloWorld.java, then if HelloWorld.java is available in the same directory where this command is executed, then HelloWorld.class will be generated. This is however not the case with java interpreter, which always uses classpath to find the .class file specifed on the command line.

For all non-JDK classes that are accessed from the program specified on command line, both javac & java will rely on paths in the classpath.

Note that classpath can also be set temporarily while running a javac or java command in the following way. The option -cp is followed by the path (C:\java). Instead of -cp, -classpath can also be used. Note that path can also be simply dot (.) indicating current directory. However, if you want to set classpath permanently, then you should set it as environment variable.
eg if Hello.java is in the java folder
javac -cp C:\java\ C:\java\Hello.java

java Hello

Finally, recall that javac will always try to automatically compile any source files accessed from the program specified on the command prompt. If the .class files have already been generated for those files, then javac will still recompile those source files that have a later timestamp than the corresponding .class files, i.e., they have been modified after the .class files were generated.

Strings
String manipulation is one of the most common operations in programming. If you do not have a good understanding of Strings you can write very inefficient code
String class is part of java.lang.String package

String s = new String(); //empty string
String s = new String("hello") // a string is enclosed in double quotes (character literals are in single quotes 'c'.
string literal is a string object. Internally it is passed as an object;
So in the initialization String s = new String("hello!");
s is an object reference to a string object and we are creating by passing another object reference as input to the constructor.

also we can do char cArray[] = { 'h', 'e', 'l', 'l', 'o'};
     	       String s = new String(cArray);

or the recommended way String s = "hello!"; here, s is still a string object reference;
Internally the string class uses a character array to store text. A string in Java is basically a sequence of unicode characters.
Strings are immutable - once created, the value is never changed. So a string object contains an immutable string of unicode characters.
+  operator can be used for String concatenation
All strings created using string literals are saved in a location called String pool. The pool helps save memory by not duplicating strings.eg two strings with the same text inside. This does not happen with Strings created using the new keyword. If you create two identical strings with the new keyword, then there are duplicates created.

String Manipulation
String class
Comparing
Searching
Examining characters
Extract substrings
Case translation
Replace
Split

3rd Party String Utilities
Apache Commons Lang ~ StringUtils
Guava's String Utility Classes

Be aware that they exist and are commonly used; Research before building a new package
TODO: LOOK AT STRING CLASS API

String Pools
String literals are stored in a special area of the heap memory (where all objects reside) called string pool
Identical String literals share same storage. As long as the strings are created during  a single JVM process.
Strings created via the new keyword are stored as regular objects also on the heap section of memory but not in the string pool. They get their own storage and identical strings do not share storage.
When a String is created as a string literal say String s1 = "Hello"; a string object is created in the string pool and s1 stores the memory location of that object. If another string s2 is created with the same literal eg String s2 = "Hello"; then no new string object is created and s2 points to the same memory location of the previously created "Hello" object. Thus s1 == s2 is true.
If another string reference is created but using the new keyword eg String s3 = new String("Hello"); the identical object is still passed to the constructor String() and so it doesn't create a new String object in the pool since "Hello" is already there. Instead, it creates a string object  outside of the string pool pointing to that string object in the string pool. Then the location of this secondary object is passed back to s3. If another string is created with the new keyword again, String s4 = new String("Hello") another separate object is created outside of the string pool, in heap memory. This object still references the "Hello" in the string pool. The location of this object is assigned to the new object reference s4. Thus s3 == s4 is false

In general, when a string is created with the new keyword, first if that string doesn't exist in the string pool, then a new string object is created in the string pool, containing the string literal passed into the String constructor. Then outside of the string pool, another string object is created and this one references the one inside of string pool. The memory address of this secondary object is passed back to the String reference object. Thus, two string objects are created on the heap memory in this case.

So the string pool stores a single copy of each string literal as a string object. The string pool only stores string objects. There is only one copy of string pool on the heap. It is also called string table.
The process of building the string pool is called interning. Each string object in the pool is called an intern
When JVM receives  a string literal for the first time, it creates a new String object with the given literal. Then it invokes the intern() method . The intern method checks if the string is already in the string pool. If it is there, it returns a reference of that existing object. JVM then abandons the newly created object. If string pool doesn't contain the string, then the string object is added to the string pool and returns its reference.
If the same literal is encountered once again, then JVM checks if the intern method was previously called on such a literal and if so returns its reference. JVM always checks if
intern was previously called on a literal.

When two literals are concatenated, their result is interned as the concatenation produces a literal whose value is known at compile time.
so String s = "hel" + "lo"; ->this expression is interned
   String s1 = "lo"
   String s2 = "hel"+ s1; -> not interned. Here variable s2 is a concatenation between a literal and a variable s1. Here, variable s1 is evaluated at run time and so we do not have a literal for it on compile time so this would not result in the creation of an intern and the resulting object would be outside of the string pool. But we can explicitly invoke the intern method on s2 then an intern would be created. s2 = s2.intern(); explicit interning
Explicit interning is not useful unless we are working with many strings eg Natural language processing.
String Immutability
Once a string is created, its value cannot be changed
String s1 = new String("abcd");
       s1 = new String("1234"); // above object "abcd" is abandoned. The references can be reused which is why we could assign s1 to something else
       Why immutable strings? it would affect string interning as one String object reference could alter the shared String object leading to serious errors for the other references.
       Also affects concurrency as multiple threads may be sharing the same string object
       Also creates security vulnerabilities by allowing hackers to alter input strings and gaining access to critical parts of programs.

 String concatenation
+ operator All non-string operands will be converted to String if a string comes first
  eg String s = "hello"+ 1 + 3 -> "hello13"
  but String s = 1 + 3 + "hello" -> "4hello"
Evaulation always happens from left to right for the + operator. Precedence can be set using parentheses.
StringBuilder & StringBuffer - from java.lang package. These two allow us to mutate their StringBuilder and StringBuffer objects
StringBuilder sb = new StringBuilder();
	      sb.append("hello");
	      sb.append(" world!);
	      String s = sb.append(" Good").append(" morning").toString();

Other methods in StringBuilder: length, delete, insert, reverse, replace
StringBuilder is not synchronized - if the same string builder object is shared between two processes, one process can modify a shared string.

StringBuffer is now obsolete. It is slower than StringBuilder because StringBuffer is synchronized. Its API is compatible with StringBuilder.
BEWARE OF THE PERFORMANCE OF STRING CONCATENATION
The + operator is a convenient way to combine a few strings. It should not be used for many strings because it severely affects performance.
This is because with each concatenation the following steps are taking place:
     1. contents of both strings are copied
     2. a new StringBuilder object is created and appended with both strings
     3. the resulting StringBuilder object is then used to create a new String object via the toString() method. The StringBuilder object is discarded
Thus concatenation is time consuming O(n^2), space consuming
RECOMMENDATION: Use StringBuilder instead. O(N) and orders of magnitude faster than + operator. Also twice as fast as StringBuffer

Escape Sequences
A character preceded by \
To use special characters and strings
\", \', \n, \t, \\, \r (carriage return), \b (backspace), \f (formfeed)
\u0041 UTF character code.
Note that the escape sequence is not required to put the " or ' in a string.

Access Levels and Hiding of Information
Access levels provide restrictions on accessing classes and their members.
eg we may want a class to only be accessed by other classes in the same package. We may not want other external classes to create instances of that class.
In most cases, you'd want the class to be accessible to all classes inside and outside of that package.
This is done by using the keyword public in the class declaration. public is an access modifier. eg public class Basics{...}.
If you don't use any explicit access modifiers, then the default modifier is that the class is only available in the package.

Accessibility for Class Members
Inside class - member only accessible within the class that it is defined. For this you use the private access modifier.
Sometimes we want to make a member accessible to other members in the same package, for this we do not use any modifier at all. By default, the members are accessible to all classes in that package but not outside. This is called package-private.
We may also want a class to be accessible to all package members as well as any subclass. Those subclasses may be outside the package too. for this access level, you would use the protected access modifier
Finally we may want members to be accessible to any code regardless of where it is defined - inside or outside package. This is the public access level.
private and public are the most used. protected is rarely used.

Members of a class have additional access restrictions -> private and protected
public and default modifiers apply to both classes and members

private Access Modifier
private member variables can only be defined at class level. any private member variable created inside a method is already private to that method, so this results in a compile error
 eg private int id; // visible only within the class.
void method(){
     private int b; //this causes an error since b is already private to method()
}

You can also make methods private eg private void method() - NOTE THAT THE ACCESS MODIFIER ALWAYS COMES FIRST OTHERWISE YOU WILL GET A COMPILE ERROR

Private MEANS THAT IT IS PRIVATE TO THE CLASS AND NOT PRIVATE TO OBJECTS OF ITS CLASS
eg class Student{
   private int id;
   String name;
}

A PRIVATE METHOD CAN ONLY BE RUN INSIDE OF THAT CLASS

Student s1 = new Student();
s1.id = 1;
Student s2 = new Student();
Here since s1 and s2 are both of the Student class,  they can access each others'
private member id. Any other class beside Student cannot access the id member eg Lecturer etc...
By using access modifiers we can restrict the parts of the code that can be seen outside of the package.

Information Hiding
WE MUST TRY TO RUN GOOD PROGRAMS RATHER THAN FAST ONES. USE GOOD DESIGN PRINCIPLES FIRST
Encapsulation
A language facility that allows bundling of data and methods that manipulate that data. It is done using a class in Java eg
  public class Student{
  	 //variables or data
	 public int id;
	 public String name;

	 //method definitions
	 public boolean updateProfile(String newName){
	 	name = newName;
		return true;
	 }
}

Here, the Student class has allowed us to bundle our id and name data

ENCAPSULATION ALONE DOES NOT LEAD TO GOOD DESIGN
eg for the previous example, the variables are all available to the public. This can lead to tight coupling
Tight coupling
      can't enforce invariant (or range)
      eg for a gender field, we cannot restrict the possibilities to "male", "female" and "transgender" since client code can directly access and change the gender field to any value they wish.
      can't change data representation eg if we want to change one of the variables to a different type, the client code may be affected. We cannot change it without possibly compromising the end user's program. If we have an API for a package, the end user expects that none of the available methods will change for a long time.
      IN PUBLIC CLASSES, USE ACCESSOR METHODS, NOT PUBLIC FIELDS
Accessor methods
	 public class Student {
	 	private String gender;
		public void setGender(String gender){
		       this.gender = gender;
		       }
		public String getGender(){
		       return gender;
		       }
}

1. access modifier for the gender field is set as private
2. we define a public getter (accessor) method eg public String getGender();
3. we define a public setter (mutator) method eg public void setGender();

IDEs try to automatically have you declare getter and setter methods once you declare a private variable in a class.

How do accessor methods help us avoid the problems that come from tight coupling? - now we can enforce invariants by checking the submitted input. if it falls outside of our range, we can reject it and throw exceptions to the client that the argument is illegal. See below:
     public class Student {
      	    private String gender;
	    public void setGender(String gender){
	    	   if(gender.equals("male") || gender.equals("female") || gender.equals("transgender"){
		   this.gender = gender;
		   }
		   else{
		   throw new IllegalArgumentException("Wrong gender passed!!");
		   }
		    }
	public String getGender(){
	       return gender;
	       }
}

We can also change our own internal representations and refactor our implementations without affecting the clients. The code is now loosely coupled. API is the same and there is no access to the backend of the API.

Loosely Coupled Systems
	allow us to develop, test, use and optimize in isolation
	useful code in multiple projects and decreases risk of building large projects.

MINIMIZE THE ACCESSIBILITY OF CLASSES AND MEMBERS
General suggestion is:
1. carefully design a minimal public API of your class.
2. See which of the members will really be needed by client and make them public
3. Make all the others private
4. Make a member default only if really needed
[frequent changes mean you need to reexamine your design!]

Accessibility for classes/interfaces
If possible let it be default. If only one other class uses it, consider making it a private nested class

static, final and Coding Conventions
Writing code in a professional way.
Static methods
Methods can be of two types - instance or static methods. Java is an OOP language so most of the methods we invoke deal with state - instance methods. But sometimes we define utility methods which do not depend on state and such methods are defined as static.
So a class can have only instance methods, or only static methods or both of them.
Static methods have the keyword static in the declaration.
main method is static. All static methods can call on each other as there is no need to have an instance of a class object. Thus main can freely call other static methods in the class to evaluate during its run.
Static methods are class-level methods, they have no access to state ie, they cannot access instance variables/methods. Trying to do so results in a compiler error. However, they can access static variables - these are class-level variables. A static variable declared in a class is shared across all objects in that class. Since static methods do not have anything to do with state, they can directly access other static methods in the class.
Static methods are invoked using the dot method on the class eg className.methodName(), Math.min()
Static methods save heap space as you do not have to create an object. Note that it is legal to invoke a static method on an object reference variable but it leads to misleading code as reference variables are related to objects. eg instead of Math.min() [using the className.method()] we use an object of the math class eg num1.min() [implicitly, the compiler uses the className in that situation.
ENFORCE NONINSTANTIABILIBY WITH A PRIVATE CONSTRUCTOR
If all of the methods in your class will be static, you can make your class non-instantiable by marking its constructor as private - no other code can create an object of your class. eg the Math class in java.lang.Math is created this way so you cannot create an object of the Math class. Math is a class of utility functions - ie static functions.
Math class java.lang.Math
only static method, private constructor (non-instantiable)
commonly used is the random method - Math.random()
returns a double between 0.0 & 1.0 exclusive (never returns 1.0)
so to generate a random integer between 0 and 10 then we do
int rand_num = (int)Math.random()*10

Math.abs()
returns absolute value

Math.round()
rounds argument to the nearest long or int based on the data type of the argument eg Math.round(23.4) -> 23L,
However if argument is FLOAT, IT IS ROUNDED TO NEAREST INT. This is because the two types that Math.round returns are long and int. Long is 64 bits whilst int is 32 bits. double is 32 bits so a double number like 23.4 is returned as a long number 23L. A float is 32 bits, same as integer so it is returned as an integer.

Math.ceil()
returns the smallest whole number double that is greater or equal to the argument eg Math.ceil(4.3) returns 4L Math.cel(10.0) -> 10

Math.floor()
Returns the largest whole number double less than or equal to an integer. Math.floor(24.8) returns 24.0

Math.min() & Math.max()
both take 2 arguments and return minimum or max of the two.

Math.sqrt()
returns the positive square root of a double. Returns NaN if argument is NaN or negative. NaN - not a number (undefined) eg 0.0/0.0 or Math.sqrt(negative number)

Static Variables
declared with keyword static. Independent of any instance of the class.
Declared directly within class. Will result in compilation errors if declared within a method.
They are assigned a default value if they are not explicitly initialized.
Accessibility: if declared with a public access modifier, then any code outside of the class can access it via the class name ie ClassName.variable
Any code inside of the class can access it directly be it static or instance methods. If it has default access (ie not public static but just static), then only classes in that package can access that variable
Static variables are also referred to as Class variables because there is only one copy per class and it is shared across all objects of the class so if one object updates the value of the variable, then all objects will see it. As opposed to instance variables which vary from object to object.
Accessible to static methods in the class, and also to instance methods and constructors of a class.

class StaticExample{
      int instanceVar;
      static int staticVar;

      void instanceMethod(){ // can access static and instance members
      	   instanceVar++;
	   staticVar++;
	   staticMethod();
}

	static void staticMethod(){ // can access only static members
	       staticVar++;
	       instanceVar++; // compile error
	       instanceMethod(); // compile error
	       (new StaticExample()).instanceMethod(); // has an instance of class so ok
}
}

Initializers: Static & Instance
the initializer blocks can be useful for initializing static and instance variables
Static initializer
Can be useful initializing static fields where you need multiple lines to initialize them. eg populating a data structure, initialization with error handling
examples:
	static HashMap map = new HashMap();
	static{
		map.put("John", "203-405-9087");
		map.put("Anita", "222-333-4444");
}
There is no way we could have initialized our static HashMap with these 3 lines and not encounter a compile error.  so the static {...} block helps us to do this

example 2:
	static Stuff stuff;
	static {
	       try{
		stuff = getStuff();
		} catch(Exception e){ ... }
}

In the above case the static {...} block allows us to call on a function to get data and even handle exceptions of that function call before we initialize our static variable.

example 3:
	static Stuff stuff = initializeStuff();
	private static Stuff initializeStuff(){
		try{
			return getStuff();
		} catch(Exception e){ ... }
		return null;
		}

Here we have created a method that we can use to reinitialize the static variable if need be [note - if we are outside of the class we cannot call it directly since in this case it is private]
We can have multiple initializers and they will be excecuted in the order that they appear in our code.
Static initializers cannot reference instance members ie the instance variables or methods

Instance initializer
initializes instance variables the syntax is { ... } so it is the same as the static initializer but has no static keyword.
But constructors initialize state so why do we need instance initializers?
    it is useful when sharing a block of code between multiple constructors
    under the hood, the Java compiler will copy every initializer block into the beginning of every constructor
There can be multiple initializers and they will be executed in the order that they appear
They can also reference static members

So in summary, static initializer blocks help when initialization cannot be done in one line. syntax is static{...}
Instance initializer blocks {...} help when we need duplicate code to be in all the constructors. During compilation, the initializer code will be copied to the top of all constructors. It helps them share code.

final Variables
VALUES MAY OR MAY NOT BE EVALUATED AT COMPILE TIME
sometimes we want the value to remain constant
eg public static final double PI = 3.14159265358979323846;
final keyword implies constant
If it is used with a primitive variable - value is constant
If it is used with a reference variable, then the reference is constant, not the object content itself - this applies to objects eg arrays...thus the array content can be changed, but we cannot assign a new array to the variable as the new array would have a different memory address
(what about final Strings? the object is immutable and so if the reference is immutable as well(final), then it must be constant)
final variables do not get a default value because if it can be initialized once again later, then that goes against the whole principle of final - which is that we want the variable's value to remain fixed forever.
final keyword can be used with instance, local or static variables

final Instance Variable
- constant for the life of the object
- must be initialized in declaration, constructor or instance initializer
- cannot be initialized through a method because if that method is never called, it would never be initialized. In such a case we would run into problems if we need to use that variable at a later point but it was never initialized - so you get a compile error for this.
If declaration lacks an initializer and is initialized later in a constructor or an instance initializer block, then the final variable is referred to as blank final
final local variable is straightforward - once initialized, it cannot be changed (and it has to be initialized at declaration)
final static Variable
These are class variables once initialized it is constant regardless of the number of instances are created. Must be initialized during declaration or during the static initializer block.
Naming convention of static constants -> should be all CAPS_WITH_UNDERSCORE_SEPARATING_WORDS eg private static final int COPY_THRESHOLD = 10;
Constant Variables
Constant variables are a special type of final variable whose VALUE IS KNOWN AT COMPILE TIME
For this reason they are usually referred to as compile time constants
 eg public static final double PI = 3.14159265358979323846;
The benefit of knowing the value at compile time is the compiler can already pre-fill every instance of that variable with the actual value and this eliminates some run time overhead. eg
    int x = Math.PI here PI is a constant (shown above) and at compile time, the compiler can already substitute x with the value of PI so that at run time,  there is not need to check for the value of by going to the Math class first.
Constant variables are final variables with the following restrictions:
	 - needs to be declared with keyword final
	 - data type needs to be primitive data type or String (string obj is immutable so both reference and object cannot be changed as in the case of arrays and other objects)
	 - initialized in the declaration statement itself, not in constructor or initializer or static block
	 - initialized with a compile-time constant expression - value is known at compile time itself. eg primitive literals or string literals
	   final int x = 23;
	   final int x = 23 + 5;
	   final String x ="helo" + "world!";
	   final int z = 5;
	   final int y = 23 + z; //if z is a constant itself then it will be constant
	   if z was just int z then y above would not be a constant;
	   final int w = getValue(); not a constant because the value is evaluated at run time. It may be a final variable but not a strict constant
	   public class Test {
	   	  final int x;
		  public Test(){
		  	 x = 23;
			 }
		}
In the class Test above, x would not be a constant because the declaration is not taking place at the declaration itself. It is happening in the constructor.
public class Test {
                final static int x;
                 static{
                      x = 23;
                         }
		}

Similarly, x is not constant in the above example because it is not being initialized during its static declaration but it is being initialized in the static block. so its value is not known at compile time.
SUGGESTION: use final with local variables only if it is some special constant and it would be worthwhile to highlight it that way

Boxed primitives
Primitives in Java are:
byte
short
int
long
float
double
boolean
char

Each of them has an associated class called a box primitive
The box primitives for the above are as follows:
Byte
Short
Integer
Long
Float
Double
Boolean
Character

These boxed primitives are part of the java.lang package. They are all simply classes. They are called Boxed primitives because they enclose a value
eg Integer data = new Integer(25); or Integer data = new Integer("25"); A boxed primitive is a wrapper class that wraps the primitive.
Uses of Boxed Primitives
useful in converting Strings to primitives eg int i = Integer.parseInt("25");
They also provide useful public static fields eg MAX_VALUE, MIN_VALUE -> this returns the corresponding maximum value for that primitive
Provide utility methods:
	Character: isLetter, isDigit, isLetterOrDigit, isLowerCase, isUpperCase, isWhitespace
	Integer.toBinaryString(int)
	Double.isNaN(double), Float.isNaN(float)
So in summary boxed primitive provide some fundamental methods for each primitive type
Also useful in populating data structures eg ArrayList, HashMaps. This is because we cannot add primitives directly to such structures.
     eg ArrayList = new ArrayList();
     list.add(25); // illegal before Java 5
     list.add(new Integer(25));
     It used to be illegal because a data structure like ArrayList is used to store only object references. So you had to wrap the primitive in a boxed primitive to store it in the ArrayList. In Java 5 onwards we can add primitives to ArrayList because of a feature called autoboxing. With this feature, the boxed primitive is what gets added
Boxed Primitives are also used in Generics when defining Parameterized types eg ArrayList<Integer>
Common Methods for Boxed Primitives
Unwrap:	       int i = (new Integer(25)).intValue(); //other boxed primitives have values like booleanValue() or charValue();
Parsing Strings:   Input is a string and you need to convert it into either a primitive or a boxed primitive. eg if you had to read the order Id of a sales document perhaps you could parse the XML first with a library eg  <orderId>25</orderId>. The extracted value is a string and we want to either an int or an Integer
		   To primitive: int i = Integer.parseInt("25");
		   To boxed: Integer i = Integer.valueOf("25");
the static valueOf() is a standard naming convention for methods that create objects. they are also referred to as simple factories.
To String:   String s = Integer.toString(25); primitive int to String
Wrap: Integer.valueOf(int)  has much better performance than new Integer(25). The reason for better performance is due to the internal caching that the Integer class does. The values in the range -128 to 127 are always cached that is, Integer instances with these values are stored in memory so if you try to create an integer instance in this range using the valueOf() method, then the method would return an instance from the cache ie not creating a new instance. This is similar to String pool where string literals were being cached.

Autoboxing
Prior to Java 5 one had to manually create a box primitive by invoking either its constructor or using its valueOf() static method. In Java 5, a compiler feature called autoboxing was introduced. So the compiler can automatically create a Boxed primitive from a primitive. This means we can directly assign a primitive with a boxed primitive, that is we can assign a literal, directly to an object reference
      eg Integer boxed = 10;
      The compiler does autoboxing in the background -
      Integer boxed = new Integer(25)
There is also auto unboxing:
      eg int j = boxed; which allows a boxed primitive to be assigned to a primitive variable. Here, the compiler is running int j = boxed.intValue()
Method Invocatons
     ArrayList list = new ArrayList();
     list.add(25);
We cannot add a primitive value directly to a data structure like ArrayList but autoboxing facilitates this. Before Java 5, instead of list.add(25), you had to do list.add(new Integer(25));
Autoboxing has made the code less verbose and looks a lot cleaner
Autoboxing allows us to do:
	   void go(Integer boxed){}
	   go(25);
	   Here, autoboxing converts the primitive int to an Integer;
Auto-unboxing allows us to do:
	      void go(int i){}
	      go(new Integer(25));
	      above, the Integer object created is unwrapped back to an int integer
Operations on Boxed Primitives
You can perform arithmetic operations directly on boxed primitives eg
    Integer boxed = new Integer(25);
    boxed++;
    int i = 3*boxed;
Note that autoboxing does not work with arrays
     eg Integer items[] = new int[]{1,2} //compile error
Most likely due to it being an expensive conversion to convert every array element into a boxed primitive
PREFER PRIMITIVE TYPES TO BOXED PRIMITIVES
Time & space efficient - primitive types are faster and do not take up much space.
eg void veryExpensive(){
   Long sum = 0L;
   for(long i = 0; i < Integer.MAX_VALUE; i++){
   	    sum = sum + i;
   }
}
In the above code, we cannot store the final sum in an integer value because it would be too big and so we use a long type to store it. This program will work correctly but is much slower than it should be because of the usage of the Long wrapper class instead of primitive long.
In the code above in sum = sum + i, the + operator has two operands of different types, the boxed primitive Long sum and the primitive long i. Recall that arithmetic operation rule included the operand promotion rule eg if you add a double to an int, the int is promoted to double.
In sum + i, one operand is an object and the other is a primitive. In this case auto-unboxing occurs on sum from Long to long. Then long sum is added to long i. After the addition, the total is assigned back into sum, which is a Long boxed primitive and so the total is autoboxed again and assigned to sum. So roughly 2^31 Long object instances are being created which is a very expensive procedure.
Always use primitives when you are doing intensive operations.

Primitives are simple and have only their values. Boxed primitives are regular classes and have separate identities, that is each box primitive is an object which has a memory address and that memory address is its identity. So two box primitives can have the same value but two different identities.
Thus for Integer a = new Integer(2); Integer b = new Integer(2); a == b is false
A special exception is when boxed Integers are declared using autoboxing and the values of the integers are in the range of -128 to 127.In this range, the reference to the object is collected from the Integer cache of objects (similar to the String pool).\n Thus the two objects would be equal since they point to the same memory address");
eg Integer a = 2; Integer b = 2; [direct assignment of primitive to object uses autoboxing in the background] a == b is true; but Integer a = -129; Integer b = -129; a == b is false
HOWEVER for comparisons, <, <=, >, >= the Boxed primitives are always auto unboxed before comparisons so you won't have that issue. In fact only boxed primitives are allowed with this kind of comparison because of the auto unboxing.
Luckily, you can always use the static intValue() method for example to make sure that you are always getting the value.
Mixed-type computations lead to confusing results.
eg Integer i;
   if(i == 0){
   	System.out.println("i is zero!");
	}
for the above code, you would get a NullPointerException error. This is because, in the comparison, the compiler will look for i and try to unbox it to get its int value but because i is a null pointer not pointing to anything, it would throw the NullPointerException

Coding Conventions
Naming
ADHERE TO GENERALLY ACCEPTED NAMING CONVENTIONS
Typographical conventions - more about appearance eg upper or lower case
Grammatical conventions - more of part of speech eg nouns, verbs, adjectives
packages
	lowercase alphabetic characters, rarely digits
	should be short with 8 or few characters & single words
	should have meaningful abbreviations eg util for utilities
	acronyms are fine eg awt for Abstract Window Toolkit
	never start with java or javax which are used by standard Java API
	use organization's reverse internet domain name
Classes
	 Capitalize first letter of each word
Methods and Variables
	Use camelCase eg getArea, studentCount
	static final Variables should be in ALL_CAPS_WITH_UNDERSCORES
	eg static final int COPY_THRESHOLD = 10; Note that this does not
	apply to final instance or final local variables. Rule only applies
	if variable is primitive.
Abbreviations
	avoid them for Classes, methods and fields
	acronyms are fine
	for local variables, abbreviations and acronyms are fine
	meaningful individual characters are fine eg x, y, z
Grammatical
	Classes
		use singular noun or noun phrase eg User
		keep names simple and descriptive
	Methods
		named based on what their action is
		use verb or verb phrase eg append, calculateDistance
		use descriptive names
		don't hesitate to use longer names
		methods that return a boolean value start with is eg is Digit
		isEmpty(), isActive(), setActive()
		sometimes has is used eg hasLicence()
		Non-boolean methods - use attribute name. Use get and set in
		pairs
		Special methods
		- Object type conversions - use to eg toString, toArray
		- static factory - eg valueOf, of, newInstance, newType
	Fields
		boolean usually adjectives eg active rather than isActive
		non-boolean - nouns and noun phrases
		singular and plural nouns
		name objects of same class by purpose eg
		void sendMessage(User sender, User receiver)
Structuring Programs
Class organization:
      1. variables - static followed by instance
      2. static initializers
      3. static nested classes
      4. static methods
      5. instance initializers
      6. constructors
      7. instance nested classes
      8. methods
Class size
      The Single Responsibility Principle
      a class should not have more than one responsibility
      helps create better abstractions and loosely coupled classes
      helps having fewer lines of code too
      should be less than 2000 lines
Method size
       small and focused
       should do only one thing
       recommended reading - Clean Code: A Handbook of Agile Software
       Craftsmanship by Robert C. Martin
       recommends that methods should hardly ever be more than 20 lines of
       code
       refactor long methods - this promotes software reuse and clean,
       readable code
       group methods with similar functionality
Local Variables
      MINIMIZE THE SCOPE OF LOCAL VARIABLES
      declare a local variable where it is first used
      for loop minimizes the scope of variables so it is preferred over
      while loops
Stylistic conventions
	  beginning brace - end of line
	  end of brace, start of statement
	  indent blocks by 4 spaces (1 tab)
	  wrapping lines - limit line length to 80 characters
	  	   break after comma eg method calls & declarations
		   break before operator eg if blocks, arithmetic ops
	use 8 space rule(or 2-tab)
	When using Eclipse, you can can use the CTRL-Shift-F or
	Command-Shift-F on Mac to format your code

Comments
	provide code overview
	specify non-obvious design decisions
	frequent comments -> poor code quality
	use descriptive method and variable names
	eg int search(int list[], int key){
	       		  sort(list);
			  binarySearch(list, key);
		}
	if developing an API, then you need to provide an overview of methods
	implementation comments and documentation comments
	implementation comments use // or /* */
	/* */ can also be used to disable part of code
	Documentation comments are called javadoc comments
	They start with /** eg /**API details...*/
	If source code includes javadoc comments then a javadoc parser
	can extract the comments and generate HTML from it
Implementation Comments
	       Used inside methods or with private fields
	       3 types - block, single-line, trailing comments
	       block comments
	       	     describe block of code
		     1 or more lines
		     preceded by a blank line
	single line comments
	       short comments
	       preceded by blank line

trailing comments
	 very short
	 appear on same line as code
Documentation Comments
	      should provide an overview of classes, methods and constructors
	      general overview should be provided as javadoc comments and
	      implementation as block comments
Using the javadoc tool
start with /**
put a brief overview of class inside.
Select the files or project you want to generate Javadocs for. Click
Project and Generate javadoc

Introduction to Thrill.io
Thrill.io is a social bookmarking site which will be serving as a case study for the different topics to learn in Java

User Types in Thrill.io and functions
User, EmailAdmin, Editor & ChiefEditor

User functions:

User		: saveWebLink(), saveMovie(), saveBook(), rateBookmark(),
     			postAReview()[needs approval]

EmailAdmin	: saveWebLink(), saveMovie(), saveBook(), rateBookmark(),
		          postAReview()[no approval], handleEmailCampaign()

Editor		: saveWebLink(), saveMovie(), saveBook(), rateBookmark(),
		          postAReview()[no approval], approveReview(),
			  rejectReview()

ChiefEditor	: saveWebLink(), saveMovie(), saveBook(), rateBookmark(),
		          postAReview()[no approval], approveReview(),
			  rejectReview(), updateHomepage()

Inheritence
Each user in Thrill.io can be thought of as a class. Looking at these
classes, it is apparent that they share a lot of methods - all classes
have the following identical behaviors: saveWebLink(), saveMovie(),
saveBook(), rateBookmark()
What does that mean?
It means that we will have duplicate code which leads to a maintenance
nightmare. The solution for this is Inheritence
Inheritence is one of the fundamental features of OOP. We abstract all the common features and place them in one Superclass and the remaining classes become subclasses. Such a design is an inheritence hierrarchy.
Subclasses inherit non-private features from superclasses - variables and methods. In fact subclasses can access superclass members directly without any special operator. A superclass can never access members of a subclass however

Thus the user functions defined above now look like:

User[Superclass]	:saveWebLink(), saveMovie(), saveBook(),
			rateBookmark(),
                        postAReview()[needs approval,
				 this function is unique to
				 User as other user types need no
				 approval]

EmailAdmin		:[inherit from User], postAReview()[no approval],
			 handleEmailCampaign()

Editor			:[inherit from User], postAReview()[no approval],
			 approveReview(), rejectReview()

ChiefEditor		:[inherit from User], postAReview()[no approval],
			 approveReview(),rejectReview(), updateHomepage()

Inheritence promotes code reuse and makes it easy to maintain. If Superclass adds new methods, subclasses will easily inherit them.

Subclasses are specialized versions of super classes
	   inherit members, add new members, override superclass methods
Subclass = Superclass + Subclass unique capabilities
Superclass is sometimes called a supertype or base class
Subclass is sometimes referred to as subtype or derived class
You will notice that even across subclasses, we can apply additional inheritence - they all share the postAReview() method; Editor and ChiefEditor user types both share the approveReview() and rejectReview() methods

    	 	     	  	 User
			______________
			saveWebLink()
			saveMovie()
			saveBook()
			rateBookmark()
			postAReview()[requires approval]

				Staff
			_____________
			postAReview()[no approval needed]

	EmailAdmin				Editor
__________________			_________________
handleEmailCampaign()			approveReview()
					rejectReview()

					ChiefEditor
					_________________
					updateHomepage()

Applying the additional inheritence, we come up with a new design shown
above. Here, an additional class has been created called Staff which is for
the shared postReview() method which staff have which is different from a
regular user by not requiring approval. A subclass will inherit members from all its superclasses.
Extending a Class
A keyword called extends builds inheritence. A subclass would use the keyword to inherit from a superclass. Here are the resulting class declarations
class User{}
class Staff extends User{}
class EmailAdmin extends Staff{}
class Editor extends Staff{}
class ChiefEditor extends Editor{}

A CLASS CAN EXTEND FROM ONLY ONE CLASS

Access Modifiers & Inheritence
What members of a superclass can be accessed by its subtypes?
Classes in a package are like a family. Access modifiers allow us to specify what data and methods are available to family members (classes in the same package) versus non-family members (classes outside of the package)
Inheritence Accessibility:
	    private - NEVER INHERITED
	    default - inherited IF FROM FAMILY(same package)
	    public - inherited by anyone
	    protected - inherited by family members (same package)
	    	      - inherited by subclasses inside and outside of
		      	package
			[once inherited, the member should not be available 
			to any non-family member]
How would you know which of the classes should be a superclass and which
should be a subclass?
Blindly creating inheritence relationships could be dangerous. There are
a few tests we can use to determine  the best way to design the inheritence
relationships.
The Is-A test is one such test. It is the most fundamental test for inheritance

eg Staff IS-A User
   Editor IS-A Staff
   Editor IS-A User (automatically valid due to the previous test)
   EmailAdmin IS-A User
   EmailAdmin IS-A Staff
   ChiefEditor IS-A User
   ChiefEditor IS-A Staff
   ChiefEditor IS-A Editor

The Is-A relationships works in one direction eg Staff IS-A User but User is not a Staff as we know that a Staff has some more specialized functions that
are not available to a User

There are other tests that you should apply
If the IS-A test is failing for a relationship, that means that you must
definitely not use an inheritence relationship
eg Bookmark IS-A Review
   Review IS-A Bookmark

However
   Bookmark HAS-A Review -> yep
A HAS-A relationship is also known as composition. In some cases, composition
is preferred over inheritence

   Bookmark IS-A Tub -> NO
   Tub IS-A Bathroom -> NO
   Bathroom HAS-A Tub -> yep

Polymorphism
Defining Contract
Every class defines a contract through its methods. That is it announces
the kinds of methods it has. If the class is public, then the contract is
the API.
If the class is a superclass/supertype, its contract is defining a common protocol for itself and all its subtypes -> Me & my subtypes have these kinds
of methods...
By defining these common protocols for its subtypes, the supertype is 
providing the benefit of polymorphism. What are these benefits?
With polymorphism, a supertype can be assigned any of its subtypes ie
Supertype = subtypes
So if we have a method in the supertype void updateProfile(User u) and User is the super class to Staff, Editor and ChiefEditor, then we can call the
updateProfile method with all any of the instances of the subtype objects eg
updateProfile(Staff s) or updateProfile(Editor e) or updateProfile(ChiefEditor c). All the objects of the subtypes can substitute the supertype's object instance (User u) in this case.
The substitution for the supertype's instances can take many forms and hence
the term polymorphism. In the example above, the method parameter is a
polymorphic reference[note that event the method return type can be a 
polymorphic reference].
This means that we can have one method in the supertype class which we can 
reuse in all the other classes. - MORE FLEXIBLE & LESS MAINTENANCE
This also leads to MORE REUSABLE CODE and LESS OVERALL CODE in general
If more subtypes were to be added in the future, our methods would not need to be updated
Being able to substitute the supertype's object instance means that in 
polymorphism, the reference type and actual object type can be different eg
User u = new EmailAdmin();
the reference type is the supertype User but the actual object type is EmailAdmin, a subtype of User.
Now that the reference type and the object type can be different, we need to
understand the possibilities and limitations with regards to method invocation
- compiler uses reference type to decide whether a method can be invoked

eg User u = new EmailAdmin();
   u.handleEmailCampaign(); // gives compile error
This is because the compiler knows that the User class does not have this method.
But at run time, JVM uses the actual object type to decide which method is invoked and invokes the most specific version of the method in the inheritence tree. It starts in the actual object's class and searches up through its supertypes till it finds the method then excecutes it.

Casting Objects
Primitive casting
	  implicit[when destination type > current type] eg float f = 25;
	  explicity[when destination type < current type] eg int x = (int)42L
	  
In polymorphism we are able to pass a subtype object as an alrternative argument to the method parameter which is of type superclass.
This is basically implicit casting in action that is the subclass object is
implicitly cast to the supertype variable
However, once implicity casting is performed, we can only perform those 
methods that are defined in the superclass. Any methods specific to the subclass are no longer valid eg
	Staff s = new Editor();
	s.approveReview(); // compiler error
This is because the compiler uses the reference type to decide whether a method can be invoked or not.
In order to be able to use the subclass methods, we must explicitly cast the supertype object eg ((Editor)s).approveReview();

Another example of explicit casting:
	void approveReview(Staff s){
	     ((Editor)s).approveReview(); // runtime error
	}

This causes a ClassCastException because Staff is a broad class that includes other subclasses of which Editor is a part of. But Staff is not an Editor.
The last two examples can also be thought of in this way: 
in Staff s = new Editor(); the object reference type is a Staff object reference but the actual created object is an Editor object thus when we use explicit casting ((Editor)s).approveReview(), the object instance actually has these methods.

In void approveReview(Staff s){
   ((Editor)s).approveReview();
}, the passed object reference points to a Staff object so even when we 
typecast this one, it doesn't contain the approveReview() instance method. Thus we get a runtime error.

To avoid this runtime error, we can perform a logical test before doing the cast. Syntax:
   objRef instanceof aClass
The instanceof operator returns a true if the object referenced by the objectRef on the left is an instance or subclass  of Class on the right. Thus it is the object
reference's object type that matters, not the reference type
It doesn't have to be a diect instance of the class on the right

User u = new User();
Staff s = new Staff();
User usr = new Staff();

for the above: u instanceof User -> true
    	       u instanceof Staff -> false
	       s instanceof Staff -> true
	       s instanceof User -> true
	       us instanceof User -> true
	       us instanceof Staff -> true

Updated approveReview() method:
	void approveReview(Staff s){
	 if(s instanceof Editor){
	      ((Editor)s).approveReview();
	 } 
	}

thus approveReview(new Staff()) -> cannot aprove
     approveReview(new Editor()) -> can approve
     approveReview(new ChiefEditor()) -> can approve
Java is referred to as a type safe language.
This is relevant when casting objects. A lot of the compile time and run time
errors we encounter when working with objects are due to the result of applying type safety rules
Type Safety is the extent to which a programming language prevents type errors. These errors can lead to undesirable program behavior eg invoking a non-existant method on an object eg the class staff has no approveReview() method so our program should not allow us to do staff.approveReview()
Buffer overflow - usually occurs in languages like C & C++. It is an out of bound write operation. eg char data[6] = "hello"; if we try to insert a character outside of the character array data's range it should be invalid ie
data[6] = 'p'; In a type-unsafe language, this can overwrite data in the next
memory location. This corrupts the data.
A type safe language will try to avoid these errors
Java enforces type safety at both compile time (static-type checking) & runtime(dynamic-type checking)
C does static type-checking while Ruby & Python do dynamic type checking
Static Type checking examples
int i = 233.3; // compile error [larger type to a smaller type]
we have to insert an explicit cast for it to work int i = (int)233.3;
we also cannot invoke a non-exixting method eg Staff s = new Editor(); s.approveReview(); // Staff class does not have approveReview() method
The solution once again is to use an explicit cast ((Editor)s).approveReview()
Generics are all about type safety at compile time. Before generics, many of the errors were only caught at run time. But since the introduction of generics in Java 5, many of the errors were now caught at compile time itself which is more desirable as run time errors can be disastrous.
Dynamic type checking
ClassCastException
	void approveReview(Staff s){
	     ((Editor)s).approveReview(); //runtime error - Staff object cannot be cast to Editor type
	     }
	     approveReview(new Staff());

ArrayIndexOutOfBoundsException
	char[] data = { 'h', 'e', 'l', 'l', 'o'};
	data[5] = ''; //runtime error - outside of array boundary

Note that since statically checked languages do all the checks at compile time, they tend to be faster than dynamic languages which have to do all of the
tests at run time
Strong vs Weak Typed Systems
No standard definition for strong or weak typed systems.
Some agreed upon definitions are:
     strong typing - no loopholes in type system
     weak typing - some loopholes and can be subverted
C is considered to be weakly typed as it seems to have loopholes.

Method overriding
Redefining behavior of superclass method
 eg defining new behavior, extending behavior, providig better implementation (override bad code) eg when working with third party software you may have
 to create a new class which extends the one with the method you want to override then rewriting the method
Overriding method must have the same name.
The supertype provides a common protocol for all its subtypes so when you override a method in the superclass, you are agreeing to fulfil a contract ie you are telling the outside world that the overriding method looks exactly like the overwritten method. Method overriding has some rules that are based on
this notion of fulfilling the contract.
rules:
	must have the same name (as always)
	the parameters should be kept the same(SAME NUMBER AND TYPE)otherwise
	it is an overloading method
	the return types must be compatible -> return type must be the same 
	or must be subclass type [incompatible return type = compile error]
	overriding methods must at least be as accessible as the overriden
	method. - access level must be the same or friendlier eg cannot
	override a public method and make it private.

super Keyword
 can be used to access a superclass method from a subclass. Typically used
 for extending behaviour defined in superclass. If the method in super class is not overridden in subclass, then it can be accessed directly using the method name or via the super keyword - typically we use the simple method name. But if the method in the superclass is overridden but we want to access it, then you must use the super keyword eg
 class Staff extends User{
       void postAReview(){
       	    super.postAReview();
	    // behaviour extension code
       }
}
	
NOTE: we would get into an infinite loop if we do not use the super keyword in the above method
After invoking the superclass method, we can now have additional code
thus extending the behaviour defined in the superclass method. Sometimes,
you will need to access the overridden mehtod from other subclass methods as well
The super keyword is related to objects so it CANNOT BE USED inside a static
method. 
The super keyword can also be used to access a hidden field belonging to the superclass. It is hidden if a variable with the same name is defined in the subclass. Note that it is only variable name that matters here to hide a field, everything else like data type, static or non-static, access modifier is immaterial. If a class does not use the super keyword, it will always use a field in its own class.
eg id will access the id of the current class instance whereas super.id will access the super class id.

Method Binding
The compiler looks at the reference type to know whether or not we can call a particular method on an object reference. JVM on the other hand looks at the actual object type to know which method to execute at runtime. We have discussed it so far in the context of instance methods. What about static methods?

Binding is associated with every method call. It occurs everytime we call a method. It is the mechanism of binding the method call to the method declaration and method implementation of the method being called. Method declaration is the method signature while method implementation is the method's body which gets executed at runtime. Thus a method call is associated with the method signature and its implementation and they are the two steps of method binding. They are also called method signature binding & method implementation binding

Method Signature Binding
1. compiler checks if the reference type of the object reference on which the method has been called has a compatible method which would include the same or compatible parameters
2. if it finds one, then it writes the method signature details into bytecode, OTHERWISE it throws a compiler error
This is method signature binding and it is always done regardless of whether the method is an instance or static method.

Method Implementation Binding
Then it is a question of which method to execute at run time, the decision can be made by either the compiler at compile time or JVM at run time, depending on the method in context.
If the method is static, then the decision is made by the compiler based on reference type. 
If the method is an instance method, then the decision is made by JVM based on object type. Recall how JVM starts with the most specific object and goes up the tree when looking for a method to run.
Basically, binding of static methods is completed at compile-time[static methods are compile-time or early binding]. This makes sense because static methods are class methods and have nothing to do with objects which are created only at run time.So the decision of which static method to execute is done at compile time itself - compile time binding/early binding
Binding of instance methods has to wait till run time as it is based off the object type, that is only based off the object encountered at run time will JVM be able to know which method to execute. Such a binding is called runtime or late binding. Note that even for instance methods, their signatures are still bound at compile time itself.
Field Binding
Whilst instance methods are late bounded, instance fields or variables are early bounded that is reference type is used to bind instance variables.
So in Java, early binding applies to both static methods and fields(static or non-static)
javap -v Hello.class can be used to show the bytecode of a compiled class
You can see in the bytecode that there are commnands such as invokestatic or invokevirtual
invokestatic is an instruction that we are using a static method
invokevirtual is when we will be calling a an instance method which will be decided at run time.But it can be seen that the method's signature binding is already done by the compiler and it shows the parameter type and the return type of hte function as well. 
At runtime, when JVM encounters the invokevirtual instruction, it already knows about the method signature because it is there in the byte-code so it looks at the object type and it searches the class corresponding to the object type and searches and tries to find that particular method and if it finds it in the same class, it executes it. Otherwise it will climb up the inheritence tree until it finds a method. So this is how it finds the most specific method to that object.
Edge case
Early binding by the compiler can lead to some unexpected results when there are two overriding methods with compatible types eg if we have a superclass User and a subclass Patient and both have a printNumber() method - one taking a double and the other taking an int see below
public class User{
       public void printNumber(double n){
       	      System.out.println("Double!);
       }
}

public class Patient extends User{
       public void printNumber(int n){
       	      System.out.println("Int!");
	}
}

if we have the following code elsewhere:
User p = new Patient();
p.printNumber(5);

We expect the Patient class's function to be called since at runtime, JVM starts with the most specific object that has the function that is being called on the object instance. However, during compilation, the compiler has already prefilled the method signature and left a invokevirtual command in the byte code. This invoke command will wait on the object encountered by JVM at runtime but the prefilled function signature will have been based off the compiler checking the reference type of the object -> User then checking that class to find a compatible method. It will find a method with the same name printNumber but a different parameter type - User class printNumber takes a double. However, because the numbers are both numeric and are thus compatible, the compiler prefills the bytecode with a printNumber function that expects a double as the parameter. 
Now, at run time, JVM will look for the specific Class which gives the object its type and in that class it will look for a function based off of the prefilled bytecode function provided by the compiler. And so JVM will look for a printNumber functiont that takes a double as parameter. In Java the double needs to be explicitly cast to work with an integer so JVM will not use this ffunction and deem it as incompatible. It will search up the class inheritence tree until it finds the printNumber function in the User class and execute that.

What is not Overriden?
There are 3 things that cannot be overriden:
      1. final methods: normal method declared with keyword final
      	 eg final returnType methodName(){}
      2. fields/static or instance variables - We can redeclare a variable
      	 with the same name but the superclass variable of the same name is
	 only hidden. Why are instance variables not overridden like the
	 functions?
	 When it comes to behavior it makes sense to pick the most specific
	 type of behavior with respect to the object context. The same 
	 does not hold for fields as whatever value the data has in whatever 
	 class should be good enough. No need to go down the hierrarchy and
	 pick a more specific value. Thus instance variables are also early
	  bounded. If instead of redeclaring, the subclass simply reassigns
	   the value, then we will see that value as there is only one version of that value
      3. static methods - static methods are bound and set at compile time so by the time JVM is executing, it cannot pick another more specific static method.

Static Methods & Overriding
Can't use super keyword -> only qualifies to objects. If you need to access a
hidden superclass method, then you need to qualify the method name by the superclass name ie User.staticMethodName()
Static methods can't hide an instance methods - static means no state and you get a compiler error if you try this.
Static methods cannot be overridden by instance methods and you also get a compiler error if you try this.

The Object Class (java.lang.Object)
Mother of all classes ie superclass of everything
Why have an Object class?
    acts as polymorphic type that allowed Java designers to create classes with methods of any type that never existed when they first wrote those classes
    includes core methods that are inherited by every class since the Object class is the highest class. Some of these methods can be overriden and some are marked as final and cannot be overriden.

Core methods
     toString() - returns a string representation of the object
     		- by default it includes the class name and a weird number 
		- ALWAYS OVERIDE THE toString method - this method is very
		useful in debugging
		- toString() is automatically invoked when an object 
		reference is passed to the System.out.println() statement - 
		no need to invoke it explicitly, println() does it for you
      hashCode() - returns object's hashcode (memory address in hexadecimal)
      		 - used in hash table
      equals(Object) - tests object equality
      		     - by default, it uses == operator so you may want to
		     overwrite it eg equals(Object user) { return this.id == 
		     ((User) user).getId(); }
      getClass() - final method that returns Class object which encapsulates
      		 all the meta information about classname, superclass name, 
		 methods...
      clone() 	 - returns a copy of this object. Is a protected method and
      		 must be overriden to use its functionality

Constructor Chaining
Motivation - we know that subclasses inherit methods from superclasses and those methods might depend on superclass state, that is the instance variables
defined in the superclass. 
So it means that superclass state should be initialized first. Otherwise, you may call on an inherited method which might not work as expected as the state in the superclass is not yet initialized.
Thus a subclass state must be initialized after all its superclasses are initialized, including the Object class
Constructors are used to initialize state, meaning that all the superclass constructors should run before the subclass constructor runs. This is what 
constructor chaining does.
When first creating an object it first runs the constructor code but due to constructor chaining, the first thing that an object does is to first invoke
its constructor which in turns calls its own superclass constructor. This process continues until class Object's constructor is run.
Constructor chaining happens every single time you create an object
super keyword invokes a superclass constructor but we now use it followed by parentheses which may have zero or more parameters eg super();
The important thing is that the super(); invocation statement call must the the first statement in the constructor UNLESS a this invocation statement is used (remember this() is to invoke overloaded constructors)
A CONSTRUCTOR CAN HAVE this() OR super() BUT NEVER BOTH. Thus if there are multiple overloaded constructors, then the last invoked will call super
-if not provided, the compiler will insert a super(); on top of the constructor

If a superclass constructor cannot be invoked -> compiler error
class User{
      User(int id){
      }
}

class Staff extends User{
      Staff(int id){
      }
}

Since both User and Staff classes already have constructors, the compiler will not insert the default no-args constructors in any of them so the above code will give a compiler error because the compiler will not be able to add a no-args super(); invokation statement within the Staff's constructor as there is no default constructor in the User class [User class' constructor asks for an int to be provided].
This problem can be rectified by either adding a no-args constructor in the
User class User() {} 
OR adding a line in the Staff constructor:
   Staff(int id){
      super(id);
   }
The super(id); invokation statement will begin the constructor-chaining and be able to use the id as a parameter in the User constructor.

Preventing Inheritence
How can we prevent it? You want your class to be the final version. You do not want your methods to be overriden, you want them to work in the exact same way as you implemented them. You may not want any subclasses to be created as they may affect the semantics(invariants) of your class eg String, an immutable class which was designed that way by preventing inheritence altogether
    MINIMIZE MUTABILITY OF CLASSES AS MUCH AS POSSIBLE
2 Ways of preventing inheritence:
  - final class INSTANTIABLE BUT NOT EXTENDABLE
  - private constructor NOT INSTANTIABLE NOT EXTENDEBLE

    final ClassName{...} - class can never be extended, none of its methods can be overriden. final class is still instantiable eg String class
The final keyword still allows instances to be created which helps in defining state as well as defining instance methods that can work on that state. String method can be used to initialize some text and there are some methods available to manipulate that text.

    private Constructor - not extendible, not instantiable eg utility classes like Math. Saves heap space as it is meaningless to create instances when all the methods are static. Not extensible because the constructor cannot be invoked from the subclass thus there can be no constructor chaining and no subclass.

New Requirement: thrill.io for kids - add a new tab for bookmarks relevant to kids 
Specifics:
	- editorial staff must approve a bookmark as kid friendly
	- if link IS kid friendly and needs approval it should have
	 a "Mark as Kid Friendly" link
	 
				Bookmark
			------------------
				id
				title
				description
				profileURL
			- - - - - - - - - -
			  generateProfileUrl()
			  isKidFriendlyEligible()



Weblink				Book				Movie
-------------             ------------------             -------------------
generateProfileUrl()	  publicationYear			releaseYear
isKidFriendlyEligible()   publisher				cast
			  authors				directors
			  genre					genre
			  - - - - - - - - - -	         - - - - - - - - - - 
			  generateProfileUrl()		 generateProfileUrl()
			  isKidFriendlyEligible()     isKidFriendlyEligible()


Note that the bookmark superclass has the functions generateProfileUrl() and 
isKidFriendlyEligible() even though they are overriden in the subclasses.
the generateProfileUrl() generates the category of the bookmark eg movie/, link/ or book/ then for the rest of the Url, the method in the subclass is invoked to generate more specific and appropriate details
the isKidFriendlyEligible() in the Bookmark superclass determines the base requirements to determine whether a bookmark could be kid friendly. However, the Bookmark class' method is too generic to go into the different details so each subclass then goes into more specific determinations by overriding the Bookmark class method. However, the method is still present because it helps in defining a contract in the subclasses, that is a common protocol for subclasses that is important for polymorphism

Technical requirements
- Bookmark should be non-instantiable. Too generic. All bookmarks should fall into one of the 3 subclass categories only [private constructor doesn't work because we need inheritence so we need somehting new]
- better representation for isKidFriendlyEligible() within the Bookmark class - a way to indicate that the method is too abstract to have any implementation

Abstract Classes & Methods
Abstract class signifies abstractness - too generic to be instantiated but defines a common protocol for subclasses. NOT INSTANTIABLE BUT EXTENDABLE
abstract class Bookmark{ ... }
abstract method: abstract returnType functionName(); Note that an abstract method has no implementation thus no function body.
an abstract method MUST be overriden thus it cannot be declared as static

Abstract class has no use unless it is extended. [Abstract classes have constructors which are called in constructor-chaining, but no objects can be created out of them. If they did not have a constructor, they could not be extendable] It is the subclasses and their instances that are doing the real work at runtime.

Cannot have an abstract method in a non-abstract class. However an abstract class can still have concrete methods. You can also have an abstract class without any abstract methods but that is not typical and is confusing.

Abstract Subclass
Need not override inherited abstract methods. Does not even need to redeclare them. Some other subclass would be expected to provide an implementation for abstract methods
Like an abstract class, it can still define abstract and concrete methods. An abstract can override inherited methods whether or not the inherited method is abstract.

Concrete Subclass
Non-abstract classes MUST override all of the unimplemented abstract methods. Some of the abstract methods might have been implemented by one or more superclasses in inheritence tree. Only the others not implemented must be implemented.

abstract class AbstractSuperClass{
	 abstract void test1();
	 abstract void test2();
}

abstract class AbstractSubClass extends AbstractSuperClass{
	 //override
	 void test1(){
	      System.out.println("test1");
	      }
	abstract void test3();
}

public class ConcreteSubClassClass extends AbstractSubClass{
       //override
       void test2(){
       	    System.out.println("test2");
       }
       
       void test3(){
       	    System.out.println("test3");
       }

       public static void main(String...args){
       	      ConcreteSubClass concrete = new ConcreteSubClass();
	      concrete.test1();
	      concrete.test2();
	      concrete.test3();
	      //AbstractSubClass absub = new AbstractSubClass() // compilation error as abstract classes are non-instantiable
	      //AbstractSuperClass ab = new AbstractSuperClass() // compilation error as abstract classes are non-instantiable
       }
}

PREFER CLASS HIERARCHIES TO TAGGED CLASSES
       	     		<<   abstract   >>
                                Bookmark
                        ------------------
                                id
                                title
                                description
                                profileURL
                        - - - - - - - - - -
                          generateProfileUrl()
                          isKidFriendlyEligible()



Weblink                         Book                            Movie
-------------             ------------------             -------------------
generateProfileUrl()      publicationYear                       releaseYear
isKidFriendlyEligible()   publisher                             cast
                          authors                               directors
                          genre                                 genre
                          - - - - - - - - - -            - - - - - - - - - -
                          generateProfileUrl()           generateProfileUrl()
                          isKidFriendlyEligible()     isKidFriendlyEligible()

Tagged class
Instead of having multiple subclasses with a set of shared fields inherited from superclass and more specific fields declared within the subclasses themselves, a tagged class has all the fields in it but determines which ones to instantiate and which ones to ignore during construction eg

public class Bookmark{
       private String title;
       private String author;
       private String directors;
       private String bookmarkType; // tag field
       
       public Bookmark(String title, String author){
       	      this.title = title;
	      this.author = author;
	      this.bookmarkType = "book";
       }

       public Bookmark(String title, String directors, String cast){
        this.title = title;
	this.directors = directors
	this.cast = cast;
	this.bookmarkType = "movie"
       }

       public void isKidFriendlyEligible(){
              if(bookmarkType.equals("book")) { //code specific to book }
	   else if(bookmarkType.equals("movie") { //code specific to  movie }
        }
}

Tagged classes are verbose - multiple constructors, too many fields, too much
logic in one single method. It is error prone as too many things are represented. Recall that classes should be designed with the single responsibility principle. It is also inefficient as any object regardless of its type will include some irrelevant fields and thus have a larger footprint eg a Book object will still allocate memory for the variables directors and cast.

Tagged Class refactored to Class Heirarchy:
       	     		   << abstract >>
			   Bookmark
        ------------------------------------------------
			   title
	-  - - - - - - - - - - - - - - - - - - - - - - -
	<abstract method> isKidFriendlyEligible()

	Book						Movie
----------------				----------------------	
  authors					    cast
- - - - - - - - 				    directors
isKidFriendlyEligible()			        - - - - - - - - - - - -
						isKidFriendlyEligible()

No more irrelevant fields and clearer. It now has better design and more flexible. eg if we wanted to add an Ebook type, we would have to add more code to our tagged class making it more complicated. With class hierarchy we would create another class Ebook which can be a subclass of Book. So we wouldn't have to change code in any of the superclasses but only in the new class itself.

NEW REQUIREMENT FOR THRILL.IO
Share kid-friendly Books and WebLinks with partner site goodsnips - sharing only kid-friendly Books or links
Only editorial staff should be able to do this.
We need to have a function getItemData() that returns the necessary information to goodsnips

Technical requirement:
	  define a common protocol for defining optional capability
	   - define the same function only in Book & Weblink. The other 
	   classes have nothing to do with it
	  at the same time we also want a common protocol between them
	  rather than have multiple versions which will further multiply
	  as more class types could need that same functionality later.
One way to achieve this is via Multiple Inheritence
Multiple Inheritence & Diamond Problem
You can have another superclass and have some subclasses extend multiple
superclasses whilst others only extend one. In our case we could have another abstract superclass called Shareable which has our common protocol getItemData(). Book and Weblink classes would extend Shareable and still extend the original abstract class Bookmark.
With this multiple inheritence we have our common protocol or contract specified by our superclass Shareable, then we have that protocol overidden only in the relevant classes
However, in Java each subclass can extend only one superclass. Java doesn't support multiple inheritence. It does not support it because it can lead to the diamond problem (deadly diamond of death)

	    	      	       Bookmark
			   ---------------
			   isKidFriendly()
	Book						Movie
---------------				   	------------------
isKidFriendly()					 isKidFriendly()
			MovieAndBook
	  	----------------------------------------
		which version of isKidFriendly() is here?

The programming language will need to support some complicated programming
rules to support this ambiguity. Java is designed to be simple so it avoids this problem by doing away with multiple inheritence completely. 
Multiple diamond problem not only applies to methods but to shared state as well. Imagine if there is an extended instance variable i which has different integer values across the different classes. What is the state in MovieAndBook?

So since Java doesn't support multiple inheritence, how can we solve the puzzle we have of having a common protocol for defining optional capability? ie have a getItemDate() in only Book & Weblink? 
The answer is Interfaces.

Interface
An Interface is a reference type.
Can never be an object type ie, non-instantiable. In that sense it is like an abstract class which can also never be an actual object. Note that the term
type is often used to refer to a class or an interface
Defining an Interface:
	 public interface InterfaceName{ ... }
just like a class, an interface can also have default access (available only to family members/same package classes)
eg interface InterfaceName { ... }
Thus classes and interfaces can only have either default or public access levelss
An interface can include:
   - static constant fields -> that is static fields declared with final modifiers eg static final int field
   - abstract methods -> that is methods with no bodies
   INTERFACES ARE MOSTLY ABOUT ABSTRACT METHODS. Prior to Java 8, an interface was considered as a 100% pure abstract class, that is it would include only abstract methods. Subclasses of an interface would override all abstract methods defined in an interface
   - default methods - concrete method
   - static methods - just like static methods we have for classes
   - Nested types -> nested classes or nested interfaces
IN GENERAL, IT IS MOSTLY ABSTRACT METHODS THAT YOU WILL SEE IN INTERFACES
ALSO NOTE THAT ALL MEMBERS OF AN ABSTRACT CLASS ARE IMPLICITLY PUBLIC

For our requirement of having a capability shared by the Book and Weblink class we can define an interface like so:
    public interface Shareable {
    String getItemData();
}
Note that by the default of the interface, the method is both public and abstract. That is why public and abstract modifiers were omitted above.
All fields declared in the interface are by default public, static and final so the public, static and final modifiers do not have to be included explicitly. In fact, as a matter of style, it is discouraged to specify the default modifiers in the Interface.
All interface members are public by default so you cannot use either private or protected modifiers with members. 
If members are to have access only within the package, then the public modifier should be omitted in the interface declaration. In that case the public access of the interface would no longer apply and those members are not visible outside of the package. So basically the default public access of members in an interface is overriden by the default access level specified in the declaration
Implementing Interface
public class Book extends Bookmark implements Shareable{
       public String getItemData(){ ... }
}

public class WebLink extends Bookmark implements Shareable {
       public String getItemData() { ... }
}

for Interfaces we use the keyword "implements"
The interface can also be used as a polymorphic reference type. Using the interface gives us the polymorphic benefits of multiple inheritence
    Shareable obj = new Book();
    Bookmark obj = new Book();

A class can implement multiple interfaces
eg public class Book extends Bookmark implements Shareable, Comparable {
   	  public String getItemData(){ ... }
	  public int compareTo(Object o) { ... }
}

An interface can also extend another interface
public interface List extends Collection{
...
}
Just like when subclasses extend superclasses, sub-interfaces also add some specialized behavior
A class that implements a sub-interface has to implement all the abstract methods declared in both the sub-interface & the super-interfaces. It should be noted that a class can only implement an interface, it cannot extend it since an interace is non-instantiable. However, unlike classes, an interface can extend multiple interfaces eg public interface Train extends Commuting, ModesOfTransportation{ ... }
If an abstract subclass implements an interface, it need not implement the abstract methods declared in the interface
A class can implement multiple interfaces with the same abstract methods but we would not have the diamond of death problem because abstract methods are merely the outlines of the function declaration. The class itself is forced to decide how to implement and override these functions.

Why fields are static & final
    static?
    - interfaces cannot be instantiated thus they cannot have instance variables so the fields have to be static and can be called by qualifying the field names with the interface name eg Shareable.homePage;
    final?
    - so we avoid the diamond problem that is caused by shared state
    
    Inheriting identically named variables from 2 different supertypes [remember that type can mean class or interface] -> in this case merely calling the field, in the subclass causes an error ie if we inherit a variable int VAL [implicitly static final constant if from interface] from two supertypes, we cannot just call it using the field name, we have to fully qualify it by calling it via the type name eg B.VAL [notice that VAL is all caps as it is a static final constant]

Interfaces: A conceptural view. 
When do you use an interface or an abstract class?
The confusion: if an abstract class has only abstract methods, then it is no different from an interface. With Java 8, interfaces can now include concrete methods so they do not seem to be different from abstract classes. When do we use either one?
In general interfaces can be classified into 2 types:
   - representative interfaces
   - mixins
Representative interfaces
- define behavior that exemplifies subclasses. That is the interface methods show the core functionality of subclasses. Such interfaces typically come with one or more implementations
Mixins
- define additional capability of subclasses. This is when subclasses have their own identity but they are announcing that they also support additional capabilities that the interface is defining eg the Shareable interface
- very generic as subclasses can come from anywhere

- IN GENERAL, even though interfaces can represent the core functionality of the subclasses, they are typically used to announce new capabilities via mixins

eg public class Book extends Bookmark implements Shareable, Comparable, Cloneable{ ... }

From a naming standpoint, Mixins typically end with the suffix -able

PREFER INTERFACES TO ABSTRACT CLASSES
interfaces are ideal for defining mixins. Mixins are capability add-ons and because of this, a class might want to support many of them. If we use an abstract class, then it cannot be extended by the classes that already extend another class. So if you use abstract classes as mixins, a subclass can only support at most ONE mixin but there are no limitations with interfaces
- if the type is defining representative behavior but with no state involved, the mixins are better since interfaces are stateless
THE KEY OF WHEN TO GO WITH INTERFACES IS WHEN YOU WOULD LIKE TO FACILITATE 
MULTIPLE INHERITENCE

WHEN SHOULD WE PREFER ABSTRACT CLASSES?
When a class is defining the core identity of its subclasses that is representative behavior with state. We cannot use an interface as it is stateless
Abstract classes can be used to provide a skeletal implementation of the interface - that is they would implement the interface and provide some form of basic implementation - programmers can extend this implementation for other uses. No need to reinvent some logic. Thus the abstract classes would implement an interface minimally and show some direction to a new programmer looking to use an interface.
There is a naming convention that a skeletal implementation of an interface start with the prefix "Abstract-" followed by the name of the interface that is going to be skeletally implemented eg AbstractList which is an abstract class for the minimal implementation of the List interface

USE UTMOST CARE WHEN DESIGNING INTERFACES
If you are designing a public API, think long about the method signatures as it will be extremely difficult to change once released eg if you add any new abstract methods to the interface that is already used, then any code that used the package will no longer compile until that new method is implemented in all of the subclasses that implement it eg the List interface in the Java API is used and implemented by external libraries eg the ImmutableList in the Google Guava API and the TreeList in the Apache Commons API. If this interface is updated and includes new methods that would crash both external implementations until the new methods are implemented. However with abstract classes, if we add new concrete methods, they are automatically inherited by subclasses so we would not have this problem but now in Java 8 onwards, even interfaces permit the adding of concrete methods which also get automatically inherited however adding new abstract methods or changing signatures of abstract methods would still break the code of all implementors.

REFER TO OBJECTS BY THEIR INTERFACES
Whenever possible, try to use an interface as a reference type in all kinds of variable declarations and also use them as method return types.

eg void foo(ArrayList list){ ... }
   foo(new ArrayList()); the problem with this method signature is that we can only call it with an object of type ArrayList but can have no other implementation.
But if we had the parameter type as a List, which is an interface, we could have in the future passed ArrayList, LinkedList or TreeList as parameters since they all implement the same List interface.
Thus we can change implementations if needed as new implementations offer better performance
Polymorphism benefits - flexible code, clean code

Exceptions
- if there is no interface at all, try to use the least specific class
 - if we need specific subclass functionality in the code

IF WE NEED TO DEFINE CORE BEHAVIOR OF ALL OUR CLASSES AND INCLUDE STATE AS WELL AND ONE CLASS IS GOOD ENOUGH -> ABSTRACT CLASS
IF WE NEED TO ADD IN MORE CAPABILITIES TO CERTAIN AND NOT ALL CLASSES IN AN UNLIMITED WAY -> INTERFACE

Marker interfaces
Interfaces without any methods. Merely marks a class as having some property.
Thus each class that implements a marker interface is announcing that it has a certain property defined by the marker interface. This property is explained in plain English in the javadoc of the marker interface. eg java.util.RandomAccess -> any class implementing this interface declares that it allows fast random access of its elements
Another is the java.io.Serializable -> any class that implements this is declaring that it allows its objects to be serialized ie converted to bytestreams that can be saved to disks and can be deserialized (converted back to Java objects later)
Cloneable marker interface from java.lang
- by implementing cloneable, a class declares that the objects can return their exact copies.

class CloneableClass implements Cloneable{
      public CloneableClass clone(){
      	     try{
		return (CloneableClass) super.clone();
		} catch (CloneNotSupportedException e){}
	     return null;
      }

}

Clone returned from the Object class' clone method is of type Object and so we need to typecast it to our appropriate class.
Note that the clone() method in the Object class has protected access and hence can only be invoked in a subclass. You do not have to implement the Object class' clone method, you can implement your own.
Clone method performs a shallow copy in order to generate the duplicate object - shallow copy implies that in generating the new object, the fields in the original object are not cloned. Their values are simply assigned to the new corresponding fields in the new object. Had the fields been cloned, this would be known as deep copy. So in shallow copy both the original object field and the generated clone's field would be referencing the same object. A problem can arise if that object is mutable. The value in both the clone and the original field would be affected. In deep copy, that is not an issue. But if the fields are all primitives (which get cloned by value to the new fields) or all immutable objects eg Strings, then shallow copy is not a problem.
If you know that some of your fields are mutable during cloning, you can explicitly clone those internal mutable objects then return the new clone.

default methods
Before Java 8 - pain to evolve interfaces. Changes to API can easily break their code. 
We could perhaps add new methods and implement them in the abstract classes but we cannot use abstract classes for multiple inheritence.
This is where we use default methods. The main goal of the default methods are interface evolution with binary compatibility - clients of API should be able to use the old and the new methods without breaking their code. 
Default methods cannot be final since we need to change their implementation in the subclasses. They are there only to provide minimal implementation of new abstract methods that the client may not have defined already.
Default methods are also called defender/virtual extension methods
Binary compatibility -> works without recompiling the code first
Source compatibility -> works after recompiling
Default methods are instance methods so you cannot invoke them using the interface name
Any interface can never overwrite a method from an object
Recap - use default modifier -> only can be used in the interface
      - diamond problem can be avoided
      	- classes over interfaces
	- the more specific version is picked
	- manual resolution
Explicit invocation of a default method in a superinterface -> must use parent.super eg
Default implementation can be re-abstracted in subinterface or abstract class if the implementation is not good enough
Cannot use final or synchronized keywords with default methods
default methods, other benefits:
- interface evolution
- default implementation that can be overridden
- eliminate utility classes
- allow interface to stay as functional interface -> these have exactly one abstract method

NOTE THAT TO INVOKE A DEFAULT METHOD FROM WITHIN A SUBCLASS YOU HAVE TO USE superInterfaceName.super.defaultMethod(). It is not simply superInterfaceName.defaultMethod(). Note that you can only access the parent superinterface's default methods and not the grandparents' default methods 

Having static methods with the interfaces helps to do away with companion classes and to just have the utility functions stay with the interfaces themselves eg
instead of List s = new ArrayList(); s = Collections.sort(s); we can have the sort utility function be a static method of the List interface
Interface evolution not affected
Declaration
static
- static methods in interfaces ARE NOT INHERITED since two superinterfaces can have the same static methods. Inheritence of static methods in classes is itself a design bug.
- can be invoked only via interface name. No other way. Not even with sub-class. However, within the interface itself, default methods can directly call static methods. And static methods can call other static methods.


MVC Architecture
3 layer
Model - holds business logic and has 2 layers - the service layer & Data access objects 
View - front-end (Java Server Pages)
Controller - servelets (Java Programs), separates model from the view. Controller and model have Java programs

Advantage of MVC is the separation of business logic from presentation layer. Thus you can use the same business logic for requests coming from multiple types of devices
Implementation Details
-> we will implement both Model & Controller
-> for view we will use View.java
-> Database - Java class DataStore.java
-> Entities -> classes like User, Bookmark, Book etc. They correspond to database table. Each instance is a row in the database.
GET YOUR DESIGNS RIGHT TO AVOID REFACTORING LATER


JVM Internals
It is helpful to understand the inner workings of JVM. Look at this example from this article:http://www.xyzws.com/javafaq/when-initialization-occurs-in-an-interface/123 
When initialization occurs in an interface?
According to Java language specification, initialization of an interface consists of executing the initializers for fields declared in the interface. Before a class is initialized, its direct superclass must be initialized, but interfaces implemented by the class need not be initialized. Similarly, the superinterfaces of an interface need not be initialized before the interface is initialized. Initialization of an interface does not, of itself, cause initialization of any of its superinterfaces.

Here is an example listed in JLS. More detail information and example can find in 12.4 Initialization of Classes and Interfaces.

interface I {
        int i = 1, ii = Test.out("ii", 2);
}
interface J extends I {
        int j = Test.out("j", 3), jj = Test.out("jj", 4);
}
interface K extends J {
        int k = Test.out("k", 5);
}
class Test {
        public static void main(String[] args) {
                System.out.println(J.i);
                System.out.println(K.j);
        }
        static int out(String s, int i) {
                System.out.println(s + "=" + i);
                return i;
        }
}
produces the output:

1
j=3
jj=4
3
The reference to J.i is to a field that is a compile-time constant; therefore, it does not cause I to be initialized. The reference to K.j is a reference to a field actually declared in interface J that is not a compile-time constant; this causes initialization of the fields of interface J, but not those of its superinterface I, nor those of interface K. Despite the fact that the name K is used to refer to field j of interface J, interface K is not initialized.

System.out.println(J.i); // The i variable is inherited from I but since it is a constant - you don't have to go through the whole process of initializing I, just reference it and get on with things.
System.out.println(K.j); // now this is more complicated. Since the variable holds something other than a constant, the first thing that we have to do is initialize J so that we can figure out what to DO to come up with the value of j.
Initializing interface J causes variable j to be initialized first: executing Test.out("j",3) which prints j=3, and setting the variable j to 3 (note the return type on the method). Now jj is initialized executing Test.out("jj",4) which prints jj=4 and sets the variable jj to 4.
Now that initialization is done we can evaluate and execute the println for K.j which prints the current value of j which is 3.




JVM Internals
Understand the lifetime of a type inside JVM
Runtime data areas - understand the different memory areas in JVM
Anatomy of a class file - how bytecode instructions work
JVM is the cornerstone of the Java platform. JVM is an abstract computing machine. 
It has Java bytecode as its instruction set. It manipulates machine at runtime like a real computing machine.
Core Responsibilities of JVM:
- loading and interpreting bytecode
- security
- automatic memory management

JVM is platform dependent but it excecutes platform independent Java bytecode. This is similar to interpretation but much faster because JVM interprets bytecode instead of source code.
Specification & Implementation
- abstract specification - high level description of its features and instruction set. Anyone can take the specification and implement their own JVM
- concrete implementation of a JVM specification - popular implementations are Oracle's Hotspot JVM and IBM's JVM
- runtime instance - instance of a concrete JVM implementation. When we run a Java program from the command line, a runtime instance of JVM is created and loaded into memory before that program can be run. JVM is allocated a chunk of memory which it then divides into different sections for its processing needs.

Performance:
- Bytecode interpretation is much faster than source code because bytecode has a compact format, is pre-compiled and already optimized
- Just-in-time JIT compilation - caches frequently used bytecode in the form of machine code and when needed it excecutes the cached machine code to speed up performance

Lifetime of a type
Hello.class -> Class Loader -> (Well formed?) -> no[REJECT]
	       	    	     	   	    -> yes -> allocate space for static variables and initialize them with the default values
					    -> load referenced classes -> initialize variables(ovewrite the previous default values with the actual user specified initial values from declarations or static initializer or instance initializer blocks)

Loading is performed by a Class Loader -> searches classpath for the class. Once found, it loads the bytecode into memory and initializes the superclasses. After that, it generates a Class Object which is the output of the loading step. Class Object simply has the meta information about this class eg name, superclass names, method names etc. Class object is an instance of java.lang.Class.If the type is an interface, it will be loaded but not initialized. It will only be initialized if one of its static methods is initialized. Another time that an interface is initialized is when a field is initialized  via a method
The Class object is created once when the corresponding class is accessed for the very first time. In subsequent accesses, JVM will load the Class object from memory. So the output of the loading step is the Class Object which is the input for the next step -> Linking

Linking has 3 steps:
1. Verification - a bytecode verifier checks if the input class is well formed or not [ this helps detect malicious classes ]
2. Preparation - space is allocated for static variables and they are initialized with default values
3. Resolution - load in classes referenced by the input class. These classes are loaded into memory dynamically - dynamic linking [NOTE THAT RESOLUTION IS AN OPTIONAL STEP - it can run after preparation or after the next step -> Variable initialization.

Initialization
Ovewrites the default values with the default user-defined initial values

After initialization -> Excecution

So the 3 stages in the lifetime of a type are Loading, Linking & Initialization

Class Loading
1. Whenever a class is accessed, the Class Loader checks if the corresponding Class Object is already on the heap. If so, it returns the Class Object and if not the class looks for the .class file using the Parent Delegation model. 
If the .class file is found, the Class Loader loads the corresponding bytecode and creates a Class object and returns it. This Class Object is stored on the heap for future use.
If the .class file is not found, then an exception called ClassNotFoundException is thrown

The Parent Delegation search model is protocol and order in which Class Loaders look for a .class file. It starts at the topmost Bootstrap Class loader -> Extension Class Loader -> Application Class Loader -> User-Defined Class Loader. This is because JVM considers the classes at the top as more trustworthy(bootstrap class loader) than the ones at the bottom (User-defined Class Loader). 
If class is found in one of the trustworth repository, then JVM doesn't perform the more stringent verification checks

When is a Class Accessed and Loaded for the First Time?
- when an instance of it is created via the "new" operator
- it is loaded when one of its static methods or fields are called on. NOTE THAT ACCESSING COMPILE-TIME CONSTANTS WILL NOT LOAD A CLASS eg static final double PI = 3.14; MyClass.PI will not load the class because it is a compile time constant - values are known at compile time and they are already copied and substituted wherever they are used - so there is no point loading the class here
- if subclass is loaded (constructor chaining) or sub-interface is loaded
- if it is run from the command line (entry point in its main method, which is a static method)
- can also be loaded via Reflection (to be covered)

Class Object
- the output of the loading step.
All the objects we create from a particular class are always done using the Class object of that class. It is not just Classes and Interfaces that have a Class Object. The Primitive types, void keyword and Arrays also have one. We will see later how the Class object of a primitive could be useful.
- All arrays of the same dimension regardless of length have the same Class Object eg all 1D arrays have same Class Object
- Class object contains meta information about the class:
  	String getName(); -> returns name of class
	Class getSuperClass(); -> returns the supertype of the current Class -> thus returns Class object. If the current class is either Object class or an Interface or a primitive or void then null is returned as they do not have a superclass. If current class is an array then the Object class is returned
	boolean isInterface();
	Class[] getInterfaces(); -> returns all the interfaces implemented by the current class
	ClassLoader getClassLoader(); -> returns the class loader that loaded this class

Linking
Is the most complicated of the lifetime of a type. Has 3 stages - verification, preparation and resolution
Verification
- checks that the loaded class conforms to Java language rules. This is necessary as the class file might have been loaded across the network or it could be a user defined class from the local machine. In both cases JVM does not trust those classes as they come from less trustworthy resources eg they could have been generated by a hostile compiler intending to perform some malicious actions. Thus JVM subjects them through some stringent verification checks although the same verification is already done during compilation. Classes from the Java library are not verified as they are considered trustworthy -> they are loaded by the Bootstrap ClassLoader
- bytecode verification is done by the Java Bytecode Verifier and only after this is the code considered safe by JVM. If the verifier finds a problem, it rejects the malformed class and throws an exception.
Some verification checks:
     - final classes must not have subclasses
     - final methods must not be overridden
     - no illegal method overloading
     - bytecode integrity - methods expected to return values always do so before closing

Preparation
-starts off straightforward:
	- allocate space for static fields and initialize them with default values
	- if there is no memory throw an OutOfMemoryError
	- fill static fields with the user-defined values
	- Instance Creation then initialize instance fields and give them default values. This happens for all classes - static fields of all classes will be initialized before the first instance field is initialized with default values in a superclass.

Resolution
- fields and methods from other classes and/or interfaces are loaded so that the current class can use them. Such references are called symbolic references. All symbolic references are stored in one area of the .class file called the constant pool which also includes compile-time constants & string literals
- need not strictly happen after preparation step. Can be performed later after initialization step
- referenced classes are loaded into memory here and their corresponding symbolic references within the current class will be replaced with direct references to their actual locations in the memory. 

When this linking is done at runtime, it is called dynamic linking. Linking at compile time is called static linking. In static linking, the contents of the reference file are copied into the final executable. The advantage of dynamic linking is that you can make easy updates that is you can replace a class file with a more newer classfile. However, the software would cease to work if updates are incompatible eg a method previously referred to by the current class might be missing. The resolution of symbolic references in the current class happens only once. The symbolic reference might be referenced from multiple locations within the same class but that reference will be resolved only once and thereafter the direct reference is used.

Dynamic linking
Can happen in 2 ways depending on JVM implementation. It can be either via:
- Eager loading - means that resolution happens right after preparation step - means all classes referenced by current class will also be loaded, meaning that they get loaded and initialized before the current class itself is initialized.
- Lazy loading - resolution is postponed till after initialization - till the statement that includes the reference is actually executed (on-demand). Typically JVMs implement lazy loading because you don't have to load a class until you really need it. Sometimes certain statements may never get executed and so there is no point loading the references appearing in those statements.

Resolution checks:
- permission - ensure that current class has permission to access the referenced class
- correctness - ensure that the fields exist in those classes with the right type and the current class has the permission to access those fields

Once a class is found to be safe, initialization can begin -> initialize static fields with actual default user values.
Note that Interface initialization only occurs when a static method is accessed or one of its fields that is a non-compile time constant is accessed -> that is it is initialized via a method or a constructor.



Reflection
There are 3 ways to access a Class object
1. via ObjectRef.getClass()
2. Class.forName(String className)
3. Class literals

1. Using Object reference
Class c = "foo".getClass(); -> returns Class for String
Set set = new HashSet();
c = set.getClass(); -> c is set to the Class for HashSet

2. Using Class.forName(String className) -> static method in Class class
   - argument is fully-qualified class name
   - doesn't work with primitives
   - Examples: Class.forName("java.lang.String")
     	       Class.forName("[D"); -> Array of primitive double

3. Appending .class to type name
   - works with classes, interfaces, arrays and primitives
   eg String.class, boolean.class, int[][][].class, void.class

Special case: Boxed primitives have a TYPE field. Accessing this field returns a Class object of that primitive
There is a class called Void in the java.lang package. This Void class also has a field called TYPE. Accessing this returns the Class object for the void class. Note that the void class is non-instantiable as it has a private constructor.
In general using .class is preferred over using the type field

Runtime data areas
The operating system allocates memory for all given processes when they start running. This memory is called native memory. Process will also have its own virtual address space which maps to physical memory or any file or addressable storage. 
This virtual address space will have 2 parts - user space and kernel space.
Kernel space is where the kernel resides and this space is shared by all the processes. The user space however is unique to each process and that is the native memory too where the user programs are stored.
On a 32 bit Windows machine, by default a process gets 2GB of user space and 2GB of kernel space.
Book recommendation: Operating System Concepts, Peter Galvin, Greg Gagne (9th edition)
JVM as a process also gets its own native memory which it splits into multiple subareas
JVM User Space
User space = Native Heap + Java Heap
Java Heap stores Java objects. Setting an appropriate Java Heap size is important for good performance. 
Method area contains Class data eg superclass name and actual bytecode of the class. Multiple objects of the same class will point to the same method area. 
The Native heap stores code that is compiled by the Just-in-time compiler which is tored to speed up future performance. Native heap can also have special objects called direct buffers which are useful when caching lots of data.
The Java heap and the method area are shared across threads during multitasking. However there are certain areas of memory that must be specific to each thread eg stack.
JVM Stack includes the order of invocation of methods (method invocation state). It also includes information about local variables within each method.
There is a separate stack for native methods. Sometimes JVM might invoke methods in native code which could be applications written in native compile languages eg C and C++.
JVM relies heavily on native code to do tasks like input/output.
Another section of the User space is the Program Counter. It holds the memory address of the next instruction meaning that it is a pointer to a method in the method area where the bytecode is.
Each thread has its own JVM stack, Program Counter(PC) and native method stack 

Method Area & Heap
What goes into method area and how it is connected to heap
Objects are stored on heap -> when we talk of objects we are mostly talking about the instance data inside those objects. JVM allocates space for an object based on the number and type of its instance variables. 
Objects also contain behavior which are methods. But methods are something that is more specific to the class that the objects belong in so they would be part of class data. Any class data is stored in the method area. Class data also includes meta-data like field names and field type.
Method area is all about classes while heap is about objects. 
When creating an instance of a class. The class loader will check if the class object is already present on the heap and if not, it creates a Class object on the heap and stores the class data in the method area. JVM would also create a new instance of that class and store it on the heap. If a new object of the same class is created, then only the object is created and stored on the heap. The class loader will know that the class object and class data have already been created and so it does not create them again.
As program execution continues, more things are added to the heap and method area. Pointers (unidirectional and bidirectional) go back and forth between the heap and method areas.
Method area (class data store):
- meta info - eg names of type, superclass, super interfaces, class or interface, access modifiers eg abstract, final, abstract. Such meta information is accessible through the class object so that means that the Class object internally uses the data stored in the method area.
Class data and the Class object have a bidirectional link. This is important eg during class loading, the class loader first checks if the class object for the type is already on heap. For that it may search the method area to see if class data for that type exists and if it does exist, it would then return the reference to the class object.
Classes include fields like static and instance variables so class data would include information like field name & type; modifiers: static, final, access modifiers, transient [related to serialization], volatile [related to multithreading]
If the field is an instance variable with primitive data type, it is stored on the heap but if the field is a static variable, with a primitive data type, then the method will be stored on the method area.
If a field regardless of whether it is an instance variable or static references an object, the object will still be on the heap, but the reference itself which is the memory address of the object will be stored in the method area in the case of static variables. For instance variables it would be assumed to be on heap.
Class data will also include the runtime constant pool - this is a runtime version of the constant pool as seen in the .class file. It includes constants like String literals or primitive value constants. Can also include symbolic references(processed in the resolution step of a type).
Classes also store method information eg name, return type, number and type of parameters, modifiers, method bytecode.
Method area also contains method table, which is an array of references to instance methods (not static methods). Each reference is a pointer to actual bytecode. The method table is used during method invocation, that is when a method is invoked on an object, then the method table is used to find the method code that needs to be executed. This is one reason for having pointer from the object heap, to the class data - when you invoke a method on an object, JVM will follow the pointer from the object to the class data and use the me†hod table to find and execute the target method.
Method table also contains references to methods inherited from superclasses.
Method area used to be allocated in the PermGen space (permanent generation space). Removed completely in Java 8. Method area moved to native heap and is now known as metaspace. The reason for this was that for PermGen there is a default maximum size set and if this maximum is reached, an out of memory error would be generated. Now with metaspace, there is now default max size and the OutOfMemoryError is less likely. Metaspace also improves the performance of garbage collection process.
Runtime Type Information (RTTI)
- invoke method code in method area
- check correction of cast
  	Superclass obj = new Subclass();
	Subclass subObj = (Subclass)obj; // RTTI used here
- RTTI also used to perform instanceof checks
       subObj instanceof Subclass

Method Table
Basically an array of references to instance methods.
Static methods are statically bound. At compile-time, the address of the method is already known and so the runtime constant pool would have a reference to the static method.
In summary method tables include only references to instance methods. Only concrete classes have method tables. Abstract methods do not have them because they cannot be instantiated.

Garbage Collection
There is a need to reclaim memory when objects are no longer requiered. Taken care of by the garbage collector. We will look at the heap area and how Java manages this area.
In C/C++ the programmer has to explicitly allocate & free memory. This helps create efficient applications. This gets risky in larger projects.
Memory corruption errors:
- memory leak - when unused objects are never freed. eg if a new object reference is assigned a reference of an object that was not freed. Eventually, you will run out of memory and the program will not work. 
Memory leaks are not as bad for short-running programs but for long ones like web browsing it can be very serious
- dangling reference - reference to deallocated location. If memory location is pointed to by 2 references, and one of them frees it and/or gives a new value, then the previous pointer to it is still there but the second pointer will not behave in an unusual manner.

Java uses automatic memory management. Done through garbage collection using a Garbage Collector. 
The Garbage Collector reclaims dead objects so there are no memory leaks.
GC needs to make sure that an object is really dead and there are no active references to it otherwise we can end up with a dangling reference.
If an object is not referenced anymore, it is reagarded as an abandoned project.
An object is also considered abandoned when:
   -it goes out of scope eg void go() { Book b = new Book(); return; }. here object b is considered abandonded after excecuting this method.
   - if reference is assigned another value or if null is assigned to its reference.
GC may be implemented or as an add-on. Runs in background. Programmers have limited control over when it will run. It is usually triggered when there is little memory.
   - you can make JVM run GC by either System.gc() or Runtime.getRuntime().gc() --> note that these are only hints and JVM can choose not to run.
Garbage Collector Algorithms
GC challenges?
- how do you identify abandoned objects?
- how do you reduce pause time?

Identifying & reclaiming dead objects
- Mark & sweep - find and mark live objects. Sweep would go through and identify the unmarked objects and release them. But during sweep phase, if new objects are created, they may also be initially unreachable and may be wrongfully freed. Thus we need to pause the application and sweep. Note that freeing has to be carefully not to fragment data. The solution to this is another algorithm known as Mark-Sweep-Compact. 
In the Mark-Sweep-Compact algorithm, there is an additional compacting which moves all the live objects to the beginning of the memory region thus doing away with fragmentation and there is a greater chance of successfully storing large objects. 
The problem with MSC is that there would be a significant pause time as objects are moved and also updating corresponding references as their objects are now in different locations in memory.
There is also a third algorithm which is the Mark And Copy. It maintains a separate memory location free so that after sweeping, all live objects are relocated to the empty location. This also prevents fragmentation but an added advantage is that the copy phase can happen simultaneously with the mark phase - that is as objects are being marked, they can be moved to the second region. Due to this the application pause time is shorter.

Generational collection
Helps stop application pauses. Lots of objects are created but most die young. However there are some long living objects that GC will check on many times unnecessarily. We can divide memory into 2 buckets - one to store long lifespan objects and another for short lifespan objects. This allows GC to focus on cleaning the short life objects.
this is the generational collection approach - heap is split into 2 generations/groups in memory - young and old(tenured) generation. 
Young generation contains recently created objects and gc mostly focuses on this group. The objects that last in young generation are promoted into the old generation. 
The old generation is still subjected to gc but less frequently
Young generation has further divisions called eden and survivor( has 2 regions - to and from). Initially created objects are in eden and gc monitors them. Surviving ones are moved to the to survivor group. When garbage collection is finished, eden is empty and the to objects are moved to from.
Dead objects can still be found even in the survivor space of the young generation. 
By default, JVM moves an object from young to old generation after 15 gc cycles. This option can be adjusted through an option given to JVM on the command prompt.
Generational collection is used to reduce pause times. Garbage collection can also use multithreading to further reduce pause times
Types of Garbage Collection - CMS, Parallel GC and Serial GC. All use Mark and copy in the young generation. For old generation Serial and Parallel use Mark-Sweep-Compact whilst CMS mostly uses Concurrent Mark-Sweep. New collector called G1

ELIMINATE OBSOLETE OBJECT REFERENCES - to avoid memory leaks.

Memory leaks -> increased memory footprint -> increased garbage collection activity -> performance degradation -> WORST CASE (no memory error)

Stack
All information about methods getting invoked and also about local variables will be stored on stack.
Last in first out data structure. One stack per thread. Each method call creates a method frame which is pushed into stack. 
If an object reference is on the stack, the object it references will be on the heap
Stack Frame Contents
- contains local variables, operand stack and a reference to the runtime constant pool to the class of the local method
Operand stack - similar to registers in CPU. Stores returned values by invoked methods
Local variables are stored in an array and the results are added to this array until the final value is stored at the back of the array. This final result is the return value.

eg int y = 1; 	    	      	       	   iconst_1    //integer value of 1
   int z = 3;				   istore_1  //store in position 1
   int x = y + z;			   iconst_3  // integer 3
					   istore_2  // store in position 2
					   iload_1   // get position 1 value
					   iload_2 // get position 2 value
					   iadd
					   istore_3 // store result in position 3 and return

index 0 in this case is researved for the method parameter. If the code was in a function that did not have method parameters, it would be istore_0 eg.

Instruction Set
JVM has an instruction set -> a method's bytecode instructions
Bytecode instructions have similar structure to machine code. Each instruction involves a 1 byte opcode followed by operands
opcode -> operation to be performed eg iadd, iload_1
operands -> additional information

Like CPU, JVM's excecution engine follows the fetch-and-execute cycle. That is, JVM fetches an opcode and then any trailing operands for that opcodes. Then it executes that operation after which it if fetches the next instruction and so on.

javap Disassembler
Disassembles 1 or more class files.
javap -c
-c flag prints method bytecode
javap -v OR javap -verbose
-v flag prints method bytecode and constant pool
-help flag shows all options

eg javap -v Hello.class

invokespecial:
- is run for all instance initialization methods, private methods & superclass methods via super keyword.
- the instance initialization method is referenced using a special keyword called <init>
1. peforms method resolution -> replacing symbolic references with direct references
2. creates stack frame for method on stack
3. pops the this reference stack element & store it at index 0 in local variables array -> The zeroth element in the local variables array is a always a reference to the current object. Each variable is first loaded onto the stack then popped into the local variables array when it is time for it to be used
4. set program counter (pc) to the first instruction in the instance initialization method

invokevirtual:
- discussed in method binding section of Inheritence & Polymorphism chapter
- for instance methods, method signature binding happens at compile time itself but the method implementation binding happens only at run time. This is because with instance methods, we do not know which method to run until run time ie it is dependent on the object in context.
When JVM encounters invokevirtual:
1. performs method resolution -> points to index of method in method table of object class
2. method implementation lookup: JVM goes from objectReference -> actual object on heap -> method table[index] (goes to the index of the method refered to by the actual object]. At this point, JVM now knows the method to be executed.
3. create stack frame for method on stack
4. pop stack element and store it at index 0 in local variable array
5. set pc to first instruction in method

Constant pool
Contains symbolic references to methods eg #1 = Methodref, classes eg #9 = Class, method descriptors eg ()V -> includes method parameters and the return type (no parameters in this case and  return type is V for void)

System.out.println("Hello");
- System is a class 
- out is a static variable defined in the System class
- out is of type PrintStream from the java.io package
- the println() method is invoked on the out static variable

aload:
- implies that we are loading an object. If an integer for example it is iload
so we need to store the out variable in the operands stack. This is done by the getstatic instruction.
getstatic:
- get and push static field value onto operand stack
ldc:
- gets the value of a constant from the constant pool and pushes it onto the operand stack
invokevirtual: 
- pops operands and invokes the method
areturn:
-implies that we are returning an object reference. Primitive types have their variations eg ireturn for integers

invokeinterface instruction is also available.
 
Exceptions
We all want programs to be as error free as possible. But at runtime we will encounter exceptions eg partner server is down or our database is down. These events are not in our control but we must write code to account for these situations eg write code to automatically connect to another server if partner server is down.
This leads to robust software otherwise the code can be very fragile and will bring trouble to the organization and the programmer.

Agenda:
- Exceptions
- Exception Handling
- Assertions

An exception is an object of class java.lang.Throwable

Checked & Unchecked Exceptions

Checked exceptions are caused by exceptional situations that are not under our control
These errors are checked by the compiler. If you throw a checked exception, the compiler requires that
- you announce that you are throwing an exception by using the "throws" clause in the method declaration
- you must set up the invoking code to acknowledge the incoming exception by either wrapping the call in a try/catch block or by declaring that the invoking method itself throw the received exception.

Unchecked exceptions
- generated by programming flaws or system errors
- if they are caused by programming flaws, they are called Runtime Exceptions.
- if caused by system errors, they are called Errors

Generally you shouldn't catch Runtime Exceptions as they are due to programming errors. This is because, usually recovery from such errors is not possible and the times when it is possible, it will do more harm than good to simply catch the error and continue excecuting.

Errors due to the system are very rare. When they do occur you do not want to handle these.They are usually caused by abnormal conditions.

Exceptions Inheritence Tree
						Throwable
		Exception					Error
IOException	AWTException	RuntimeException		VirtualMachineError
				NullPointerException		Linkage Error         
-FileNotFoundException		  ArrayIndexOutOfBoundsException  NoClassDefFoundError
-EOFException			  IllegalArgumentException
				  ClassCastException
				  NumberFormatException

Some rules:
Here are couple of rules when it comes to exceptions & method overriding.

Rule 1: If the super class method does not declare an exception, then the overriding method in the subclass cannot declare a checked exception, but can declare an unchecked exception.

Rule 2: If the super class method declares an exception, then the overriding method in the subclass can declare same exception or a subclass exception or no exception at all, but cannot declare parent exception.

finally Block
Exceptions can affect control flow. Sometimes this can cause resource leaks as some methods that were running in the background are left open after control has shifted abruptly from the  original method.
The finally block guarantees that code inside of it will run even if an exception is present
try{ .... }
catch(){...}
finally{...}

It is an optional block and when present, it always runs. Only exception when finally does not run is when JVM encounters a severe JVM error or when the method Syste.exit(int) is run. The exit() method is used to terminate JVM itself. Situations when you need to have finally are when you have to make sure that the clean up is proper and not affected by the switching of control when exceptions are thrown. eg to make sure that a database connection is closed properly, or a filestream is closed properly when reading or writing to files.
finally block must follow any catch blocks
try must have at least one catch or a finally. You cannot have more than one finally block associated with a try block

Here is the control flow of code using try and finally blocks

Exception! -> Exception handler? -> Yes! -> execute catch block(if present)v-> execute finally block -> execute code after finally

Exeption! -> Exception handler? -> No -> execute finally block only -> end method

No Exception -> execute try block -> execute finally block -> execute code after finally

try-with-resources
-resources could be classes like operating system methods. This statement automatically closes such resources.

FileInputStream in = null;
try{
	in = new FileInputStream(filename); //open stream
	//read data
}catch(FileNotFoundException e){
			     ...
}finally{
	try{
		if(in != null)
		      in.close(); // in.close() can also throw an exception thus try
	}catch(IOException e ){ ... }
}

The above finally block looks ugly with the enclosed try/catch block, the null check and the close method invocation. To avoid this, we use the try-with-resources statement introduced in Java 7

The same code would look like this:
try(FileInputStream in = new FileInputStream(filename)){
		    //read data
}catch(FileNotFoundException e){
			     ...
}catch(IOException e){
		   ...
}

Note that the resources are created within the parentheses after the try keyword. It will not work unless the full declaration happens within the parentheses. The close method is invoked implicitly after the code in the try block is executed. The compiler will insert the entire finally block into the bytecode so that even if an exception is generated, teh close() method is still executed. 
We are also catching an IOException because we know that the close method can throw an IOException. 
Note that the resource created within the parentheses is implicitly final so it cannot be reassigned within the try block.
Since the resources are being automatically closed, this feature is called Automatic Resource Management (ARM)
We can also open multiple resources too in the try-with-resources block eg
   try(FileInputStream in = new FileInputStream(filename);
   	FileOutputStream out = new FileOutputStream(filename)){
	// read data
	} catch(FileNotFoundException e){
	...
	} catch(IOException e){
	...
	}
Note that the multiple declarations are separated by a ; just like in a for loop.
Resources are closed in reverse order that is, those created later are closed first. Thus when you look at the declaration statements in the try block, if there is a failure in one of the resources, then all the others created to its left would be closed.

General Syntax
	try(java.lang.AutoCloseable){
	...
	}
Any resource we create in the parentheses must be of type Autocloseable. Meaning that every resource has to implement Autocloseable or one of its subinterfaces.
Autocloseable has only one method which is the close() method.
The try block need not have a catch or finally block if the close you implement as part of implementing Autocloseable does not throw an exception. The code within the try block should also not throw an exception.
If you are not dealing with autocloaseable resources, then you have to use the regular try,catch,finally block
AutoCloseable Hierarchy
				java.lang.AutoCloseable
java.io.Closeable		javax.sql.ResultSet	javax.sound.sampled.Line
java.net.Socket	java.util.Scanner


Best Practices: Creating new Exceptions
USE CHECKED EXCEPTIONS FOR RECOVERABLE CONDITIONS AND RUNTIME EXCEPTIONS FOR PROGRAMMING ERRORS

DON'T IGNORE EXCEPTIONS - DO NOT JUST PUT AN EMPTY CATCH BLOCK. IGNORING EXCEPTIONS IS LIKE IGNORING A FIRE ALARM

INCLUDE FAILURE-CAPTURE INFORMATION IN DETAIL MESSAGES

THROW EXCEPTIONS APPROPRIATE TO THE ABSTRACTION

API contracts should be kept but teams will sometimes break the API contract and hence break your code. APIs can be broken especially working with unprofessional teams. Once the API is out, you should not change the response or the request format. A courtesy is to let your clients know of the imminent change say two or 3 weeks in advance so that they can make the necessary adjustments once you implement the change.
You should guard yourself when working with teams that change API suddenly but implementing exceptions in your code that would detect any breaks with the expected API return or request formats. 
You can define your own exceptions and throw and handle them when such situations arise. You should name the API in a meaningful way eg APIFormatChangeException.
Every new exception has to be a subclass of Throwable eg Exception, Error, RuntimeException etc. We should not subclass the Error class because the convention is that errors should be generated only by JVM as they are JVM-related. So since it is highly recommended that we don't extend Errors, then we have two options left - a RuntimeException or Exception
A RuntimeException would seem ideal because an API change is a programming error on the external partner. However, RuntimeExceptions are unchecked exceptions and can be ignored. If we make it a checked exception however, we then force the code that will invoke the API to handle the exception. This has the benefit of forcing present and future developers to handle and not overlook such exceptions. If you use a RuntimeException, the compiler will not force them to do it.
Checked exceptions will force the developers to handle the exception either by contacting the creators of the API to fix it or adapt their code to these new terms of the API.
When creating your custom exception, it is not recommended to subclass directly Throwable because this is more confusing to users. To create a checked exception, it is recommended that you subclass Exception which is a direct subclass of Throwable OR one of its subclasses.

How can we associate additional information within exceptions so as to help with debugging?
- create a new constructor from the superclass of your custom constructor that takes in a String message variable. This message variable will be included in the printout of the exception.
You can also create your own fields inside of the custom exception class and generate custom getters and setters for them. Then you can create a custom constructor which still uses super() to initialize its superclass and then set your custom fields with the incoming values.
The super() call can also still be set to a String so that anyone debugging can still get a full message of the error if they choose.

Throw Exceptions Appropriate to the Abstraction
- if a higher level method catches an exception from a lower level method, then instead of propagating that exception, it should throw a new exception that is more meaningful in terms of higher level abstraction. This way, the higher level layer is not polluted with lower leve details. This idea is referred to as Exception Translation 

Exception translation is good but we should avoid overusing it.
- see if we can handle the lower level exception at its level
- in some cases, even the lower level error may be appropriate to higher levels, then we should propagate it. Otherwise we should do an exception translation.
- at times the programmer might want to know exactly what caused the higher level exception and in this case they would want access to the lower level exception. This can be done by a special form of exception translation called exception chaining. Thus the higher level exception can encapsulate the lower leve exception
- we can do exception chaining by:
1. creating a constructor from the superclass which also accepts a Throwable class exception. Now when we printStackTrace() of the exception we will also have a Caused By element. This comes from the Throwable object saved in the cause field of our higher level exception. If we need to print only the cause we can of a higher leve exception e we can run e.getCause().printStackTrace() - here getCause() gets the causing exception.
2. in some cases if we are working with exceptions that are not of the Throwable class. In such cases we use the .initCause() method which takes an exception as argument and generates a throwable cause for it.

Exceptions: More Advice
USE EXCEPTIONS ONLY FOR EXCEPTIONAL CONDITIONS
DON'T USE EXCEPTIONS FOR REGULAR CONTROL FLOW

eg try{
   while(true){
	Object item = nextItem();
	}
}catch (NoSuchElementException e){
// some complex logic
}

Here the above program's flow is dependent on the generation of an exception. NEVER DO THIS

You can instead do this:
    while(hasNextItem()){
	Object item = nextItem();
}

AVOID UNNECESSARY USE OF CHECKED EXCEPTIONS
- if used carelessly they make the API unpleasant to use as they force the client to handle those exceptions and place a burden on the client
Use them only if there can be an UNPREVENTABLE EXCEPTIONAL CONDITION and the API client can actually recover from it. Otherwise, an unchecked exception is more appropriate

FAVOR THE USE OF STANDARD EXCEPTIONS
-exceptions that come with Java should be good enough most of the time. It makes it easier for others to understand your API. Commonly used standard Exceptions are:
IllegalArgumentException, NullPointerException and IndexOutOfBoundsException

DOCUMENT ALL EXCEPTIONS THROWN BY EACH METHOD
- it helps in using the method properly. use the @throws tag
- for checked exceptions -> document each one individually and document precisely the conditions under which it is thrown. You cannot use a superclass for them because it is vague eg throws Exception or throws Throwable
- document unchecked exceptions too - generally thrown in the event of a precondition violation. This is a failure by the API client to stick to the API contract. Document unchecked exceptions but do not declare them in the method declaration. This helps programmers looking at your program to clearly distinguish between checked and unchecked exceptions.
- document unchecked exceptions in interface methods

CHECK PARAMETERS FOR VALIDITY
- precondition checks - Think about parameter restrictions when writing new methods or constructors. 
- for non-public methods use assertions.

Assertions
- help detecting errors during developmental phase
Robustness - ability to withstand errors even in exceptional situations -> possible with exceptions and exception handling
Correctness - ability of software to function properly -> improved via assertions

- we write our code based on the needs of our product managers. In the process we make some assumptions some of which are right but some of which may be wrong.
We want to detect those incorrect assumptions at development time itself
Thus an assumption is either right or wrong ie it is a boolean expression and we need to test it

Syntax: assert boolean-expression 
eg assert index > 0;
If assertion is correct, program continues running. If false, then an AssertionError is thrown and the program is terminated immediately.
AssertionError is a subclass of the Error class and is from the java.lang package

Syntax: assert boolean-value: error-message;
eg assert index > 0: "index is negative"
In this case, if an AssertionError is thrown, it is initialized with an error message -> AssertionError(error message)

Benefits
- effective in detecting bugs during development
- serve as documentation - can be better than comments in some situations as they still test validity of statements even if the logic or computation changes so they do not need to be regularly adapted as do comments ie comments can get out of date. If we use assertions instead, when they fail they force us to update them and thus they are like active comments.

Assertions are really good at validating parameters when there are restrictions to them. 
For public methods, you can throw an unchecked exception if there is a violation of a precondition. This is because we know that this would be a programming error from the API client. Do not use assertions for public methods for 2 reasons:
1. assertions are disabled by default - so there won't be any parameter validity checks and consequently any programming errors from API clients may go unnoticed
2. assertions throw a universal AssertionError which may not be helpful for API clients in fixing the problem.

For non-public methods, use assertions. This is because the API clients are not invoking them directly. It is the internal code that invokes them instead. The owner of the code is expected to test the methods rigorously during development with the help of assertions. This way, in production, non-public methods should always invoked with correct paremeter values.

But what about JUnit?
- Assertions complement unit testing
- JUnit mostly targets blocks of code or functions whereas assertions are much more granular.

On production systems, assertions are disabled by default to ensure that they are not a performance liability. Can be enabled by the command line option -ea (or -enableassertions) which can be passed to the interpreter
They can be disabled using the option -da
Assertions can be enabled or disabled at class and package levels eg

java -ea:com.semanticsquare.Hello MyClass

In the above code they have been enabled only for the class Hello
Another example:

java -ea -da:com.semanticsquare.Hello MyClass 

The above code enables assertions for all classes but disables it for the Hello class

To disable for all classes in a certain package (and its subpackages) you can run:
java -ea -da:com.semanticsquare... MyClass

The 3 dots here suggest a package and its subpackages
JUST HAVING -da BY ITSELF HAS NO EFFECT AS ASSERTIONS ARE DISABLED BY DEFAULT

To enable assertions using Eclipse:
1. Make sure you are in the file with the main method
2. Run -> Run As -> Arguments -> Enter "-ea" (or other forms of it) in the VM arguments section -> Click Apply -> Run

Input/Output
Java comes with 2 I/O packages:
- java.io - also called StreamIO
- java.nio - new IO (since Java 4)

Steam IO has 2 sets of packages: Byte Streams and Character Streams
Character Encoding
Fundamentally all files are binary. All files look alike to hardware. However, software can make a distinction thus certain software handles certain files eg text editors for .txt and Paint for .jpg
Computers use hexadecimal numbers to represent characters eg 'a' -> 61(hex) -> 01100001
A single byte can be any of 256 patterns (2^8). To represent more characters, more bytes are needed and that is where encoding schemes come from.
Every file uses some encoding scheme to represent its characters. An encoding scheme is an algorithm which maps characters to a hexadecimal number whose binary is saved

character <---> hexadeximal <--> binary
Encoding: 'a' --> 61 (hex) --> 01100001
Decoding: 01100001 --> 61 --> 'a'

Examples: ASCII, UTF-16, UTF-32
Variations in encoding algorithms led to decoding issues
Advent of internet made it worse. That is when the Unicode character set was invented

Unicode
Maintained by Unicode Consortium.
Backward compatible with 7-bit ASCII
Initial assumption:
- 16 bits for 65536 chars would suffice - Basic Multilingual Plane (BMP)
- the used exactly 16 bits to represent any character
But it was realized that there were more characters thus other encoding schemes were
created eg UCS-4, UTF-32
According to Wikipedia, Unicode covers 120 000 characters from 129 scripts
Unicode character set has 2 parts - BMP and Supplementary characters(Non-BMP)
BMP has 65 536 characters whilst non-BMP has around 55 000 characters. The hexadecimal code that represents each character is called a code point.
To represent a single BMP character, one 16 bit code point is used. To represent a non-BMP character, two 16-bit code points are used.
BMP codes range from U+0000 to U+FFFF
Non-BMP codes range from U+10000 to U+10FFFF

UTF-16 and UTF-8 are popular implementations of Unicode. UTF stands for Unicode Transformation Format
UTF-16:
-Variable length eg BMP: 2 bytes, Non-BMP: 4 bytes
-BMP Codes -> 1-1 correspondence
-Non-BMP Codes -> Surrogate pairs (higher and lower) eg \U1F602 == D83D DE02
-Used by Java, C#, Python etc

UTF-8
-Variable length
	  ASCII chars (0-127): 1 byte
	  Others: 2 - 4 bytes
	  Non-BMP: 4 bytes
-favored for English since it only needs one byte for each character whereas UTF-16 uses 2
-most popular. Half of web uses it
-designed by Ken Thomson, the creator Unix and B programming language (B is the direct predecessor to C language)

Endianness
In UTF-16, since the basic unit is 2 bytes, there can be 2 ways in which those bytes are stored in memory:
Big Endian (BE) - most significant byte (MSB) stored at lowest memory address (this is the most common format and the default one too)
Low Endien (LE) - MSB stored at highest memory address 

Byte Order Mark(BOM). Used to identify if the encoding is Big Endian or Low Endien. For that it uses a special unicode character
- BE ~ FEFF
- LE ~ FFFE

These byte order marks are placed at the beginning of a data stream and that would tell if the data stream is big endian or low endian.
eg data stream for "Hello" is as follows:
"Hello" -> 0048 0065 006C 006C 006F
BE -> FEFF 0048	0065 006C 006C 006F
LE -> FFFE 0048	0065 006C 006C 006F

Always decode using same or compatible encoding scheme
Databases generally do not accept storing of non-BMP characters and will throw an error when this happens.

Stream IO
Stream is a connection to a data source/storage. Stream can be input/output
Stream operations
1. open stream
2. read/write
3. close stream

Closing stream frees up the resources that the stream is using and avoids resource leaks. Operating systems have limits to the number of sockets or file handles that can be run simultaneously.
Standard template for IO

FileInputStream in = null;
try{
	in = new FileInputStream(filename); // open stream
   	//read data
   } catch(FileNotFoundException e){
     ...
   } finally{
	try{
	    if(in != null)
	    	  in.close();
	  }catch(IOException e{ ... }
   
}

We can use the try with resources block
try(FileInputStream in = new FileInputStream(filename)){
   //Read data
}catch(FileNotFoundException e){
 ...
}catch(IOException e){
 ...
}

close() method is handled implicitly. Compiler implicitly adds the finally{...} block. Note that in the try-with-resources block, the variable in is final and also that the class FileInputStream must implement java.lang.AutoCloseable interface. This feature is referred to as Automatic Resource Management (ARM).

We can also have multiple resources being created:
try(FileInputStream in = new FileInputStream(filename);
    FileOutputStream out = new FileOutputStream(filename)){
    //read data
} catch(FileNotFoundException e){
  ...
} catch(IOException e){
  ...
}

Streams Classification
Streams are of 2 types: Byte streams or Character Streams
	       	 	     Object
InputStream 	OutputStream	|	Reader		Writer
	Byte Streams		|		Character Streams

The reason for having these 2 types of streams is because Java differentiates between processing characters and everything else.

Byte Streams
-read/write raw bytes serially
-character streams are built on top of byte streams
InputStream
- Base abstract class for all byte input streams
- reads data in groups of 8 bits (1 byte)
eg abstract int read() throws IOException 
   - this function reads 1 byte and returns as int between 0 & 255 (2^8-1)
   - returns -1 if end of stream is detected
   eg for 'a' read() would return 97
Read Operation - is when we are reading groups of bytes
     int read(byte[] b, int offset, int length) throws IOException
     	 - a byte array is passed to this method and it will read up to length number bytes into the array starting at the offset
	 - if number of bytes that can be read is less than length, then those will be returned
	 - method returns the total number of bytes read or -1 if end-of-stream detected
	 -internally, it repeatedly invokes the read() method implemented by the subclass(remember that the read() method from InputStream is abstract)

another read method int read(byte[] b) throws IOException -> this method calls the previous read(byte[] b, int offset, int length) with offset = 0, length = b.length
Note that all read calls would block when no data is available ie if no data is available, the method will wait until the data becomes available. For example, if we are reading data on the network and the other end is not sending data. In this case the method will block.

OutputStream 
- base abstract class for all byte output streams
- used to write data in groups of 8-bits (1 byte each)
- abstract void write(int) throws IOException
-Notice that the input parameter is an int which has 32 bits. But this method needs to write only on byte so it writes the least significant byte -> rightmost 8 bits. The other 24 will be discarded.
second version of write void write(byte[] b, int offset, int length) throws IOException
- write length number of bytes from array starting at offset.
- internally repeatedly invokes write()

third version:
      void write(byte[] b) throws IOException -> calls write(byte[] b, int offset, int length) with offset = 0 and length = b.length

InputStream Hierarchy
				____________
				|InputStream|
				-------------
ByteArrayInputStream		FileInputStream			PipedInputStream
		FilterInputStream		ObjectInputStream
BufferedInputStream	DataInputStream

OutputStream Hierarchy
				---------------
				| OutputStream |
				---------------
ByteArrayOutputStream		FileOutputStream		PipedOutputStream
		FilterOutputStream	       ObjectOutputStream
BufferedOutputStream	DataOutputStream
		PrintStream

Reading Byte-Oriented Files Efficiently
- these are files containing non-textual data like images
- the FileInputStream and FileOutputStream classes provide implementation of the read and write methods.
- creating a FileOutputStream:
  	   FileOutputStream(String filename) throws FileNotFoundException
-this creates a new file if file does not exist. If file exists, it will overwrite it
- FileInputStream does not create a new file if it does not exist - constructor will throw a FileNotFoundException which makes sense for the input case
For the output case, what are the reasons that FileOutputStream(String filename) throws a FileNotFoundException?
    - file cannot be created for writing
    - file is actually a directory
    - file exists but cannot be opened for reading/writing
read()/write() is Expensive
 - reading/writing single bytes is grossly inefficient. Similar to shopping without a cart and carrying each item one by one to checkout.
 - the programming equivalent of the shopping cart would be Buffering. In buffering, you read blocks of bytes into a memory buffer, then you read from that buffer. This is much faster than reading from the disk.
 - similarly, you can write blocks of bytes to a buffer then flush all of that data to the disk all in a single IO operation. 

-> to do buffering there are two classes: BufferedInputStream & BufferedOutputStream
- these classes are subclasses of FilterInputStream & FilterOutputStrem respectively, which then subclass InputStream and OutputStream
- memory buffer referred to here is a simple byte array. Default buffer size is 8192 bytes. This size can be changed with constructors
- BufferedInputStream & BufferedOutputStream do not work independently as they only offer buffering as their core functionality. They take no responsibility with dealing with files directly on the disk - this is handled by FileInputStream and FileOutputStream
- thus to work with buffering, the buffered stream has to be chained to another stream eg BufferedInputStream & FileInputStream

Chained Streams
- thus to work with buffering, the buffered stream has to be chained to	another	stream eg BufferedInputStream & FileInputStream
In terms of code this is how it looks:
BufferedInputStream b = new BufferedInputStream(new FileInputStream("file.jpg"));
- The BufferedInputStream has a constructor which takes an InputStream object as input and that is how the two classes are chained
This is called a decorator design pattern. Here BufferedInputStream is called the decorator as it is decorating the FileInputStream object with additional (buffering) functionality. 
Decorator is also referred to as a wrapper class as it is wrapping another object. 
The open-closed design principle serves as motivation for the Decorator pattern. According to the open-closed design principle, classes should be open for extension but closed for modification. 
That is what is happening as we are adding new functionality by simply chaining classes rather than modifying them thus avoiding the possibility of making new bugs.
How are these classes open for extension?
- both decorator and the class being decorated must have a common supertype eg BufferedInputStream and FileInputStream both have a common supertype InputStream
-now we can pass around a BufferedInputStream object in place of a FileInputStream. The read method can be invoked as if it was invoked on the FileInputStream object. The read method of the BufferedInputStream object will give us the buffering benefit. Internally, it accesses the read method of the FileInputStream class and will buffer the bytes read. The logic is as follows:
- the read method in the BufferedInputStream is as follows
     synchronized int read() throws IOException
     		  if(buffer has unread data)
		  	    return first unread byte
		  else
			fill-buffer <-- in.read()
It is basically an implementation of the abstract read() method in the InputStream class. It invokes the read method of the underlying stream ie FileInputStream
- so by having a common supertype, we are able to extend the read() functionality of the FileInputStream class by providing buffering as an additional capability.
Note the keyword "synchronized" in the method declaration which is a multithreading feature used to avoid data corruption. Because the method is synchronized, JVM has to make sure that only one thread is able to access it at any given time. So some additional checks are being performed thus causing a slow excecution speed.
Due to this, the second version of the read method can be used where bytes are read in groups.
second version: synchronized int read(byte[] b, int offset, int length)

-reads length number of bytes from buffer into array starting at offset
- returns number of bytes read or -1 if end-of-stream detected
- this method has fewer invocations since we are reading in groups

Under the hood
      if(buffer has requested data)
      	b <-- buffer
      else
          if(buffer has partial data)
	      b <-- buffer.partial
	      fill-buffer <-- in.read(buffer, buffer-offset, buffer-length)
	      b <-- buffer.remaining
	  else // buffer has no unread data
	      if(buffer.length > b.length){
	      	    fill-buffer <-- in.read(buffer, buffer-offset, buffer-length)
		    b <-- buffer
	      else
	          in.read(b, offset, length)

Write Operation
      synchronized void write(int) throws IOException
   - data is written to buffer
   - flush buffer to underlying stream if not enough space
   - second version: synchronized void write(byte[] b, int offset, int length)
     - writes length number of bytes from array starting at offset into buffer
     - if buffer does not have enough space, then the buffer contents are flushed and then the array contents are copied into the buffer. Note that for flushing, the write method of the underlying stream method is used --> write(buffer, 0, count) by passing the buffer as the argument where count would be the index of the last byte not yet returned to the stream
if(b.length >= buffer.length){
    flush-buffer -> out.write(buffer, 0, count)
    out.write(b, offset, length)

When the close method is invoked on the decorator, it internally invokes the close method of the underlying decorated stream. If decorator is BufferedOutputStream, then a flush method is first invoked to clear the buffer.
If the underlying stream is in turn a decorator, then it would inturn invoke the close method on the object that it is decorating. Note here that chaining is not restricted to 2 classes. 

Character Streams
- to read/write character data
- built on top of byte streams since everything is binary
- Reader and Writer serve as base classes for all character oriented streams.
Reader class
- reads 16-bit char data in UTF-16 format
- int read() throws IOException -> reads 1 char and returns int between 
0 - 2^16 (65535)
- returns -1 if end-of-stream is detected
- second version abstract int read(char[] cbuf, int off, int len) throws IOException
   - reads length number of characters in to array starting at offset
   - returns total number of characters red or -1 if end-of-stream is detected
-Recall that all read calls will block until the data is available or some IOException is generated or they reach the end-of-stream.

Writer
- base abstract class for all character output streams
- used to write 16-bit character data to a sink (may use another character format)
- void write(int c) throws IOException
       - method writes a single character -> lower 2 bytes
- second version void write(int[] c, int offset, int length) throws IOException
       - writes length number of characters from array starting at offset

Reader Hierarchy
				 ______
				|Reader|
				--------
CharArrayReader	StringReader	InputStreamReader  BufferedReader  FilterReader
				FileReader	   PipedReader

Writer Hierarchy
				 ______
			        |Writer|
				 ------			       
CharArrayWriter  StringWriter  OutputStreamWriter  BufferedWriter  FilterWriter
		 	       FileWriter	   PipedWriter	   PrintWriter

The decorator pattern is used to facilitate reading. In this pattern, classes use other classes as input and add functionality to those unique instances only
eg 
   StringBuilder text = new StringBuilder();
try(BufferedReader in = new BufferedReader(new InputStreamReader(new FileInputStream("file.dat"), "UTF-8")){
   String line = null;
   while((line = in.readLine()) != null){
   	       text.append(line).append("\n");
	       }
}catch(UnsupportedEncodingException e){
   e.printStackTrace();
}catch(IOException e){
  e.printStackTrace();
}

Here FileInputStream reads the bytes from the file, passes them to InputStreamReader which decodes the bytes to characters, by a specified encoding format (here UTF-8) and BufferedReader makes the process more efficient by storing the characters in a buffer, and flushing them every so often.

If working with just text, one can also use the simple Scanner class to work with files and console input. Scanner's constructor can be called with a File object:
eg Scanner in = new Scanner(System.in);
in.nextLine() --> reads from console and returns string
in.nextInt(); in.nextDouble(); in.hasNext() --> boolean
in.close();

Scanner can also work with files
Scanner infile = new Scanner(new File("data.dat"));
while(infile.hasNext()){
	System.out.println(infile.nextLine());
}
infile.close();

Since Scanner was created with File argument, it will create FileInputStream internally and will close it automatically. File object does not need closing since its not a Closeable resource. Thus Scanner can be used in a try-with-resources block.

Writing to a file is similar:

try(BufferedWriter out = new BufferedWriter(new OutputStreamWriter(new FileOutputStream("blank_file.txt"), "UTF-8")){
		   out.write();
}catch(UnsupportedEncodingException e){
   e.printStackTrace();
}catch(IOException e){
   e.printStackTrace();
}


or

The File Class
Useful for manipulating files on the system

File f = new File("go.txt");
File instance represents a path, not the contents of the tile. Here "go.txt" is referred to as a path name.
FileInputStream and FileOutputStream have constructors that take a File object as input.
		    	Windows	     Unix
Directory Separator	\	     /
Root	  		C:, D:	     /
Line Separator		\r\n	     \n

Pathname - can be absolute or relative
	 absolute -> points to the same path location regardless of the currrent
	 working directory
	 relative -> relative to current user
	 User directory/current working directory -> user.dir system property. Directory in which the Java interpreter is running
File methods
getAbsolutePath() --> returns absolute path
getCanonicalPath() --> returns the simple path name (no ...)
createNewFile() --> will try to create a new file and return true if successful. If
		    file is already there, it returns false

Get file members:
separator --> returns a string representing the directory separator for that given operating system
separatorChar --> returns a character representing the directory separator for that system
getParent() --> returns parent directory
lastModified() --> returns the time in milliseconds from Jan 1, 1970 when the file was modified
exists() --> boolean
isFile() --> boolean
isDirectory --> boolean
length() --> returns size of the file in bytes
System.getProperty("user.dir") --> prints working directory
mkdir() --> create directory [only creates a single directory]
mkdirs() --> creates a nested directory structure
delete() --> delete directory [deletes if directory is empty and returns true otherwise false]
renameTo(new File("new_name") --> rename current file to specified name
renameTo(new File("new_dir//new_name") --> moves file to that directory and name

dirFilter(true/false)
list() -> returns a String array of the names of folders and files in the directory
- you can pass an object for filtering the names. This object must come from a class that implements the interface called FilenameFilter eg

class JPEGsOnly implements FilenameFilter{
      public boolean accept(File file, String){
      	     return name.endsWith(".jpg") || name.endsWith(".JPG");
	}
}

eg File	documents_folder = new File("/home/user1/Documents");
   documents_folder.list() --> lists all files in Documents folder
   documents_folder.list(new JPEGsOnly()); --> returns only files ending with ".jpg" or ".JPG"


Serialization & Deserialization
Sometimes we need to save regular objects into files and open them up at a later time in the same state. Typically you save object state to a database but there are times when saving on the disk is handy.
Serialization is the process of writing Java objects to some destination - that is, Java objects get saved as byte streams.
Deserialization is the reconstruction of Java objects back from their byte stream. Serialized objects can also be transferred across JVMs.

To serialize an object, its class has to implement java.io.Serializable. To perform the actual serialization, we use the classes ObjectOutputStream. For deserialization, we use ObjectInputStream. 
ObjectOutputStream implements ObjectOutput interface whilst ObjectInputStream implements ObjectInput interface

Serialization Example
ObjectOutputStream out = new ObjectOutputStream(new BufferedOutputStream(new FileOutputStream("object.ser")));
out.writeObject("Only objects from classes that implement the Serializable interface, can be serialized eg String and Date");
out.writeObject(new Date());

- convention is to write serialized object files with suffix ".ser" but it is not required
ObjectInputStream in = new ObjectInputStream(new BufferedInputStream(new FileInputStream("object.ser")));
String s = (String)in.readObject(); //returns an Object instance and needs proper downcasting
Date d = (Date)in.readObject();

Objects need to be read in the same order in which they were serialized.

Use cases of serialization
- high traffic web pages with frequent reads than writes
  - serialize to disk or perform caching eg memcached. when the webpage is visited the first time, we can create a Java object that is serialized and stored on the disk and then on subsequent visits the website can be built using the serialized object avoiding database read operation and object construction.
-passing Java objects to remote hosts -> you can serialize the object and pass to the web service. Web service will in turn deserialize the object.
- postmortem analysis -> if an object is causing an error, you can serialize that object and later deserialize it with a debugger to see why it caused those errors.

Serialization Facts
- primitives & arrays are serializable by default
- serialization saves the entire object graph -> if an object is serialized, any object it references and any objects those objects reference will also be serialized.This means that if even one of of the objects in the objects graph doesn't implement Serializable, serialization will fail.
- if the same object is referred to multiple times on the object graph, it is saved only once
- STATIC variables are NOT SERIALIZABLE -> this is because Serialization is about object state. This means that during deserialization, a static variable will be assigned the value that the class has at that particular time, not when the object was serialized.
- if a Superclass is serializable, then the subclasses are automatically serializable. If superclass is not serializable, subclasses are still free to implement the Serializable interface and be serializable.
- if you do not want a particular instance variable to be serialized, you can mark it with the keyword "transient" during its declaration. During serialization, this variable's value will be skipped. During deserialization, the variable will be given a default value based on its type eg objects --> null, int --> 0
Deserialization Process
-read serialized object
-find serialized object's class name and load Class object
-Deserialization fails if:
		 - Class object cannot be loaded
		 - version mismatch eg if new fields are now present in class or old
		   ones have been deleted thus making the class and the serialized
		   object incompatible. Class has evolved after object was serialized
-create new object on heap & restore its state -> object's constructor is not run since that would create a brand new object rather than recreate object with same state. If there is a non-serializable ancester then run ancestor's constructor and any constructor of all its direct and indirect superclasses (even if those are serializable)
- instance variables get serialized state
- transient variables get default values

serialVersionUID
-every serializable class gets a version ID computed from class structure
-this version id is stored in the .class file. Thus whenever the class structure changes, the version id also changes
-this version id is called serialVersionUID. This version id is not generated for non-serializable objects.
-when a serialized object is generated, the object is stamped with the serialVersionUID that the class had at that time.
- during deserialization, serializedObj.serialVersionUID == class.serialVersionUID
   - if true deserialization passes, otherwise, it fails
Challenge: How can we still make deserialization work even after class has evolved?
-Solution: make serialVersionUID constant even if class evolves eg
	   static final long serialVersionUID = 888888353586783L;
-where do we get the long number? you can run the serialver command on the .class to get the version at the time of serialization then you can make the serialVerionUID of the class a static final long variable of that value

Changes that do not affect deserialization (by hard-coding serialVersionUID)
- add/delete instance variable
- make instance variable static
- change instance variable from transient to non-transient
-change access levels of variables
- add/remove classes to/from inheritence tree

Changes that affect deserialization:
-change instance variable's type
-make serializable class (anywhere in object graph) non-serializable

Collections Framework
-part of java.util package which includes classes representing sofisticated data structures.
-ready to use highly efficient data structures we can use, right out of the box without implementing them ourselves

Arrays and their limitations
-fixed number values
-not extendible
-element search is expensive - linear
-it is difficult to build software with just an array

General requirements needed when working with real-world data
- No knowledge about size
- automatically extendible
- fast random access
- fast lookups
- ordered vs unordered
- dublicates vs unique
- null vs non-null
- automatic sorting
- <key, value> mappings

Collections Framework
Contains:
- interfaces
- implementations of those interfaces eg ArrayList
- algorithmic classes eg Collections

Core interfaces include:
______________________________                      _______________
|	Collection	     |			    |	Map       |
------------------------------			    ---------------
|List	Set		Queue|			    |	SortedMap |
|	SortedSet	Deque|                      ---------------
|____________________________|
Collection represents a collection of objects whilst Map represents a collection of key,value pairs.
These interfaces allow us to define common protocols and thus give us the benefit of polymorphism which allows us to manipulate collections independently of implementation
Commonly used implementations:
- ArrayList, LinkedList
- HashSet, TreeSet, LinkedHashSet
- ArrayDeque, LinkedList
- HashMap, TreeMap, LinkedHashMap

Note that the names are quite similar for Set and Map implementations. This is because Set implementations internally use Map implementations.
The interfaces SortedSet and SortedMap ensure that all the data in them is sorted and placed in the appropriate position.
All the implementations in the Collections class are Serializable, implement clone() an d most allow nulls. 
Note that there are are legacy implementations Vector, Hashtable and Stack which are synchronized. Earlier implementations were not synchronized however it is recommended to not use them as synchronization slows operations and it is recommended that it be added externally.
Instread of Vector -> use ArrayList, Hashtable-> HashMap, Stack -> ArrayDequeue

Collection Interface
It is the root of the Collection hierarchy
- represents a collection of objects
- polymorphically provides maximum generality so whenever possible, you should use it to reference objects
- some of its implementations eg ArrayList allow duplicates and some don't
- some collections are ordered and others unordered
- Collection interface has different subinterfaces but it has one direct subclass called AbstractCollection -> provides a skeletal implementation of the Collection interface[ recall that skeletal implementation help to minimize the work required to implement interfaces ]
declaration:
	public interface Collection<E> extends Iterable<E>{ ... }
Collection interface extends another interface which enables its objects to be used in for:each loops. Iterable is from java.lang and contains one abstract method called iterator() which a subclass has to implement if its instances are to be able to be used in for:each loops

Collection interface contains several fundamental method common to all collections and they can be broadly classified into 3 categories:
1. Basic Operations
2. Bulk Operations
3. Array Operations

Basic Operations eg
public interface Collection<E> extends Iterable<E>{
       boolean add(E element); //optional - boolean if it could add. Is optional operation because a subclass need not support it. It can define an empty method and throw an UnsupportedOperationException to indicate that it does not support the add method.
       boolean remove(Object element); //optional
       boolean contains(Object element); - basically the search method
       int size();
       boolean isEmpty();
       Iterator<E> iterator(); --> returns an instance of Iterator which helps in iterating elements of collection
}

Bulk Operations eg
public interface Collection<E> extends Iterable<E>{
       boolean addAll(Collection <? extends E> c); // optional - adds all elements in the input collection object into the current collection
       boolean removeAll(Collection<?> c); //optional - removes all elements in the in\
put collection object from the current collection
       boolean retainAll(Collection<?> c); //optional - retains all the elements present in the input collection object and deletes all teh others from the current collection
       boolean containsAll(Collection<?> c); --> returns true if the current collection contains all the elements in the input collection
       void clear(); // optional --> remove all elements in collection

Array Operations eg
public interface Collection<E> extends Iterable<E> {
       Object[] toArray();
       <T> T[] toArray(T[] a); --> type of return array is the same  as the type of the input array. The input can also be a subtype or there will be an error.
       // eg String[] a = c.toArray(new String[0]); 
}
- array operations act as bridge operations between the collections classes and the arrays

List Interface
- useful when sequence/positioning matters
- models resizeable linear array with indexed access
- zero based
- can have duplicates
declaration:
		public interface List<E> extends Collection<E> { ... }
In addition to methods inherited from Collection, it also adds new ones. These additional ones are in 4 categories:
1. Positional
2. Search
3. Iteration
4. Range-view

Positional Operations
public interface List<E> extends Collection<E>{
       E get(int index);
       E set(int index, E element); // optional -> inserts an element at a specified index and returns the element previously stored at that index
       void add(int index, E element); // optional -> adds element at specified index
       boolean add(E element);  //optional --> adds to end of the list
       E remove(int index);  //optional
       boolean addAll(int index, Collection<? extends E> c); //optional
}

Search Operations
public interface List<E> extends Collection<E> {
       int indexOf(Object o); --> return index of first occurrence of element or -1 if not in list
       int lastIndexOf(Object o); --> index of last occurence of object or -1 if element not found in list
}

Iteration Operations
public interface List<E> extends Collection<E>{
       ListIterator<E> listIterator(); --> returns an instance of ListIterator interface[a subinterface of Iterator interface]
       ListIterator<E> listIterator(int index); --> returns instance of ListIterator interface
}

Range-view Operations
public interface List<E> extends Collection<E> {
       List<E> subList(int fromIndex, int toIndex); --> returns a subset of the list which is in the specified range (toIndex is exclusive so element at that index is not returned). The returned list is backed by the original list so any changes made to the return list will be reflected in the original list.
}


ArrayList
- an implementation of the List interface. One of the most commonly used data structures
- it is a resizable array implementation of a List interface. 
- since an array is used internally, it has a default capacity. This capacity is set at 10. When capacity is reached, a new array which is about 50% larger than the previous one is created and elements are copied to it.
- if dealing with a high initial capacity of elements, then you can declare the list with a high starting capacity using the constructor ArrayList(int initialiCapacity) or the method ensureCapacity(int) before adding a large number of elements.
-allows storing duplicates and null values.

Typical uses of ArrayList
- simple iteration of elements eg elements fetched from database
- fast random access ~ O(1) --> size of collection doesn't matter
- appending elements or deleting LAST element ~ O(1) --> ArrayLists are very good at this operation. Note that if ArrayList size has been reached, then appending an additional element would trigger array resizing so in that case there will be additional time involved.

add & remove Methods
add(index, element)
  - when we add an element to a certain position, all the elements following it, will be shifted right by one position
  - O(n) [in the worst case if we are placing an element at the 0th position, then all n elements will be shifted right]

remove(index)
- all elements following that index will be shifted left by one position
- O(n) [in the worst case if we are removing an element at the	0th position, then al\
l n elements will be shifted left]

Search - contains() & indexOf()
- contains() - boolean result of (is specified element in the ArrayList?)
- indexOf() - returns index of specified element if in ArrayList, otherwise 0
-both methods scan the ArrayList from its beginning thus in the worst case the operations will take O(n)
- these methods also use the equals() method to compare the input element with each element in the list. The equals method is from the Object class and can be overwritten by any subclass
- IF THERE ARE FREQUENT SEARCHES CONSIDER USING A SET IMPLEMENTATION eg HashSet can search for an element in constant time

removeAll()
- removes all elements shared between the input collection and current collection.
- invokes the collection.contains() on every element
  - if element is present -> uses the collection.remove() method
  - thus it can be worse than O(n^2) as it has the following operations:
    - O(n) for traversing the current list
    - O(n) for calling contains() [if collection is list implementation]
    - O(n) for element shift on remove. LinkedList and HashSet are better for removal
retainAll() has identical peformance issues to removeAll()

Constant Time (O(1)) methods in ArrayList
- size()
- isEmpty()
- set() & get()
- iterator() & listIterator()

Demo of ArrayList
 Collection<Integer> list1 = new ArrayList<>(); --> here we set the object to Collection because it gives us more flexibiliby on the implementation due to polymorphism. Thus we could one day change to linked list and allwe would do is change the declaration to: Collection<Integer> list1 = new LinkedList<>(); --> note that only the right side changes.

 list1.add(1);	     //add()
 list1.add(3);
 list1.add(null);	// can store null values

System.out.println("list1 = "+ list1); --> printing an ArrayList

list1.remove(3) // remove element at ith position
*note that if the element at the nth position is equal to null, the remove(n) will not work and it will instead remove the n-1th element. Note that the reason this does not work is that teh remove() method being used is not the one from our implememtation. Rather it is the one from the Collection interface. This is because of static binding at compile time. The compiler looks for a remove method that takes an int in the Collection interface and when it doesn't find it, it assigns a method with a compatible signature and binds it during compilation. In this case, it binds a remove that targets an actual Object rather than an index. 
At run time, the interpreter will find an object of type ArrayList but will look for a remove() method which takes an Object argument rather than the int one. Once it finds it first searches in its methods then up the inheritence tree, it will excecute that one and ignore the int one. So in the end, the remove we had was actually removing the element with value of 3 and not at position 3. 
In order to prevent this, we can the declaration type of the list to List rather than the more general Collection:
   List<Integer> list1 = new ArrayList<>();

list1.add(0, 10) --> add a new element with value 10 to the 0th position
list1.set(0, 20) --> set value of element at 0th position to 20. This returns the previous value at that position.

Bulk operations
making a new list:
       Collection<Integer> list2 = new ArrayList<>();
       list2.add(9);
       list2.add(3);

       list1.removeAll(list2); //remove all elements in list2 from list1
       
       list1.retainAll(list2); //keep only all elements present in list2 in list1

       list1.addAll(list2); // all in list2 added to list1
       
Search methods:
       list1.contains(1); // is 1 present in list1?
       list1.indexOf(1); //what position is the element 1 in? Similar to String indexOf
       list1.lastIndexOf(1)

Range-view
List<Integer> list3 = list1.subList(2,3);
list3.set(0, 6); -->list3 is backed by the original list so any changes made here will be reflected in the original
list3.add(0,7); // note that here we are adding 7 to position 0 in list 3 which is actally position 2 in list1. This addition will show in those respective positions for both lists.
Changing the original list also reflects in the created list. This is true except for adding new elements or removing new elements. -> we can only make non-structural changes

We can use the for:each loop to iterate through an ArrayList eg
for(int element: list1){
System.out.println(element);
}

However we cannot iterate using the for:each loop and try to make structural changes to the ArrayList eg
for(int	element: list1){
System.out.println(element);
	if(element == 9){ list1.remove(Integer.valueOf(element)); //use valueOf to create Integer boxed primitive object
}
This code generates a ConcurrentModificationException.
To make such structural changes whilst looping, we use an Iterator instance
Iterator
- an iterator is an interface. To use the iterator we need to access an instance of Iterator we need to invoke the iterator() method located in the Iterable interface from the java.lang package
The Collections interface extends Iterable and Collection implementations like ArrayList implement the iterator() method. By extending Iterable, Collections is indicating that its elements can be iterated. The for:each statement requires that any object iterates to implement the Iterable interface.

    public interface Iterable<T>{
    	   Iterator<T> iterator();
	   default void forEach(Consumer<? super T> action);
	   default Spliterator<T> spliterator();
	}

iterator() is abstract. The other two methods in the interface (forEach(), spliterator())) are default methods (which were written in Java 8) so they come with some minimal implementation. 
iterator() returns an Iterator which can be used to iterate the elements of the Collection. Internally, for:each statement also invokes this method when iterating the collection elements.
forEach() method can be invoked if are performing a certain action for each element of the collection. This action would be a method in an object which is passed  as input to the forEach() method, hence we can see that the parameter name for forEach(Consumer<? super T> action); is "action". So the method which is part of the input object will be invoked forEach of the elements in the collection. And that method's input will be the element itself, so the method would have a single parameter. Notice that the parameter type of the forEach(Consumer<? super T> action) is Consumer. Consumer is an interface introduced in Java 8 which has a single abstract method called accept(). So we need to pass an instance of Consumer which implements the accept() method or we can pass lambda expressions or method references which are Java 8 features.
spliterator() was also added in Java 8. It is useful for splitting the elements of collection into partitions so that we can process those partitions using separate threads. You can use this methods for parallel computation of a large sized collection.

The Iterator allows element removal during iteration. The iterator interface looks like this:
    public interface Iterator<E>{
    	   boolean hasNext();
	   E next();
	   void remove();
	   default void forEachRemaining(Consumer<? super E> action);
	}
If you evoke the iterator() method of ArrayList for example, it will evoke an instance of this interface. ArrayList can do this because it has a nested class which implements this interface. So an instance of that nested class will be returned when the iterator() is invoked
Iterator methods:
- has 4 methods outlined above:
  - remove() is used to remove an element
  - the forEachRemaining(Consumer<? super E> action); is similar to the forEach() method in the Iterable interface

  Iterator<Integer> iterator = list1.iterator();
  while(iterator.hasNext(){
    int element = iterator.next(); [automatically unboxed and assigned to int from Integer]
    if(element == 9){
    iterator.remove();
  }
NOTE: to use the remove() method, it has to be preceded by a next(); Otherwise, we get a compilation error
-> To remove an element whilst iterating through a collection, we need to use iterator

- iterators throw a ConcurrentModificationException is called a fail-fast iterator.
- all the general purpose implementations like ArrayList, LinkedList support only support fail-fast iterators

list1.forEach(System.out::println); note that :: are used to point to the method. Thus we can pass a method reference, lambda or an object which is an instance of Consumer interface. This instance must have a method called accept() which can be used for filtering. We can pass method references but internally the Consumer interface instance is create and its accept() method is given the method code so that the forEach() function can work.

forEachRemaining() is defined by the Iterable interface it is used  to update the rest of the elements whilst looping through

eg public class DontPrint{
   public static dontPrint(Integer i){
   System.out.print("...");
   }
}
   public class PrintIt{
   public static printIt(Integer i){
   System.out.println(i);
   }
}

Iterator iterator = list1.iterator();
while(iterator.hasNext()){
	int i = iterator.next();
	if(i < 3){
	iterator.forEachRemaining(PrintIt::printIt)
	else
	iterator.forEachRemaining(DontPrint::dontPrint);
 }

note that the forEachRemaining() can iterate over a collection on its own

List Iterator
The List interface has two methods that it supports that return instances of ListIterator
    ListIterator<E> listIterator();
    ListIterator<E> listIterator(int index); -> returns ListIterator starting from aparticular index in the current list

    public interface ListIterator<E> extends Iterator<E>{
    	   void add(E e);
	   void set(E e);
	   void remove();
	   -----------------------------------
	   |boolean hasNext();		     |
	   |E next();			     |
	   |boolean hasPrevious();	     |	bidirectional access
	   |E previous();		     |
	   |int nextIndex();		     |
	   |int previousIndex();	     |
	   ----------------------------------
	}

- when using Iterator, we can only remove elements.
- Using ListIterator, we can add new elements and set values of elements. Moreover, Listiterator supports bidirectional access so we can move forward or backward ie we have the regular hasNext() and next() but we also have hasPrevious() and previous() as well. There are also the fields of nextIndex() and previousIndex()
Due to bidirectional access the remove method will remove the element returned by the immidiately preceding call which has to be either next() or previous(); Otherwise, an IllegalStateException will be thrown. With Iterator it was only the next() method as there was no previous() option.
-similar semantics also apply for the set() method that is it updates the last element returned by next() or previous()
-add() method simply adds an element and updates the cursor position
-ListIterator is useful for traversing trees
Cursor position:
- the cursor is in between two elements so there is no concept of current element with ListIterator. That is why we only have next(), nextIndex(), previous() and prevousIndex() methods but not currentIndex().
So when we start an iteration and we invoke nextIndex() we get 0. If we try to get the previousIndex() whilst we are at the start of an iteration, it returns -1. If we invoke nextIndex() when we are at the end, then the size of the list is returned.

   List<String> list = new ArrayList<>();
   list.add("a");
   list.add("b");
   list.add("c");

   for(ListIterator<String> iterator = list.listIterator(); iterator.hasNext();){
   			    System.out.println("iterator.nextIndex: "+ iterator.nextIndex();
}

LinkedList
-singly linked list

class Node{
      int data;
      Node next;
      ...
}

first node is the head node

class LinkedList{
      Node head = new Node();
      void add(int data){
      	   Node newNode = new Node(data);
	   new Node.next = head.next;
	   head.next = newNode;
	}
}

Doubly Linked LIst
Nodes linked with next and previous nodes. head is linked to the first and last element
Has benefit of making the linked list act as a deque. A deque has frequent operations that allow us to manipulate the first and the last node.
If we want to look for an element at a particular index, then we only have to traverse through half of the list as we can choose the direction in which we want to travel from the head that will get us to the index in the shortest time.

class Node{
      int data;
      Node next;
      Node prev;
      ...
      }

class DoublyLinkedList{
      Node head = new Node();
      head.next = head;
      head.previous = head;
      void add(int data){
      	   Node newNode = new Node(data);
	   //set outgoing links
	   newNode.next = head;
	   newNode.prev = head.prev;
	   //set incoming links from head's previous prev
	   newNode.prev.next = newNode;
	   newNode.next.prev = newNode; //head.prev in this case
      }
}

Typical uses of doubly linked list
- frequent add/remove during iteration - when you remove or add an element to a doubly linked list, you only have to adjust the links at the point of insertion into the list. No need to shift elements like in ArrayList. Thus the DoublyLinkedList is better for the removeAll() & retainAll() operations since you have to remove elements as you iterate
O(n) Methods
get(i)
add(i,e)
remove(i)
indexOf(Object)
lastIndexOf(Object)

Note that for get(i), add(i, e) and remove(i), we must traverse the doubly linked list to get to that position so these operations are O(n/2) since we only have to traverse at most,n/2 of a doubly linked list.
This decision of the direction of traversal is made as follows:
     if(index <	 (size >> 1)){
     	            for(int i	= 0; i <= index; i++)
		    	          e  = e.next;
     }else {
       for(int i = size; i > index; i--)
         e = e.previous;
     }

Like an ArrayList, linked list also allows duplicates and null values

			ArrayList	LinkedList	DoublyLinkedList
------------------------------------------------------------------------     
get(i)			  O(1)           O(n)                 O(n/2)  
------------------------------------------------------------------------
add(i,e)
------------------------------------------------------------------------
remove(i)
------------------------------------------------------------------------
indexOf(Object)
------------------------------------------------------------------------
lastIndexOf(Object)
------------------------------------------------------------------------

LinkedList supports operations in Last-In-First-Out (LIFO) and First-In-First-Out(FIFO) in constant time - O(1)

List<Integer> list1 = new LinkedList<>();
With this change we can run all the previous commands exactly as they are with ListIterator and Consumer.

Queue Interface
- useful when manipulating head & tail
- elements are added at tail whilst they are removed/retrieved from head. Thus Queue is a first-in-first-out implementation (FIFO)
- can have duplicates.
- can have nulls but generally not supported. -> don't insert them if possible
- queues do not support indexed access to lists
- in addition to methods inherited from the Collection interface, Queue also has additional methods specific to its custom head and tail manipulations

               Throws exception	   	    	Returns special value
--------------------------------------------------------------------------------
Insert           add(e)				  offer(e) ~ false
--------------------------------------------------------------------------------
Remove		 remove()			  poll() ~ null if queue is empty
--------------------------------------------------------------------------------
Inspect		 element()			  peek() ~ null if queue is empty
--------------------------------------------------------------------------------

To insert an element to the queue we can use either add(e) or offer(e). Both return true if successful. If queue is a capacity restricted queue, then the add(e) method will throw an IllegalStateException while the offer method will just return false. Thus when working with capacity-restricted queues it is better to use the offer(e) method as it doesn't throw a runtime exception but instead allows us to perform some alternative action.
We can remove the head element using either remove() or poll(). If queue is empty, remove will throw an exception while poll will return a null value. Because poll() returns a null value when the queue is empty, that is why it is not recommended to insert null values into queues as it is no longer clear whether the value is null or if the queue is empty.
Inspection methods are element() and peek(). These return the head element but will not remove it. If queue is empty, then element will throw an exception whereas peek() will return null.

Deque
-extends the queue. In fact, it stands for Double-Ended Queue
-it allows items to be added/removed at both ends of the queue
-as it is a queue, it can model FIFO, but with the extra capability it can also model LIFO
-there is a legacy class called Stack but it has mostly been replaced by an ArrayDeque.
Implementations of Deque:
- ArrayDeque
- LinkedList
- ConcurrentLinkedDeque
- LinkedBlockingDeque
Deque methods
Methods that work on the last element(tail):
add(e)	| offer(e)
addLast(e) | offerLast(e)
removeLast() | pollLast()
getLast() | peekLast()

Methods that work on the first element(head):
remove() | poll()
element() | peek()
removeFirst() | pollFirst()
getFirst() | peekFirst()
addFirst(e) | offerFirst(e)

**Note that just like queue, deque supports these two versions of methods with the left version throwing an exception and the other returning a special value
Deque also supports methods which emulate the Stack class:
push(e) - same as addFirst(e)
pop() - removeFirst()
peek() applies to both queue and stack
by default, push(e), pop() and peek() were designed to be methods working with the head.If you want to use stack-like behavior but with the tail, then you use add(e), removeLast() and peekLast() methods
There are also methods like removeFirstOccurrence(Object) and removeLastOccurrence(Object) so if needed you can use these.
BlockingQueue
- these are queues where operations can block (wait on something).
- eg if we want to add an element into the queue and the queue is full, then the add(e) operation would wait until some space is available. Similarly, a remove operation would wait if the queue is empty until an element gets inserted.
- BlockingQueue extends the Queue interface
BlockingDeque
- extends both Deque and BlockingQueue

ArrayDeque
-an array implementation of a deque and it is resizable
-models both FIFO and LIFO
- added in Java 6
-can be created using ArrayDeque() or ArrayDeque(int)  or ArrayDeque(Collection)
     - it can be unbounded, or you can specify a size. You can also create it with elements from a specified Collection.
- unlike LinkedList, you cannot add null values to an ArrayDeque. And also, unlike LinkedList, ArrayDeque does not implement List
- it is preferred to use an ArrayDeque over LinkedList
  -from the Java doc of ArrayDeque ~ faster than LinkedList as a queue
  - 3X better than LinkedList for large queues. This is because with LinkedList we have to create an additional node object with every newly added element
    - LinkedList ~ node allocations overhead + GC cost: This is	because	with LinkedList	  we have to create an additional node object with every newly added element. Also, when an element is removed there is an additional Garbage Collection cost.

Why can't we use an ArrayList as a FIFO? eg add() and remove(0)?
- performance -> remove(0) on ArrayList would shift all elements. The severity increasing the more elements we have. For 1000 elements, LinkedList can be up to 20X faster.
- what about element shifts in an ArrayDeque? How are they any better given that an ArrayDeque is also an array?
  -> an ArrayDeque's implementation is based on a circular array thus we have no element shifts O(1)
-ArrayList should not be used as a queue due to intention. From a design perspective, the intention when using an ArrayDeque is to use it as a FIFO or LIFO which involve only head or tail manipulations. With ArrayList we do not constrain ourselves just to head and tail. 

Method Complexities
- most run in amortized constant time (mostly constant time)
- O(n)
  - remove(Object)
  - removeFirstOccurrence(Object)
  - removeLastOccurrence(Object)
  - contains(Object)

-Note that there is no way for us to add an object to the middle of the queue. We can delete elements internally though.

//create an instance of an ArrayDeque
Deque<String> deque = new ArrayDeque<>();
//use deque as a queue (FIFO)
      deque.add("walden");
      deque.add("harry potter");
      deque.add("head first java");

      //removing elements
      System.out.println("Printing Queue...");
      System.out.println(deque.remove());	//"walden" removeFirst() 
      System.out.println(deque.remove());
      System.out.println(deque.remove());	// deck is now empty

//use deck as a Stack (LIFO)
      deque.push("walden");
      deque.push("harry potter");
      deque.push("head first java");

      //removing elements
      System.out.println("Printing Stack...");
      System.out.println(deque.pop());	//"head first java"	
      System.out.println(deque.pop());
      System.out.println(deque.pop());	// deck	is now empty

* Note that a LinkedList can also implement a Deque thus our declaration above could have been
Deque<String> deque = new LinkedList<>(); 
This would have worked out just fine too. HOWEVER, it is recommended that you use ArrayDeque as it is faster.

Hash Table
- implements an associative array - associates keys with values
- data structure in which each element is an association between a key and a value. A collection of <key, value> pairs
- each key,value pair is called a mapping. The hash table is also referred to as a dictionary.

Key operations:
O(1) operations:
- insert<key,value>
-search by key
-remove by key
Characteristics
-cannot contain duplicate keys but it can contain duplicate values
-each key at most maps to 1 value
-certain implementations allow 1 null key. null values are fine. Some implementations do not allow any nulls at all for both keys and values
Implementation
Consists of an array containing references to linked lists which store the actual key-value mappings. Each slot in the array is called a bucket. Each linked list can have multiple mappings too.
For every operation on the hash table, the first operation is to quickly locate the target bucket. Then we need to traverse and search the list at that particular bucket.
To quickly look at the bucket for a given <key,value> pair, a function called Hash function is applied on the key.
Hash Function
-is a function of key and array-size [ f(key, array-size)] eg key % array-size
- transforms large space to smaller one eg if array-size is 25 and the key is 315 which bucket do we first look in? The answer is given by our hash function => 315 % 25 = 15

2-Step Hashing In Java
-generally hashing involves 2 functions

hash = hash(key.hashCode()) // hashCode() returns the memory value of an object converted to an int value
bucket # = hash & (length - 1) // once we get our int hash, a bitwise & is used in order to offset it into the hash table that is to find the target bucket [note that our array indices start from 0 and up so if we do not subtract 1, we would not properly place appropriate items in index 0]
the hash function itself can look like this 
int hash(h){ h^= (h >>> 20) ^ (h >>> 12); 
    return h ^ (h >>> 7) ^ (h >>> 4);
}

The hash function above may look very strange but recall that the main goal for the hash table is to operate in constant time. In order to do this, the hash function logic should be highly efficient. A function that uses several multiplications and divisions can be slow. Using bitwise and bitshift operations as shown in the above function will give us the performance benefit. 
The hash function should be able to quickly locate the bucket and uniformly disperse elements. If we only use the hash code of the key[ ie key.hashCode() ] instead of the hash function, there is a chance that several keys may get hashed into the same bucket which is called hash collision which is when a disproportionate amount of mappings are stored on the same linked list. This heaping of mappings to few linked lists will slow down the operations because once we find the bucket, we must perform a linear search inside that linked list to find the <key, value> pair we seek. The ideal situation would be to have one mapping per bucket but it is difficult to achieve in practice so we strive to minimize the hashmap collisions as much as possible. That is what the hash function is trying to do.

Insertion
- locate bucket for a given key
- check if bucket is empty 
  - if empty: add new linked list with our given <key, value> mapping
  - if not empty: check if linked list has another mapping with the same key
       	   	    - if no such mapping, then we add our mapping to front of the list
		    - if there is mapping, overwrite the old value with the new
Other performance factors
- besides a good hash function, there are other factors that contribute to performance:
  - capacity -> number of buckets in hashtable
  - load factor -> how full the hash table can get before its capacity is automatically increased. For HashSet, default capacity is 16 and load factor is 0.75 (meaning the table will not be resized until it is 3/4 full)
-in the case of an ArrayList, resizing is not a big issue as it involves creating a new larger array and copying the elements to it. With hashtable, we copy the contents but also the hash function has to be reapplied on all the keys again as the hash function is reliant on the length of the array too. So keys might get rehashed to new buckets.
- high load factor --> less frequent rehashing --> more lookup time
Hash tables are very widely used:
     - database indexing
     - NoSQL databases - they are based on key-value lookups
     - switch statement uses a hash table
-since elements are stored based on the hash function, a has table does not preserve the order of insertion.

Set & HashSet
Set interface
- extends the Collection interface
- models a mathematical set ie no duplicates
- useful when uniqueness & fast lookup matters
- HashSet is based on HashTable as it internally uses HashMap. 
- with List interface, element position was a criteria, that is insertion order is important. But with Set, insertion order does not matter but rather fast lookups and uniqueness.
-SortedSet is a subinterface of Set and it can additionally be useful for sorting the elements. So in addition to uniqueness and fast lookups, SortedSet can also help with sorting the elements.
-unlike List, Set does not add any new methods on top of what it inherits from the collection interface. However, because it does not allow duplicate methods, it places additional requirements on some of the inherited methods and constructors eg for the addAll() method is explicitly does not allow any duplicates.

HashSet
-is a HashTable based implementation of a Set interface
- internally uses a HashMaps with those <key, value> pairs
- since HashSet stores only individual objects, those objects will be stored as keys while an empty Object(an actual instance of the Object class) will be stored as a  value:
  key = element, value = new Object() 
-permits one null value

Typical Uses
- rapid lookup, insertion and deletion are done in close to O(1)
- insertion order is not important
- better for removeAll() and retainAll() than ArrayList. For ArrayList, each remove() execution has a linear time complexity due to element shifts. With HashSet, each remove will be done in constant time.

Declaring HashSet:
Set<String> set1 = new HashSet<>();
set1.add("a");
set1.add("b");
set1.add("a");
System.out.println(set1); // set1: [a, b] --> no duplicates
 
class Book{
      private String title;
      private String author;
      private int year;
}
//create identical instances of the same object
Book book1 = new Book("Moby Dick", "Herman Melville", 1851);
Book book2 = new Book("Moby Dick", "Herman Melville", 1851);

Set<Book> set2 = new HashSet<>();
set2.add(book1);
set2.add(book2);
System.out.println(set2); // assuming Book has a custom toString() method
			  // both book1 and book2 are added to the set even though they are logically equal. We need to set up the HashSet some more to prevent this
We know that HashSet internally uses HashMap which is based off of HashTable. HashTable uses a hash function in order to move into the HashTable and find the correct bucket number. In this case, if the second element is a duplicate then it needs to have the same hashCode() as the other one. In the case above, both of these objects will have different hashCodes(). The hashCode() method is defined in the collection class and it returns the memory address of a given object returning it as an int.
In our code above book1 and book2 are different objects so they have 2 different memory addresses and thus if we run the hashCode() method on them we get different values.
We need to override the hashCode() method so it returns the same value for identical objects eg
public int hashCode(){
       return title.hashCode();
}
Since the titles are the same (String pool) so this invocation will return the same hashCode(). 
If we run this, we still get duplicates in the HashSet. The reason is that we have overwritten the hashCode() method so both will have the same hashCode and will be brought to the same bucket. Initially book1 is added to the linked list. Then for book2 the HashTable will check if book1 is equal to book2 using the equals(Object) method in the Object class. This method uses the == operation which merely compares the object references and returns false. 
So we need to overwrite this equals() method method as well
eg public poolean equals(Object o){
     return (year ==(((Book)o).getYear())) && author == (((Book)o).getAuthor())) && title ==(((Book)o).getTitle()));
}

Thus, ALWAYS OVERRIDE hashCode() METHOD WHEN YOU OVERRIDE EQUALS

LinkedHashSet
- a Set implementation which uses a HashTable and a LinkedList.
- a HashSet does not preserve the insertion order however a doubly linked list can keep track of this
- extends HashSet and nearly as fast too! Slight slowness is due to the expense of mainintaining a linked list
  - search, insertion and deletion ~ O(1) just like HashSet
- permits only one null element just like HashSet. 
- internally uses a LinkedHashMap [HashSet uses HashMap]

Typical Use Cases of LinkedHashSet
- rapid search, insertion and deletion
- insertion order is important
- better than ArrayList for removeAll() and retainAll()

LinkedHashSet is generally slightly slower than HashSet for most functions but it is faster when it comes to iteration
  - this is because iteration of the LinkedHashSet is dependent on the size of the set ie the number of elements due to the use of the doubly linked list
  - in the case of HashSet, the iteration is based on capacity ie number of buckets in the HashTable. Thus in a HashSet, the number of elements could be less than the capacity but iteration still depends on capacity. In LinkedHashSet, iteration only has to do with the number of elements due to the doubly linked list

Set<String> hashSet = new HashSet<>();
hashSet.add("Raj");
hashSet.add("John");
hashSet.add("Anita");
System.out.println("hashSet: "+ hashSet); // hashSet: [John, Raj, Anita] insertion order not preserved in HashSet

Set<String> linkedHashSet = new LinkedHashSet<>();
linkedHashSet.add("Raj");
linkedHashSet.add("John");
linkedHashSet.add("Anita");
System.out.println("linkedHashSet: "+	linkedHashSet); //linkedHashSet: [Raj, John, Anita] insertion order preserved in LinkedHashSet

SortedSet and NavigableSet
-subinterfaces of Set
- recall that Set interface is all about uniqueness and fast lookup. SortedSet additionally provides the sorting capability
- NavigableSet is a subinterface of sorted set.
- sorting is a very important feature of any application
- per Java 8 API here is the definition of SortedSet
 
 public interface SortedSet<E> extends Set<E>{
    //Range-view
    SortedSet<E> subSet(E fromElement, E toElement);
    SortedSet<E> headSet(E toElement);
    SortedSet<E> tailSet(E fromElement);
    
    //Endpoints -return first and last elements
    E first();
    E last();
    
    //Comparator access
    Comparator<? super E> comparator();
    default Spliterator<E> spliterator();
}

subSet() method returns a subset of the original sorted set within the range fromElement - toElement (toElement is exclusive and will not be included in the return set)
if fromElement == toElement, then an empty set is returned. The returned set is backed by the original set so any changes to that one are reflected in the original one. Any changes made in the original set will also reflect int the returned set.
The returned set will throw an IllegalArgumentException if you try to insert an element into it which is beyond the range of the returned set [fromElement - toElement]
headSet() returns a set of elements that are less that the input toElement
tailSet() returns a set of elements that are greater than or equal to the input fromElement

comparator() method returns a Comparator which helps to keep the elements in the SortedSet, sorted. If a Comparator is not used, the comparator() method returns null meaning that the elements are sorted in natural order.

spliterator() - introduced in Java 8 and useful in splitting elements into partitions so we can process those partitions using separate threads.

SortedSet also has methods that it inherits so these are not the only ones.

NavigableSet
	public interface NavigableSet<E> extends SortedSet<E>{
	  //Closest matches
	  E lower(E);	 // greatest element < E
	  E floor(E);	 // greatest element <= E
	  E ceiling(E);	 // least element >= E
	  E higher(E);	 // least element > E
	  
	  //Iterators	 
	  Iterator<E> iterator();
	  Iterator<E> descendingIterator();
	  NavigableSet<E> descendingSet();
	  
	  //Endpoints
	  E pollFirst();
	  E pollLast();
	  
	  //Range-view
	  NavigableSet<E> headSet(E toElement, boolean inclusive);
	}

-can do everything that a SortedSet can do but also contains methods that return the closest matches for given search targets eg lower() method returns greatest element which is less than the target element, returns null if no such element is found.
- descendingSet() returns the reverse view of the original set.
- pollFirst() & pollLast - remove first or last element respectively and return it. Both return a null value if SortedSet is empty. These methods are identical to those in Queue and Deque interfaces.
- rangeview methods are similar those in SortedSet with an extra boolean parameter to indicate whether the returned values should be inclusive of the toElement or not.

TreeSet
- a red-black tree-based implementation of NavigableSet interface. Internally uses a TreeMap just like how HashSet internally uses a HashMap.
-TreeMap stores key-value pairs but since TreeSet has only elements, it will store the element as key and an empty Object as value -  key = element, value = new Object() (HashSet does the same)
- TreeSet elements will be unique and sorted (unique because it is a Set and sorted as it extends NavigableSet (which in turn extends SortedSet)).
- slightly slower than HashSet(O(1)) but still allows for fast lookup - O(log(n)) for add/remove/contains
Set<String> list = new TreeSet<>();
list.add("def");
list.add("abc");
list.add("111");
System.out.println(list);  // [111, abc, def] (sorted)
Recall that with HashSet the main concern is uniqueness and when using user-defined classes, this can be achieved by overriding the hashCode() method and the equals() method as well. With TreeSet the structure needs to be unique and fast as well but it also needs to be sorted. So there needs to be an order among the elements. There are 2 ways to do it:
1. Natural ordering -> uses interface java.lang.Comparable
2. use java.util.Comparator

Comparable interface has only one method called compareTo(). This method will specify an int value to specify where to place the element. When a new element is being added to the TreeSet, the compareTo() method is evoked on it to compare it to existing elements in the Set eg newElement.compareTo(oldElement). If compareTo() returns a 0, then the elements are duplicates and no insertion is done. If compareTo() returns a negative number, then the current element should be placed before the existing one. If compareTo() returns a positive number, then the element should be placed after the existing one so we move on to compare it to the next element.
Our user-defined class must implement Comparable and overwrite the compareTo method. This method will specify how the elements themselves need to be sorted. This is why it is called natural ordering as the rules of the ordering are specified by the elements themselves.

Second approach with Comparator
- here the sorting criteria comes from outside. You can create a new class that implements the Comparator interface. Override the int compare() method inside this class.
Then we need to pass the Comparator inside of the declaration of our TreeSet
eg Set<Book> books = new TreeSet<>(new TitleComparator());
- the advantage of using a comparator is that you can change the Comparator that you pass into the Set declaration at runtime eg if one user wants to sort books by title, then you pass in the new TitleComparator() and if they want to sort by author, then you pass in the new AuthorComparator(). When you pass an actual algorithm at runtime it is called a strategy pattern.

Other methods in NavigableSet interface (implemented in TreeSet)
      NavigableSet<Integer> set = new TreeSet<>();
      set.add(5);
      set.add(23);
      set.add(74);
      set.add(89);

      System.out.println("lower: "+ set.lower(74));			//5
      System.out.println("floor: "+ set.floor(74));			//74
      System.out.println("ceiling: "+ set.ceiling(74));			//74
      System.out.println("higher: "+ set.higher(74));			//89

      System.out.println("first: "+ set.first());			//5
      System.out.println("last: "+ set.last());				//89

      System.out.println("set: "+ set);				//[5,23, 74, 89]
      NavigableSet<Integer> descendingSet = set.descendingSet();
      System.out.println("descendingSet: "+ descendingSet);	//[89, 74, 23, 5]
      NavigableSet<Integer> headSet = set.headSet(74, false); [false meanse we are excluding the toElement = 74]

      System.out.println("headSet: "+ headSet); // [5, 23]
      //we said that any subset from the Set is backed by the TreeSet itself
      headSet.add(6);
      System.out.println("set: "+ set);			//[5, 6, 23, 74, 89]      
      System.out.println("headSet: "+ headSet); // [5, 6, 23]
      // if element is outside the range should throw an exception. Here headSet is getting anything less than 74 so if we try headSet.add(75), we will get a run time exception.
      
//    changes made in the original set will show in subset.
      SortedSet<Integer> subSet = set.subSet(5, 74);	//[5, 6, 23]
      set.add(18);	 
      System.out.println("subSet: "+ subSet);		//[5, 6, 18, 23]

We have reached the end of the Collection hierrarchy, now onto the Map hierrarchy

Map
-Map hierarchy is the second hierarchy in the Collections framework.

Map interface
______________________________                      _______________
|       Collection           |                      |   Map       |
------------------------------                      ---------------
|List   Set             Queue|                      |   SortedMap |
|       SortedSet       Deque|                      ---------------
|____________________________|

-maps store key-value pairs and these are useful for fast lookup by key eg data cache
-also called associative array
- no duplicate keys, duplicate values are fine
     1 key -> 1 value
- null key & null values - implementation dependent - some allow 1 null key, others none. Some allow null values, others no.
- Map comes with a skeletal implementation called AbstractMap. Implementations like HashMap extend this particular class. Note that there are other skeletal abstract implementations for other structures as well eg AbstractList, AbstractSet and AbstractQueue -> all 3 extend AbstractCollection
-similar to Collection interface, the Map interface has operations of the basic and bulk type. Map interface does not have Array operations like the Collection interface. Instead it has Collection View Operations.
- unlike Collection interface, Map does not extend the Iterable interface but the collection is still iterable

Basic Operations
      public interface Map<K, V> {
        V put(K key, V value);
        V get(Object key);
        V remove(Object key);
        boolean containsKey(Object key);
        boolean containsValue(Object value);
        int size();
        boolean isEmpty();
     }

V put(K key, V value) adds a value into the map. If there is a value there, it will be overwritten and the old value is returned. If there was no value there, the new value is inserted and a null value is returned. However if the map implementation allows the addition of null values then we can not tell whether the return of a null value is because of there not being a prior element or if it is the return of the previous element. To distinguish these two cases, we can use the containsValue() method which returns true if the input value is present in the map
get(Object key) returns the value associated with a given key. If there is no such key present, then a null is returned
remove(Object key) removes the element with the matching key and returns its value. It returns null if the element was not found.
containsKey(Object key) returns true if map contains the particular key
containsValue(Object value) returns true if map contains the particular value
size() returns the size of the map
isEmpty() returns true if map is empty

Bulk Operations
     public interface Map<K, V>{
        void putAll(Map<? extends K, ? extends V> m);
	void clear();
      }
putAll(Map<? extends K, ? extends V> m) puts all the corresponding elements from the input map into the current one
clear() method removes all the elements from the map.

Collection View Operations
	public interface Map<K, V> {
	    Set<K> keySet();
	    Collection<V> values();
	    Set<Map.Entry<K,V>> entrySet();
	    
	    public interface Entry {
	        K getKey();
		V getValue();
		V setValue(V value);
	    }
        }

keySet() - returns all the keys present in the map. Thus is returns a Set<K>. If you want to remove some keys from the Set, you can use an Iterator on the returned Set and invoke the remove method on the iterator. Alternatively you can use Set methods like remove(), removeAll(), retainAll() and clear() HOWEVER you cannot invoke either add() or addAll() methods --> you will get an UnsupportedOperationException. Note the returned Set is backed by the original map so any changes made in the returned set will reflect on the map.
values() returns a Collection<V> of all the values in the map. All the properties just discussed for the keySet() method will also apply to this method. Note that in the case of keySet(), a Set was returned but for values() a Collection is returned. This is because keys are unique and so can be returned in a Set whereas values can be duplicated and hence a Collection is returned.
entrySet() is useful for iterating the map. It returns a Set view of all the mappings in the map and each mapping is an instance of an interface called Entry which is a nested interface within the map interface[ nested interfaces improve readability. It is only used by Map interfaces and so it would pollute the namespace. Someone looking at the code would think it was widely used if it was a general interface but when nested, one can easily tell that it is only to do with Map ]
Each instance of Entry corresponds to a mapping in Map and so it stores both key K as well as value V providing methods like getKey() and getValue(). When iterating the map, these methods can also be invoked
There is also a setValue(V value) which can be used to update a value in a particular mapping.
EXERCISE GREAT CARE IF KEYS ARE MUTABLE OBJECTS. Ideally you should only use immutable objects as keys eg Strings. The reason is that if you are storing a mutable object as key, then you change the state of the object later, upon searching for that same key, the map may return a null value eg hash function's logic is dependent on the object's state, even if the mapping was to the same bucket.
HashMap
-O(1) for put(), get() and remove()
- insertion order is not preserved
- permits null values and one null key
- not synchronized unlike legacy Hashtable class

Map<String,Integer> map1 = new HashMap<>();
map1.put("John", 25);
map1.put("Raj", 29);
map1.put("Anita", null);

System.out.println(map1); // { John=25, Raj=29, Anita=null } //null value allowed
map1.put("Anita", 23);
System.out.println(map1); // { John=25, Raj=29, Anita=23 } //old value overwritten 

System.out.println("Contains John? "+ map1.containsKey("John")); // true
System.out.println("Value at key, John is "+ map1.get("John"); //25

//iteration
	//using keySet()...
	Set<String> names = map1.keySet();
	for(String name: names){
		   System.out.println("Name: "+ name + ", Age: "+ map1.get(name));
	}

	//using entrySet() --> returns a set of all mappings
	Set<Map.Entry<String, Integer>> mappings = map1.entrySet();
	for(Map.Entry<String, Integer> map: mappings){
          System.out.println("Name: "+ map.getKey() + ", Age: "+ map1.getValue();
	 }

//sets are backed by the map
names.remove("Anita");
System.out.println(map1); // { John=25, Raj=29}

More complex HashMap
- Map of <String, AnotherMap>
Map<String, Map<String, Object>> userProfile = new HashMap<>();
Map<String, Object> profile = new HashMap<>();
profile.put("age", 25);
profile.put("dept", "CS");
profile.put("city", "New York");
userProfile.put("John", profile);

Map<String, Object> profile = new HashMap<>();
profile.put("age", 29);
profile.put("dept", "CS");
profile.put("city", "New York");
userProfile.put("Raj",	profile);

Map<String, Object> profile1 = userProfile.get("John");
int age = (Integer)profile.get("age");
System.out.println("Age: "+ age);

BE VERY CAREFUL WHEN USING MUTABLE KEYS
Let's see this by creating a map with a List as the key. The List will give us a suitable mutable key
List<Integer> list = new ArrayList<>();
list.add(1);
Map<List<Integer>, Integer> map = new HashMap<>();
map.put(list, 10)
System.out.println(map.get(list)); // returns 10 which is the value at key=list
// now we mutate the key
list.add(2);
System.out.println(map.get(list)); // returns null

This is because when you we ran map.put(list, 10), the hash function was run on the particular hashCode that list had at that time. After adding a new element to list and changing its structure, when we run map.get(list), the list.hashCode() which is input to the hash function will return a different hashCode from the previous one and so we will search in the wrong bucket. 
Some structures have hashCode functions that only use the memory address location for their hashCode() functions but if the class is overriding this default hashCode() function as in the case of ArrayList, then this will affect the proper functioning of the mapping. The equals function also needs to be checked since it is used to do the comparison with each key to see if the item has been found.

LinkedHashMap
When we discussed HashSet and later LinkedHashSet, we saw that HashSet does not preserve insertion order but LinkedHashSet extends a HashSet and preserves insertion order and is also almost as fast as a HashSet.
Similarly in the Map implementations, HashMap does not preserve insertion order while LinkedHashMap which extends HashMap does preserve order with about the same speed.
In Set implementations we have the HashSet and its subclass LinkedHashSet whereas in Map implementations we have HashMap and its subclass LinkedHashMap.
We know that internally HashSet uses a HashMap and LinkedHashSet uses a LinkedHashMapKey points
-LinkedHashMap is a hash table & linked list implementation of Map interface
- preserves insertion order - doubly linked list 
- extends HashMap - nearly as fast too!
  - rapid lookup, insertion and deletion ~ O(1) [slight expense due to list ]
- permits null values & one null key
- not synchronized 

iteration(LinkedHashMap) faster than iteration(HashMap)
- because iteration with LinkedHashMap depends on the size of the map
whereas iteration with the HashMap depends on the capacity

LinkedHashMap can be used as LRU Cache --> Least Recently Used Cache. Most heavily-trafficked websites cache a lot of data. memcached is a very popular in-memory caching system that these websites make use of. Such data is stored in RAM for fast access.
LRU Cache
- uses least recently used caching strategy ie one end of cache is least recently used item and the other has the most recently used item -> items are ordered according to how recently they were used. 
- if cache is full, the least recently added item on the list is removed/evicted
- if you are searching for an item and it is on the cache, it is called a cache hit. Otherwise it is called a cache miss. We then try to find the item in the database and if found, it will be moved into the cache.
Note that the LRU Cache is only a feature of LinkedHashMap. It does not apply ot LinkedHashSet although LinkedHashSet internally uses a LinkedHashMap

You can specify the size of the LRU cache by creating a subclass since by default the LinkedHashMap does not have a default size for the cache.

Map<String, String> lruCache = new LinkedHashMap<>(16, 0.75f, false);
lruCache.put("a", "A");
lruCache.put("b", "B");
lruCache.put("c", "C");
System.out.println(lruCache); //[a=A, b=B, c=C]
lruCache.put("d", "D");
lruCache.put("e", "E");
// to create a cache we need to override the removeEldestEntry() function and give it a max size

public class LRUCache<K, V> extends LinkedHashMap<K,V>{
       private static final MAX_ENTRIES = 3;
       
       public LRUCache(Int initialCapacity, float loadFactor, boolean accessOrder){
          super(initialCapacity, loadFactor, accessOrder);
       }

       public boolean removeEldestEntry(Map.Entry eldest){
        return size() > MAX_ENTRIES;
       }
}

Just like in Collection hierarchy with the SortedSet and NavigableSet, there is also the SortedMap and NavigableMap in  the Map hierarchy
______________________________                      _______________
|       Collection           |                      |   Map       |
------------------------------                      ---------------
|List   Set             Queue|                      |   SortedMap |
|         |               |  |                      |       |     |
|         |               |  |                      |       |     |
|      SortedSet        Deque|                      | NavigableMap|
|         |                  |                       ---------------
|         |                  |
|      NavigableSet          |
|____________________________|

SortedMap
-allows sorting of mappings based on keys
-Natural ordering by keys implementing the Comparable interface or by passing a Comparator during declaration

public interface SortedMap<K,V> extends Map<K,V>{
//Range-view
SortedMap <K,V> subMap(K fromKey, K toKey);
SortedMap<K,V> headMap(K toKey);
SortedMap<K,V> tailMap(K fromKey);

//Endpoints
K firstKey();
K lastKey();

//Comparator access
Comparator<? super E> comparator();

//Collection view operations
Set<K> keySet();
Collection<V> values();
Set<Map.Entry<K,V>> entrySet();
}
 Note that the methods are very similar to the ones in SortedSet. Except in SortedSet we were working with elements but here we have keys.
subMap(K fromKey, K toKey), headMap(K toKey) and tailMap(K fromKey) all return a sorted map  which is backed by the original map. These methods are specific to SortedMap.
We also have a comparator() function whicch returns a Comparator if there is one otherwise it returns null

keySet(), values() and entrySet() are Collection view operations
- keySet() returns the set of all keys, ordered according to the sorting criteria. Note that it returns a Set since keys are unique
- values() returns all the values ordered according to the sorting criteria. Note that it returns a Collection since duplicates are permitted.
-entrySet() returns all the mappings in the SortedMap sorted by keys. Each mapping is an instance of the Entry interface which is a nested interface defined within the Map interface.
**All 3 of these collection view methods are backed by the original map so any changes made in the returned view will be reflected in the original map and vice versa. You can remove elements using the collections returned in these methods but you cannot add anything to the original map through them as they are collections of elements rather than a collection of mappings. Even the set returned by entrySet() does not permit add operations and if you try to add something it will throw an UnsupportedOperationException

public interface NavigableMap<K,V> extends SortedMap<K,V>{
//closest matches
K lowerKey/floorKey/ceilingKey/higherKey(K key);
Map.Entry<K,V> lowerEntry/floorEntry/ceilingEntry/higherEntry(K key);

NavigableSet<K> descendingKeySet();
NavigableMap<K,V> descendingMap();

//endpoints
Map.Entry<K,V> pollFirstEntry();
Map.Entry<K,V> pollLastEntry();

//range-view
NavigableMap<K,V> headMap(K toKey, boolean inclusive);
}

descendingKeySet() returns a reverse view of the keys in the map. It is returned as a NavigableSet
descendingMap returns a reverse view of the mappings in the map. It returns a NavigableMap
pollFirstEntry() and pollLastEntry() remove and return the first and last mappings respectively.
headMap(K toKey, boolean inclusive) returns a map whose values are less than (if inclusive = false) or less than or equal (inclusive = true) to the toKey parameter. 

TreeMap implements the NavigableMap and supports operations such as containsKey(), get() and remove() with O(log n) complexity
TreeMap<String, Integer> map1 = new TreeMap<>();

map1.put("John", 25);
map1.put("Raj", 29);
map1.put("Anita", 23);

System.out.println(map1); // { Anita=23, John=25, Raj=29 } //automatically sorted according to keys
Set<Map.Entry<String, Integer>> mappings = map1.entrySet();
for(Map.Entry<String, Integer> mapping: mappings){
	System.out.println("Name "+ mapping.getKey() + ", Age: "+ mapping.getValue());
	if(mapping.getKey().equals("John")){
	  mapping.setValue(26);
	} //show that you can make changes to the map during iteration
}

Note that entries returned by the following methods are just snapshots of the mappings at that particular time. They cannot be used to setValue() on the actual mapping. You will get an UnsupportedOperationException. These methods are Map.Entry<K,V> lowerEntry/floorEntry/ceilingEntry/higherEntry()

Arrays Class
- is a generic utility class and helps us manipulate arrays in many ways. It has methods to help us convert an Array into an ArrayList. It also has methods to help sort an Array, search for an element or compare arrays.
- most methods have overloaded versions for different primitive or object types
Arrays.asList(T[] arr) --> takes an input array and returns a List<T> - ArrayList of type T and fixed size. THIS FIXED SIZE ARRAY LIST HAS ITS LIMITATIONS. You cannot remove or add an element to a fixed size list --> UnsupportedOperationException. You can however update the value of the returned ArrayList and this would reflect in the original array too
Arrays.toString(T[] arr) returns a String representation of the contents of an array
If you want to create a modifiable ArrayList from an array, you can pass the fixed ArrayList as a parameter in a new ArrayList() declaration
eg List<String> strings = new ArrayList(Arrays.asList(strArray));
The .asList(T[] arr) takes an array as input but it also accepts comma separated lists or varargs as input eg asList("Raj", "Anita")
-if we just want to create an array of fixed size without an input array we can do:
List<String> fixedList = Arrays.asList(new String[3])); //returns an ArrayList of nulls. Other constructors of ArrayList start off with a default size but will increase size when capacity is reached. The Arrays.asList gives us the ability to make a fixed size ArrayList.
Arrays are not autoboxeable so if we want to create an array of Integers, the following will not work:
       List<Integer> fixedList = Arrays.asList(new int[2]);
int[2] cannot be automatically boxed to Integer. We have to do:
       List<Integer> fixedList = Arrays.asList(new Integer[2]);
The following would work though:
    List<int[]> fixedList2 = Arrays.asList(new int[2]);
-> this creates an ArrayList with only one element. That element would be an int array of size 2

   System.out.println(fixedList2.size()); // 1
- sort - 2 methods here one is void sort(Object[]) and void sort(T[] a, Comparator <? super T> c). 
sort(Object[])
sort(Object[]) uses merge-sort algorithm with natural ordering meaning that the type of the array elements should have implemented the Comparable interface
- Partially sorted array: far fewer than nlog(n) comparisons
- Almost sorted: approximatley n comparisons where n is the array size

Arrays.sort(strArray);

System.out.println(Arrays.toString(strArray));
-it is suitable for merging 2 or more sorted arrays - concatenate the arrays and sort the resulting array.
- if it is an array of primitives, the sort method will use a quick-sort algorithm
eg int[] iArray = {23, 34, 4, 59 };
Arrays.sort(iArray);
System.out.println(Arrays.toString(iArray));

sort(T[] a, Comparator<? super T> c)
- takes a Comparator and uses the comparator to sort the elements.

Binary Search: int Arrays.binarySearch(int[] inputArray, int searchValue)
-returns index if element is found
-otherwise it looks at the index where the element could be inserted, negates it, subtracts 1 from it and returns the result ie it returns -(insertion point) - 1
-input array must be sorted, otherwise behavior is undefined - this depends on the particular JVM implementation as some implementations still work even with unsorted arrays.

eg System.out.println("index returned by binary search: "+ Arrays.binarySearch(new int[]{4, 23, 59}, 4)); // returns 0
System.out.println("index returned by binary	search:	"+ Arrays.binarySearch(new \
int[]{4, 23, 59}, 5)); // returns -2 since 5 is not in the array to be searched, so the program also checks its possible insertion point = 1, negates it (-1) and subtracts 1 from it = -1-1 = -2

T[] Arrays.copyOf(T[] a, int length) - copy input array to a new array of a specified size. If there are any empty spots, they will have a default value in them.
eg int[] newArray = Arrays.copyOf(new int[]{1,2,3}, 5);
System.out.println(Arrays.toString(newArray)); // [1, 2, 3, 0, 0]

The System class also has an arraycopy method
System.arraycopy(T[] sourceArray, int startCopyingIndex, T[] destinationArray, int destinationArrayCopyStartPosition, int numberOfElementsToCopy)

void Arrays.fill(T[] arrayToBeFilled, T elementToFillAllIndices)
eg int[] newArray = new int[5];
   Arrays.fill(newArray, 13);
   System.out.println(newArray); //[13, 13, 13, 13, 13]

boolean Arrays.equals(T[] arr1, T[] arr2)
System.out.println("Equals? "+ Arrays.equals(iArray, newArray));
-equals() returns true if both arrays are of same type, size and have exact same contents. Can only work with arrays of 1 dimension.

boolean Arrays.deepEquals(Object[], Object[]);
-appropriate for multidimensional arrays
-returns true if arrays are deeply equal to one another
- note that the method takes two arrays of Objects (Object[], Object[])
eg int[][][] deepArray1 = { { {1,2,3}, {4,5,6} } };
   int[][][] deepArray2 = { { {1,2,3}, {4,5,6} } };
   System.out.println("Deep Array Equals? "+ Arrays.deepEquals(deepArray1, deepArray2)); //true
   int[][] deepArray3 = { {1,2,3} };
   int[][] deepArray4 = { {1,2,3} };
   System.out.println("Deep Array Equals? "+ Arrays.deepEquals(deepArray3, deepArra\
y4)); //true

   int[]deepArray3 = {1,2,3};
   int[]deepArray4 = {1,2,3};
   System.out.println("Deep Array Equals? "+ Arrays.deepEquals(deepArray3, deepArra\
\
y4)); //compilation error because int[] is not an array of objects, it is just an object.
Parallelized Operations
-introduced in Java 8. If your system has multiple cores, it will be much more efficient as it can do things in parallel
int[] iArray = {23, 4, 99};
Arrays.parallelSort(iArray);
System.out.println("parallel sort: "+ Arrays.toString(iArray));
- this method is beneficial for large arrays. Minimum size size 1 << 13 (equivalent to 2^13) = 8192

Arrays.parallelPrefix(int[] arr, IntBinaryOperator op)
- cumulates each element of the given array in place using the supplied function. It is usually more efficient than sequential loops for large arrays.
- IntBinaryOperator is a functional interface to which we can pass an implementation or a lambda
  class IntBinaryOperatorImpl implements IntBinaryOperator {
  	public int applyAsInt(int left, int right){
	       return left + right;
        }
 }

IntBinaryOperatorImpl IntBinaryOperatorImp = new IntBinaryOperatorImpl();
Arrays.parallelPrefix(iArray, IntBinaryOperatorImp);

Arrays.parallelSetAll(int[] arr, IntUnaryOperator generator)
- sets all elements of a given array in paralle using the provided generator function to compute each element.

class IntUnaryOperatorImpl implements IntUnaryOperator{
      int[] iArray;
      
      public void setArray(int[] iArray){
        this.iArray = iArray;
      }
      
      public int applyAsInt(int i){
        if(iArray != null){
	  return iArray[i] + 5;
        }else{
	   return i;
	}
}

IntUnaryOperatorImpl intUnaryOperatorImpl = new IntUnaryOperatorImpl();
intUnaryOperatorImpl.setArray(iArray);
Arrays.parallelSetAll(iArray, intUnaryOperatorImpl);


Collections Class
- we have looked at many different data structures but we need a class to manipulate all those data structures. For that we have the Collections class.
Not to be confused with the Collection interface.
- This class however is similar to the Arrays class in that it is also a utilities class with lots of static methods.

static boolean addAll(Collection<? super T> c, T...elements);
adds all elements inside an array to a Collection
eg we have our collection as a List:
   List<String> list = new ArrayList<>();
   list.add("Raj");
   list.add("John");
   list.add("John");

   String[] array = { "Batsi", "Ruva"};
//without using Collections
   //make array into list then use list.addAll()
   list.addAll(Arrays.toList(array));
//using Collections
   Collections.addAll(list, array); // cleaner and faster

static <T extends Comparable<? super T>> void sort(List<T> list)
Collections.sort(list); //elements must implement Comparable for natural sorting

<T> int binarySearch(List<? extends Comparable<? super T>> list, T key)
- takes in a List collection[only] and searches for the key.
System.out.println("What index is John in the list? : "+ Collections.binarySearch(list, "John");
-needs to be sorted. O(log(n))
-if not sorted results are undefined. Might perform an inefficient linear search
- for Sets: HashSet ~ O(1). TreeSet ~ O(log(n)), ie same efficiency as binary search
-note List.contains is O(n)


<T> int binarySearch(List<? extends T> list, T key, Comparator<? super T> c)
- this is a binary search alternative that takes in a Comparator

//other methods
Collections.reverse(list);
Collections.shuffle(list);
Collections.max(list);
Collections.min(list);
Collections.swap(list, 0, 3);
Collections.frequency(list, "John");

//Singleton ~ <T> Set<T> singleton(T o)
returns an immutable set containing only the specified object
- other: <T> List<T> singletonList(T o) & <K, V> Map<K,V> singletonMap(K key, V value)
list.removeAll(Collections.singleton("John")); //this gives us a cleaner way to delete an element from a collection rather than first creating a list of that element then using list.removeAll(). The other way would be to loop through the list then delete the item using an iterator.
singletonMap(K key, V value) returns a single mapping which can be used to delete that point from the map in a cleaner way.

Unmodifiable View - provides clients with read-only access to internal collection
      Collection<String> unmodifiable = Collections.unmodifiableCollection(list);
      System.out.println("unmodifiable: "+ unmodifiable);
      System.out.println("Is Anita there?: "+ unmodifiable.contains("Anita"));
      unmodifiable.add("Vincent"); // UnsupportedOperationException
- you can add something to the list and that element will be added to the returned collection

Best Practices
RETURN EMPTY COLLECTION OR EMPTY ARRAYS NOT NULLS
-if your method returns a collection or an array, return the empty versions rather than null
WRITE GOOD PROGRAMS WITH GOOD DESIGN PRINCIPLES EG INFORMATION HIDING. IF PERFORMANCE IS AN ISSUE IT CAN ALWAYS BE OPTIMIZED LATER

eg returning empty array
private static final String[] EMPTY_ARRAY = new String[0];

public String[] getBookTitlesByAuthor(String author){
    List<String> titles = dao.getBookTitlesByAuthor(author);
    return titles.toArray(EMPTY_ARRAY);
}

//returning the same empty immutable Collection

public List<String> getBookTitlesByAuthor(String author){
   List<String> titles = dao.getBookTitlesByAuthor(author);
   if(titles.isEmpty()){
     return Collections.emptyList();
   }

   return titles;
}

-there are other similar methods like emptyMap() or emptySet();
-to check whether collection is empty, use the isEmpty() method rather than calling on the size

SUMMARY OF COLLECTIONS
When to use Which Collection?
Collection interface hierrarchy
List: 
- when sequence or position matters
  -ArrayList: fast random access, appending or deleting last item
  -LinkedList: if there are frequent add/remove operations during iteration
Queue
- when fast head/tail manipulations matter
  -ArrayDeque: recommended over LinkedList when it comes to Deque implementation. LIFO & FIFO operations in O(1). 3X better than LinkedList for large queues
Set
- when uniqueness and fast lookups matter
  -HashSet: very fast lookup, insertion and deletion - O(1). ALWAYS OVERRIDE hashCode() METHOD WHEN YOU OVERRIDE EQUALS
  -LinkedHashSet: preserves insertion order and almost as fast as HashSet
  -TreeSet: - if we need elements sorted and still fast O(log(n))
  - both HashSet and TreeSet extend the AbstractSet class.

Map interface hierrarchy
-HashMap - fast lookup, insertion and deletion - O(1)
-LinkedHashMap (LRU Cache) - preserve insertion order and almost as fast as HashMap
-TreeMap - keeps elements sorted and fast to retrieve O(log(n))
-both HashMap and TreeMap extend AbstractMap

Algorithm Classes - static utility classes
Arrays
- asList, sort, parallelSort, binarySearch, copyOf, equals

Collections
- addAll, sort, binarySearch, reverse, swap, shuffle, unmodifiableCollection

Generics
-introduced in Java 5
Motivation
Polymorphism promotes generalization eg supertypes can be used as polymorphic types for methods, parameters and return types. This allows us to pass subclass objects as arguments and return types.
Interfaces provide even more generalization as they can be implemented by classes coming from completely different hierrarchies.
-prior to Java 5, using Object class as a paremeter in functions was very common. eg prior to Java 5, the add() method used Object as a parameter, now it uses Generics
What problems can we run into with using Object as type?
We want to create a class Store that is capable of storing data for multiple types of objects of classes from different hierarchies eg Date, Car, Bookmark, Movie, Food etc. Let's assume that the only superclass that objects from these classes have in common is Object.
We can start off by having:
 class Store{
       private Object a;
        
       public void set(Object a){
          this.a = a;
       }
       
       public Object get(){
         return a;
       }
   } 

Now lets say we have a programmer John want to create a store for Dates and he does so in the following way:
Store store = new Store();
store.set(new Date());	//java.util.Date
...
Date date = (Date) store.get();	// cast

Here a store instance is created and a Date object is stored within the Store instance. Note that here the Date class is from the java.util package. Later the Date object that was stored inside the date object is being retrieved but since the return type of the get() method is of type Object, we have to apply a cast on the returned object in order to get our desired Date object.

Let's assume that another developer Anita executes her code next on the store instance:

store.set(new Date()); //java.sql.Date

Her code resets the Date object but her code creates an instance of the java.sql.Date class.
Later John executes the following code on the same store instance:

Date date = (Date) store.get(); //casting to java.util.Date

He will get a ClassCastException as the object is now of class java.sql.Date rather than java.util.Date

This is a problem we have when Object is used as a polymorphic type. 
- too generic - allows too many different instances to be stored in it
- you always need to use explicit casting on the objects returned to downcast them to the appropriate type
- unpleasant exceptions not caught until runtime. The generic objects will pass through compilation but will fail when the methods invoked on them are unsupported

Language designers introduced the generics feature so that such problems could be caught at compile-time. Generics are a purely compile-time concept.

The class Store is now rewritten using Generics:

class Store <T> {
  private T a;

  public void set(T a){
    this.a = a;

    }

  public T get(){
    return a;
  }
}

Here T is a type parameter.
John's code will now look like this

Store<Date> store = new Store<Date>();	//java.util.Date
store.set(new Date());
...
Date date = store.get();	// no casting

Next, if Anita tries to set the store object's Date variable using Date from the java.sql package...

store.set(new Date()); //compile error notifies her that that particular store instance can be passed only Date objects from the java.util package as was done by John

Thus by using a generic, we prevent runtime exceptions and we enforce type safety at compile time itself before we even get to run time

Another programmer Raj could use that Store class later to create another object with a different hierarchy and we can handle it with no issues
eg Store<Book> bookStore = new Store<Book>();
   store.set(new Book());

-with Generics we get the benefit of type-safety at compile time itself
-we have cleaner code
-code is more expressive - developer explicitly states what type of classes will be used
- generics give us a lot of flexibility - this is similar to using Object as a type but with the advantage of type-safety.

Generic & Parameterized Types
Generic Type
-a class or interface with type parameters
   class ClassName <T1, T2, T3, ...> { ... }
-within the class, type parameters can be used as type of instance variables or types of method parameters, local variables and return types
eg class Store <T> {
  private T a;

  public void set(T a){
    this.a = a;

    }

  public T get(){
    return a;
  }
}

T is used as an instance variable type, method parameter and return type in the above generic type.
Parameterized type
 class Store<T>{...} --> generic type with type parameter/formal type parameter T
	|
	|
Store<String> stringStore = new Store<String>();
Store<Date> dateStore = new Store<Date>();
Store<List<Date>> dateListStore = new Store<List<Date>>();
Store<Book> bookStore = new Store<>();

Store<String> is an example of a parameterized type. Here String is referred to as type argument or actual type parameter
In the first 3 instance creation we have the type argument on both sides but on the last one we have it only one one side. This is called Diamond notation and it works from Java 7 onwards. In this case, type is automatically inferred based on the type specified on the left hand.

Type Parameter Naming Conventions
- use single, uppercase letters
E - Element(Collections)
K - Key, V - Value (if you are writing a Map)
N - Number
T - Type (usually in non-collections)
S, U, V - 2nd, 3rd, 4th types

You can use any valid Java identifier but it is more helpful to standardize expectations by sticking to this convention.

Subtyping of Generic Types

interface Container<T>{
  void set(T a);
  T get();
}

class Store<T> implements Container<T>{
      private T a;
      
      public void set(T a){
        this.a = a;
      }

      public T get(){
        return a;
      }
}

we can now say Container<String> store = new Store<>();

Multiple Type Parameters
public class Store <K, V> {
       private K key;
       private V value;
       
       public Store(K key, V value){
         this.key = key;
	 this.value = value;
       }
       
       public K getKey(){
         return key;
       }
       
       public V getValue(){
         return value;
       }
}

Restrictions
- type argument cannot be primitive
       eg Store<int> intStore = new Store<int>(); //compiler error
- type parameter cannot be used in a static context
       eg public class Device<T>{
             private static T deviceType;
	  }
Why is it illegal in a static context?
developer 1 runs:    Device<Smartphone> phone = new Device<>();
developer 2 runs:    Device<Pager> pager = new Device<>();
Question is what would T be after these two statements are executed? Smartphone or Pager?
developer 1 is assuming that static type will stay static as Smartphone since it ran first
developer 2 is assuming that static type is updated to Pager since it ran most recently
- type parameter thus cannot be used in a static method or static initializer.

What happens under the hood when using generics
Generics is a purely compile-time feature. At run-time there are not generics. It means that the compiler uses a feature called Type Erasure to remove all type arguments eg T and just represent the generic types without the types eg
eg class Store <T> {
  private T a;

  public void set(T a){
    this.a = a;

    }

  public T get(){
    return a;
  }
}

becomes...
eg class Store {
  private Object a;

  public void set(Object a){
    this.a = a;

    }

  public Object get(){
    return a;
  }
}

next, the compiler inserts explicit casts wherever the objects based from generics are used. Thus our code will look clean but behind the scenes, the compiler will bring back all the casts needed to ensure proper functioning.

Bounded Type Parameter
-generic types give the client the power to instantiate the generics with classes of their choosing but sometimes we might want to put some restrictions on what type they can pass in whilst instantiating the generic code.
- this is where bounded type parameters come in handy
- a bounded type parameter is a type parameter with 1 or more bounds

<TypeParameter extends bound1 & bound2 & ...> { ... }

eg class Generics Demo <T extends List> { ... }
This means that the type parameter has to be List or one of its subtypes.
Thus for this generic type, we could have:
     GenericsDemo<List> test = new GenericsDemo<>();
OR   GenericsDemo<ArrayList> test = new GenericsDemo<>();
OR   GenericsDemo<LinkedList> test = new GenericsDemo<>();
BUT NOT GenericsDemo<Collection> test = new GenericsDemo<>(); --> Thus in this way we have restricted the possible type parameters possible for our GenericsDemo class.
Bounded Type parameters also allow its class to access the methods defined by it

eg class GenericsDemo<T>{
      void go(T list){
        int i = list.size()
      }
}

We get a compiler error here because the compiler does not know whether the chosen type would include the size() method.
But if we use a bounded type parameter where T extends the List interface, we have no problem as any type that extends List will have the size() method:

class GenericsDemo<T extends List> {
      void go(T list){
        int i = list.size();
      }
}

Note that the method has to be present for the entire bound. If it is only a method specific to one of its subtypes, we get a compiler error.
Recall that under the hood, during type erasure, the compiler will replace the type parameter with the Object class but that only happens for an unbounded type parameter. In the case of a bounded parameter type, the compiler will replace the type parameter with the bound itself.

Valid Bounds
- Class	
- Interface
- enum
- Parameterized type eg <T extends Comparable<T>>

Note that we use the keyword "extends" in all cases regardless of whether the bound is a class or interface or other.

Invalid Bounds
- primitives
- arrays

Specifics
- type argument must be subtype of all bounds
  eg class GenericsDemo <T extends List & Serializable>
  Generics<List> test = new GenericsDemo<>(); // compile error as List is not a subtype of Serializable
  GenericsDemo<ArrayList> test = new GenericsDemo<>(); // valid as ArrayList is a subtype of both List and Serializable

-if class is one of the bounds, it must be specified first
-if first bound is a class, then remaining bounds must be interfaces ie YOU CAN NOT HAVE MORE THAN ONE CLASS IN THE LIST OF BOUNDS - no restrictions on interfaces
- if bound is final class or enum, then the type argument is the bound itself - this is because final classes cannot have subtypes and enum is essentially a final class too.

